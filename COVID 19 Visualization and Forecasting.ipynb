{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID_19_Visualization_and_Forecasting.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-NnfRmrcYDHJ",
        "MJ_Wg2lVkb1b"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/terminate9298/Corona-Visualization-and-Prediction/blob/main/COVID%2019%20Visualization%20and%20Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py_GDzxCNDYE"
      },
      "source": [
        "<center><a href=\"https://colab.research.google.com/drive/12xjqXdRqbvx0XJ0292L-mgALqv09L7Mb?usp=sharing\" target=\"_parent\"><img src=\"https://skycityauckland.co.nz/media/2283506/thecolab.png\" alt=\"Open In Colab\"></a></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwrkCpIyUreL"
      },
      "source": [
        "# Downloading Files and Importing Libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kXxA9Pex-RH",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to Load Libraries (Important to Run)</h3>\n",
        "#@markdown <br><center><a href=\"#\"><img src='https://gifimage.net/wp-content/uploads/2018/04/loading-gif-bootstrap-13.gif' height=\"300\" alt=\"Gdrive-logo\"/></a></center>\n",
        "#@markdown <center><h2>Loading and Installing Important Libraries</h2></center><br>\n",
        "\n",
        "MODE = \"Use Without Drive\" #@param [\"MOUNT\", \"UNMOUNT\", \"Use Without Drive\"]\n",
        "Download_Dataset = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Library_To_Import = \"All\" #@param [\"All\", \"File Upload\", \"Telegram Uploader\", \"Youtub Downloader\", \"Torrent Downloader\", \"Unzip/UnRar\", \"Mega Downloader\"]\n",
        "#@markdown <br><h4><i>* Note - Always Run This Cell before Running Any Other Cell</i></h4>\n",
        "#@markdown <h4><i>* Note - Please Dont Change Anything If you are Not Sure</i></h4>\n",
        "\n",
        "# Importing Libraries\n",
        "!pip install wget\n",
        "# !pip install plotly_express\n",
        "!pip install --upgrade plotly\n",
        "!pip install --upgrade statsmodels\n",
        "!pip install pmdarima\n",
        "# Basic Libraries\n",
        "import wget\n",
        "import json , shutil , re , datetime , requests , cv2 , os , warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.offsetbox import AnchoredText\n",
        "import seaborn as sns\n",
        "import plotly.offline as py\n",
        "import plotly.express as px\n",
        "from folium import Map\n",
        "from folium.plugins import HeatMap\n",
        "from folium.plugins import MarkerCluster\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tools import eval_measures as eval\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from statsmodels.tsa.api import Holt, SimpleExpSmoothing, ExponentialSmoothing\n",
        "from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from pmdarima.arima import auto_arima\n",
        "from pmdarima.preprocessing import BoxCoxEndogTransformer , LogEndogTransformer\n",
        "from pmdarima.arima import AutoARIMA\n",
        "from statsmodels.tsa.forecasting.theta import ThetaModel\n",
        "from statsmodels.tsa.stattools import acf , pacf\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "plt.style.use('ggplot')\n",
        "sns.set_context(\"paper\")\n",
        "%matplotlib inline\n",
        "\n",
        "# Modelling\n",
        "from scipy import integrate\n",
        "from scipy import optimize\n",
        "\n",
        "# Map\n",
        "import folium\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from fbprophet import Prophet\n",
        "from fbprophet.plot import plot_plotly, add_changepoints_to_plot\n",
        "from fbprophet.plot import plot_components_plotly\n",
        "from IPython.display import Markdown\n",
        "from IPython.display import Image\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# For LSTM \n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import  RepeatVector, Reshape\n",
        "from keras.utils import plot_model\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import  Activation, add , GlobalMaxPooling1D,GlobalAveragePooling1D , Dense, Dropout, Embedding,Flatten, Conv1D, MaxPooling1D, LSTM , GRU, SpatialDropout1D ,Bidirectional ,Input , concatenate , TimeDistributed , Concatenate\n",
        "from keras import utils\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras_preprocessing.text import tokenizer_from_json\n",
        "from keras.models import model_from_json ,Model\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount._DEBUG = False\n",
        "clear_output()\n",
        "display(Markdown(\"<h1>Colab for Corona Virus Countinuous Updates</h1><br>\"))\n",
        "\n",
        "def refine_address(Address , default = 'Download' , file = False , make_dir = True):\n",
        "  if file == False:\n",
        "    if Address == '':\n",
        "      Address = default\n",
        "    if Address[0] =='/':\n",
        "      # If Absolute Path is Provided\n",
        "      if Address[-1] !='/':\n",
        "        Address = Address + '/'\n",
        "      else:\n",
        "        pass\n",
        "    # Else if Relative path is provided\n",
        "    elif os.path.exists('/content/drive/My Drive/'):\n",
        "      #If Drive is Mounted\n",
        "      Address = '/content/drive/My Drive/'+Address\n",
        "      if Address[-1] !='/':\n",
        "        Address = Address + '/'\n",
        "      else:\n",
        "        pass\n",
        "    else:\n",
        "      #Else if Drive is Not Mounted\n",
        "      Address = '/content/'+Address\n",
        "      if Address[-1] !='/':\n",
        "        Address = Address + '/'\n",
        "      else:\n",
        "        pass\n",
        "    if make_dir:\n",
        "      os.makedirs(Address, exist_ok=True)\n",
        "    else:\n",
        "      os.makedirs(Address, exist_ok=True)\n",
        "    return Address\n",
        "  else:\n",
        "    if Address[0] =='/':\n",
        "      return Address\n",
        "    elif os.path.exists('/content/drive/My Drive/'):\n",
        "      return '/content/drive/My Drive/'+ Address\n",
        "    else:\n",
        "      return '/content/'+Address\n",
        "\n",
        "# if not os.path.exists('/content/drive/'):\n",
        "#   drive.mount('/content/drive')\n",
        "\n",
        "if MODE == \"MOUNT\":\n",
        "  if not os.path.exists('/content/drive/'):\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "  File_Prefix = '/content/drive/MyDrive/COVID/India/'\n",
        "  display(Markdown(\"- <h4>Drive Mounted.....</h4><br>\"))\n",
        "elif MODE == \"UNMOUNT\":\n",
        "  try:\n",
        "    drive.flush_and_unmount()\n",
        "  except ValueError:\n",
        "    pass\n",
        "  get_ipython().system_raw(\"rm -rf /root/.config/Google/DriveFS\")\n",
        "  File_Prefix = '/content/'\n",
        "  display(Markdown(\"- <h4>Drive Unmounted.....</h4><br>\"))\n",
        "else:\n",
        "  File_Prefix = '/content/'\n",
        "  display(Markdown(\"- <h4>Importing Libraries Done.....</h4><br>\"))\n",
        "File_Prefix = refine_address(File_Prefix)\n",
        "\n",
        "if Download_Dataset:\n",
        "  wget.download('https://api.covid19india.org/csv/latest/states.csv',File_Prefix+'states_.csv')\n",
        "  wget.download('https://api.covid19india.org/csv/latest/districts.csv',File_Prefix+'districts_.csv')\n",
        "  wget.download('https://covid.ourworldindata.org/data/ecdc/full_data.csv',File_Prefix+'Covid_full_data.csv')\n",
        "  wget.download('https://covid.ourworldindata.org/data/owid-covid-data.csv',File_Prefix+'Covid_data.csv')\n",
        "  wget.download('https://api.covid19india.org/misc.json',File_Prefix+'Populations.json')\n",
        "  wget.download('https://raw.githubusercontent.com/terminate9298/Corona-Visualization-and-Prediction/main/Dataset/centroids.csv',File_Prefix+'centroids.csv')\n",
        "  wget.download('https://raw.githubusercontent.com/terminate9298/Corona-Visualization-and-Prediction/main/Dataset/tableconvert_csv_o4ycku.csv',File_Prefix+'tableconvert_csv_o4ycku.csv')\n",
        "\n",
        "display(Markdown(\"- <h4>Files Downloaded Successfully.....</h4><br>\"))\n",
        "\n",
        "states = pd.read_csv(File_Prefix+'states_.csv')\n",
        "districts = pd.read_csv(File_Prefix+'districts_.csv')\n",
        "centroids = pd.read_csv(File_Prefix+'centroids.csv')\n",
        "states = pd.concat([pd.DataFrame([['2020-03-01','Kerala',0,0,0,0,0]],columns = states.columns) , states] ,axis = 0)\n",
        "states.sort_values(by = ['Date'])\n",
        "states.fillna(0 , inplace = True)\n",
        "districts.fillna(0 , inplace = True)\n",
        "states['Active'] = states['Confirmed'] - (states['Recovered'] + states['Deceased'])\n",
        "states['Month'] = states['Date'].apply(lambda x: x.split('-')[1])\n",
        "states['Month'] = states['Month'].astype(int)\n",
        "states = states[states['Month']>2]\n",
        "date_unique = states.Date.unique()\n",
        "date_unique = date_unique[:-1]\n",
        "World_ = pd.read_csv(File_Prefix+'Covid_data.csv')\n",
        "World_.fillna(0,inplace = True)\n",
        "World_['date'] = pd.to_datetime(World_['date'] , format = '%Y-%m-%d')\n",
        "basedate = pd.Timestamp(World_.date.min())\n",
        "World_['Days_Passed'] = (World_['date'] - basedate)/86400000000000\n",
        "World_['date'] = World_['date'].astype(str)\n",
        "World_['Days_Passed'] = World_['Days_Passed'].astype(int)\n",
        "\n",
        "world_locations = pd.read_csv(File_Prefix+'tableconvert_csv_o4ycku.csv')\n",
        "world_locations.columns = ['Country', 'Alpha-2 code', 'iso_code', 'Numeric code', 'Latitude (average)', 'Longitude (average)']\n",
        "World_ = World_.merge(world_locations , how = 'left' , on = ['iso_code'])\n",
        "\n",
        "display(Markdown(\"- <h4>World Data Processed...</h4><br>\"))\n",
        "world_dates_unique = World_.date.unique()\n",
        "\n",
        "Completed_ = []\n",
        "District_ = []\n",
        "for st in states['State'].unique():\n",
        "  Arr_ = states[states.State == st].values\n",
        "  Confirmed_ = 0\n",
        "  Recovered_ = 0\n",
        "  Deceased_ = 0\n",
        "  Other_ = 0 \n",
        "  Tested_ = 0\n",
        "  Active_ = 0\n",
        "  K_ = 0\n",
        "  dyas = 0\n",
        "  for i in date_unique:\n",
        "    if i in Arr_[:,0]:\n",
        "      Completed_.append([\n",
        "                         i,\n",
        "                         st,\n",
        "                         Arr_[K_,2],#Confirmed\n",
        "                         Arr_[K_,3],#Recovered\n",
        "                         Arr_[K_,4],#Deceased\n",
        "                         Arr_[K_,5],#Other\n",
        "                         Arr_[K_,6],#Tested\n",
        "                         Arr_[K_,7],#Active\n",
        "                         Arr_[K_,2] - Confirmed_,#Confirmed\n",
        "                         Arr_[K_,3] - Recovered_,#Recovered\n",
        "                         Arr_[K_,4] - Deceased_,#Deceased\n",
        "                         Arr_[K_,5] - Other_,#Other\n",
        "                         Arr_[K_,6] - Tested_,#Tested\n",
        "                         Arr_[K_,7] - Active_, #Active\n",
        "                         dyas #Days Passes since\n",
        "      ])\n",
        "      Confirmed_ = Arr_[K_,2]\n",
        "      Recovered_ = Arr_[K_,3]\n",
        "      Deceased_ = Arr_[K_,4]\n",
        "      Other_ = Arr_[K_,5]\n",
        "      Tested_ = Arr_[K_,6]\n",
        "      Active_ = Arr_[K_,7]\n",
        "      K_ += 1\n",
        "      dyas +=1\n",
        "    else:\n",
        "      Completed_.append([\n",
        "                         i,\n",
        "                         st,\n",
        "                         Confirmed_,#Confirmed\n",
        "                         Recovered_,#Recovered\n",
        "                         Deceased_,#Deceased\n",
        "                         Other_,#Other\n",
        "                         Tested_,#Tested\n",
        "                         Active_,#Active\n",
        "                         0,#Confirmed\n",
        "                         0,#Recovered\n",
        "                         0,#Deceased\n",
        "                         0,#Other\n",
        "                         0,#Tested\n",
        "                         0,#Active\n",
        "                         dyas\n",
        "      ])\n",
        "      dyas += 1\n",
        "Completed_ = pd.DataFrame(np.array(Completed_) , columns = ['Date', 'State', 'Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_', 'Tested_', 'Active_','Days_Passed'])\n",
        "for i in ['Confirmed', 'Recovered', 'Deceased', 'Other',\n",
        "       'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_',\n",
        "       'Tested_', 'Active_', 'Days_Passed']:\n",
        "  Completed_[i] = Completed_[i].astype(str).astype(np.float64)\n",
        "Completed_['Negative'] = Completed_['Tested_'] - Completed_['Confirmed_']\n",
        "Completed_[\"Death Rate (per 100)\"] = np.round(100*Completed_[\"Deceased\"]/Completed_[\"Confirmed\"],2)\n",
        "Completed_[\"Cure Rate (per 100)\"] = np.round(100*Completed_[\"Recovered\"]/Completed_[\"Confirmed\"],2)\n",
        "Completed_.fillna(0,inplace = True)\n",
        "India_ = Completed_[Completed_.State == 'India']\n",
        "# Completed_ = Completed_[Completed_.State != 'India']\n",
        "Completed_['Month'] = Completed_['Date'].apply(lambda x: x.split('-')[1])\n",
        "Completed_['Month'] = Completed_['Month'].astype(int)\n",
        "India_['Date'] = pd.to_datetime(India_['Date'] , format = '%Y-%m-%d')\n",
        "India_['Date'] = India_['Date'].dt.strftime('%m/%d/%Y')\n",
        "def clear_states(text):\n",
        "  text = re.sub(r\"Uttar Pradesh\", \"UP\", text)\n",
        "  text = re.sub(r\"Tamil Nadu\", \"TN\", text)\n",
        "  text = re.sub(r\"Jammu and Kashmir\", \"J&K\", text)\n",
        "  text = re.sub(r\"Andhra Pradesh\", \"Andra P\", text)\n",
        "  text = re.sub(r\"Himachal Pradesh\", \"HP\", text)\n",
        "  text = re.sub(r\"Madhya Pradesh\", \"MP\", text)\n",
        "  text = re.sub(r\"Andaman and Nicobar Islands\", \"A&N\", text)\n",
        "  text = re.sub(r\"Arunachal Pradesh\", \"Arun P\", text)\n",
        "  text = re.sub(r\"Dadra and Nagar Haveli and Daman and Diu\", \"D&D\", text)\n",
        "  text = re.sub(r\"State Unassigned\", \"Other\", text)\n",
        "  return text\n",
        "with open(File_Prefix+'Populations.json') as f:\n",
        "  data = json.load(f)\n",
        "district_populations = pd.DataFrame(data['district_meta_data'])\n",
        "state_populations = pd.DataFrame(data['state_meta_data'])\n",
        "state_populations.columns = ['Abbreviation', 'State No', 'Population', 'State']\n",
        "district_populations.columns = ['District', 'District Key', 'Population', 'SL No', 'State', 'State Code']\n",
        "\n",
        "\n",
        "Completed_ = Completed_.merge(state_populations , on=['State'] , how = 'left')\n",
        "India_ = India_.merge(state_populations , on=['State'] , how = 'left')\n",
        "Completed_['Population'] = Completed_['Population'].replace('',np.NaN).astype(np.float32)\n",
        "Completed_['Population'].fillna(Completed_['Population'].mean() , inplace= True)\n",
        "India_['Population'] = India_['Population'].replace('',np.NaN).astype(np.float32)\n",
        "India_['Population'].fillna(India_['Population'].mean() , inplace= True)\n",
        "\n",
        "Completed_['State'] = Completed_['State'].apply(lambda x: clear_states(x))\n",
        "states_list = Completed_.State.unique()\n",
        "India_ = India_.head(India_.shape[0]-1)\n",
        "\n",
        "India_.reset_index(drop = True , inplace = True)\n",
        "display(Markdown(\"- <h4>India State Level Data Processed...</h4><br>\"))\n",
        "\n",
        "\n",
        "districts['Date'] = pd.to_datetime(districts['Date'], format = '%Y-%m-%d')\n",
        "districts['Days_Passed'] = districts['Date'] - districts['Date'].min()\n",
        "districts['Days_Passed'] = ((districts['Days_Passed'].values)/86400000000000).astype(int)\n",
        "districts.sort_values(by = ['District','Date'] ,inplace = True)\n",
        "districts['Active'] = districts['Confirmed'] - (districts['Recovered']+districts['Deceased'])\n",
        "District_ = []\n",
        "for s,st in districts[['State','District']].drop_duplicates().values:\n",
        "  Arr_ = districts[districts.State == s]\n",
        "  Arr_ = Arr_[Arr_.District == st].values\n",
        "  Confirmed_ = 0\n",
        "  Recovered_ = 0\n",
        "  Deceased_ = 0\n",
        "  Other_ = 0 \n",
        "  Tested_ = 0\n",
        "  Active_ = 0\n",
        "  for K_ in range(len(Arr_)-1):\n",
        "    District_.append([\n",
        "                          Arr_[K_,0],#Date\n",
        "                          Arr_[K_,1],#State\n",
        "                          Arr_[K_,2],#District\n",
        "                          Arr_[K_,3],#Confirmed\n",
        "                          Arr_[K_,4],#Recovered\n",
        "                          Arr_[K_,5],#Deceased\n",
        "                          Arr_[K_,6],#Other\n",
        "                          Arr_[K_,7],#Tested\n",
        "                          Arr_[K_,9],#Active\n",
        "                          Arr_[K_,3] - Confirmed_,#Confirmed\n",
        "                          Arr_[K_,4] - Recovered_,#Recovered\n",
        "                          Arr_[K_,5] - Deceased_,#Deceased\n",
        "                          Arr_[K_,6] - Other_,#Other\n",
        "                          Arr_[K_,7] - Tested_,#Tested\n",
        "                          Arr_[K_,9] - Active_, #Active\n",
        "                          Arr_[K_,8],#Days Passed\n",
        "        ])\n",
        "    Confirmed_ = Arr_[K_,3]\n",
        "    Recovered_ = Arr_[K_,4]\n",
        "    Deceased_ = Arr_[K_,5]\n",
        "    Other_ = Arr_[K_,6]\n",
        "    Tested_ = Arr_[K_,7]\n",
        "    Active_ = Arr_[K_,9]\n",
        "\n",
        "District_ = pd.DataFrame(np.array(District_) , columns = ['Date', 'State', 'District', 'Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_', 'Tested_', 'Active_','Days_Passed'])\n",
        "for i in ['Confirmed', 'Recovered', 'Deceased', 'Other',\n",
        "       'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_',\n",
        "       'Tested_', 'Active_', 'Days_Passed']:\n",
        "  District_[i] = District_[i].astype(str).astype(np.float64)\n",
        "District_['Negative'] = District_['Tested_'] - District_['Confirmed_']\n",
        "District_[\"Death Rate (per 100)\"] = np.round(100*District_[\"Deceased\"]/District_[\"Confirmed\"],2)\n",
        "District_[\"Cure Rate (per 100)\"] = np.round(100*District_[\"Recovered\"]/District_[\"Confirmed\"],2)\n",
        "District_.fillna(0,inplace = True)\n",
        "# Completed_ = Completed_[Completed_.State != 'India']\n",
        "District_['Month'] = District_['Date'].astype(str).apply(lambda x: x.split('-')[1])\n",
        "District_['Month'] = District_['Month'].astype(int)\n",
        "\n",
        "\n",
        "District_ = District_.merge(district_populations , on=['District','State'] , how = 'left')\n",
        "\n",
        "state_Cooridinates = [\n",
        " ['Goa','Unknown' , 15.2993, 74.1240],\n",
        " ['Andaman and Nicobar Islands','Unknown' , 11.7401 , 92.6586],\n",
        " ['Manipur','Unknown' , 24.6637, 93.9063],\n",
        " ['Assam','Unknown' , 26.2006 , 92.9376],\n",
        " ['Chandigarh','Unknown' , 30.7333, 76.7794],\n",
        " ['Telangana','Unknown' , 17.3850, 78.4867],\n",
        " ['Delhi','Unknown' , 28.7041, 77.1025],\n",
        " ['Sikkim','Unknown' ,27.5330, 88.5122],\n",
        "]\n",
        "centroids = pd.concat([centroids , pd.DataFrame(state_Cooridinates , columns = ['State','District','Latitude','Longitude'])])\n",
        "District_ = District_.merge(centroids , on = ['District','State'], how = 'left')\n",
        "District_['Population'] = District_['Population'].replace('',np.NaN).astype(np.float32)\n",
        "District_['Population'].fillna(District_['Population'].mean() , inplace= True)\n",
        "\n",
        "District_.index = pd.to_datetime(District_['Date'])\n",
        "India_.index = pd.to_datetime(India_['Date'])\n",
        "Completed_.index = pd.to_datetime(Completed_['Date'])\n",
        "World_.index = pd.to_datetime(World_['date'])\n",
        "\n",
        "India_['Month'] = India_.index.month_name() \n",
        "Completed_['Month'] = Completed_.index.month_name() \n",
        "District_['Month'] = District_.index.month_name() \n",
        "World_['Month'] = World_.index.month_name() \n",
        "\n",
        "display(Markdown(\"- <h4>India District Level Data Processed...</h4><br>\"))\n",
        "\n",
        "Sup_Title = \"Corona Virus\"\n",
        "Style_Color = \"rocket\"\n",
        "Plot_Style = \"fast\" \n",
        "SNS_Context = \"poster\" \n",
        "SNS_Style = \"ticks\" \n",
        "Format_To_Save = \"jpg\"\n",
        "\n",
        "\n",
        "Graphs_Width = 29 \n",
        "Graphs_Height = 19 \n",
        "SNS_Font_Scale = 0.75\n",
        "Plot_Saturation = 0.86 \n",
        "Plot_Alpha = 0.85 \n",
        "SubPlot_Top = 0.92 \n",
        "\n",
        "plt.style.use(Plot_Style)\n",
        "sns.set_context(SNS_Context , font_scale = SNS_Font_Scale)\n",
        "sns.set_style(SNS_Style)\n",
        "plt.tight_layout()\n",
        "\n",
        "Style_Palettes = sns.color_palette(Style_Color)\n",
        "sns.color_palette(Style_Color)\n",
        "display(Markdown(\"- <h4>Setting To Default...</h4><br>\"))\n",
        "\n",
        "display(Markdown(\"- <h4>All Files Preprocessed Successfully.....</h4><br>\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt5YishNOd80"
      },
      "source": [
        "#Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "N_rCniuY2s41"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to Change Settings</h3>\n",
        "#@markdown <br><center><img src='https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse1.mm.bing.net%2Fth%3Fid%3DOIP.OVRVW9ZaxOE3sHmsX7_bMAHaHa%26pid%3DApi&f=1' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Setting the Configuration</h2></center><br>\n",
        "Sup_Title = \"Corona Virus\" #@param {type:\"string\"}\n",
        "Style_Color = \"rocket_r\" #@param [\"tab10\" , \"deep\", \"muted\", \"pastel\", \"bright\", \"dark\", \"colorblind\" , \"hls\" , \"husl\" , \"Set2\", \"Paired\" , \"rocket\", \"mako\", \"flare\", \"crest\" , \"magma\" , \"viridis\" , \"rocket_r\" , \"cubehelix\" , \"ch:start=.2,rot=-.3\" , \"ch:s=-.2,r=.6\" , \"dark:salmon_r\" , \"Blues\" , \"YlOrBr\" , \"vlag\" , \"icefire\" , \"Spectral\" , \"coolwarm\"]\n",
        "Plot_Style = \"fast\" #@param ['Solarize_Light2', '_classic_test_patch', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', 'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', 'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', 'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']\n",
        "SNS_Context = \"poster\" #@param ['notebook','paper','talk','poster']\n",
        "SNS_Style = \"ticks\" #@param ['darkgrid', 'whitegrid', 'dark', 'white', 'ticks']\n",
        "Format_To_Save = \"jpg\" #@param [\"jpg\", \"png\", \"jpeg\", \"eps\", \"pdf\", \"svg\", \"raw\", \"rgba\", \"tif\", \"tiff\"]\n",
        "\n",
        "\n",
        "Graphs_Width = 29 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "Graphs_Height = 19 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "SNS_Font_Scale = 0.75 #@param {type:\"slider\", min:0, max:3, step:0.05}\n",
        "Plot_Saturation = 0.86 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "Plot_Alpha = 0.85 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "SubPlot_Top = 0.92 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "plt.style.use(Plot_Style)\n",
        "sns.set_context(SNS_Context , font_scale = SNS_Font_Scale)\n",
        "sns.set_style(SNS_Style)\n",
        "plt.tight_layout()\n",
        "display(Markdown(\"<h1>Using The Color Palatte</h1>\"))\n",
        "\n",
        "Style_Palettes = sns.color_palette(Style_Color)\n",
        "sns.color_palette(Style_Color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu05ZcWZhxQ8"
      },
      "source": [
        "# COVID-19 Cases in World"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "6l8hR5mxR0wf"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://image.flaticon.com/icons/png/512/2037/2037098.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Corona Virus on World Map with HeatMap of Indian Districts</h2></center><br>\n",
        "\n",
        "Type_Of_HeatMap = \"Confirmed\" #@param [\"Effected_Districts\",'Confirmed', 'Recovered', 'Deceased','Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_','Other_', 'Tested_', 'Active_', 'Days_Passed', 'Negative', 'Death Rate (per 100)', 'Cure Rate (per 100)','Population']\n",
        "Date = \"2020-12-07\" #@param {type:\"date\"}\n",
        "\n",
        "if Date not in District_['Date'].astype(str).unique():\n",
        "  Date = District_['Date'].max()\n",
        "\n",
        "data = District_[District_['Date'] == Date].dropna()\n",
        "\n",
        "if Type_Of_HeatMap == \"Effected_Districts\":\n",
        "  m = folium.Map(location=data[['Latitude', 'Longitude']].mean().values,width=\"%100\",height=\"%100\", zoom_start=6)\n",
        "  m.add_children(HeatMap(data[['Latitude', 'Longitude']].values))\n",
        "\n",
        "else:\n",
        "  plt_by = Type_Of_HeatMap\n",
        "  m = folium.Map(location=data[['Latitude', 'Longitude']].mean().values,width=\"%100\",height=\"%100\", zoom_start=6)\n",
        "  m.add_children(HeatMap(data[['Latitude', 'Longitude',plt_by]].values))\n",
        "marker_cluster = MarkerCluster().add_to(m)\n",
        "for i in range(data.shape[0]):\n",
        "  rw = data.iloc[i]\n",
        "  tooltip = \"District:{}<br> {} Cases: {}<br> Click for more\".format(rw[\"District\"], plt_by.replace('_',' (Daily Cases)').title(),rw[plt_by])\n",
        "  location = [rw['Latitude'] , rw['Longitude']]\n",
        "  folium.Marker(location, \n",
        "                popup= \"District : {}<br>State : {}<br>Population : {}<br>Confirmed Cases : {}<br>Recovered Cases : {}<br>Deceased Cases : {}<br>Active Cases : {}<br>New Confirmed Cases : {}<br>New Recovered Cases : {}<br>New Deceased Cases : {}<br>Cure Rate (per 100) : {}<br>Death Rate (per 100) : {}\".format(rw['District'],rw['State'],rw['Population'], rw['Confirmed'],rw['Recovered'],rw['Deceased'],rw['Active'],rw['Confirmed_'],rw['Recovered_'],rw['Deceased_'],rw['Cure Rate (per 100)'],rw['Death Rate (per 100)']) , \n",
        "                tooltip=tooltip).add_to(marker_cluster)\n",
        "data = World_[World_['date'] == Date].dropna()\n",
        "for i in range(data.shape[0]):\n",
        "  rw = data.iloc[i]\n",
        "  tooltip = \"Country:{}<br>Total Cases: {}<br> Click for more\".format(rw[\"location\"], rw['total_cases'] )\n",
        "  location = [rw['Latitude (average)'] , rw['Longitude (average)']]\n",
        "  folium.Marker(location, \n",
        "                popup= \"Country : {}<br>Total Cases : {}<br>New Cases : {}<br>Total Death Cases : {}<br>New Death Cases : {}\".format(rw['location'],rw['total_cases'],rw['new_cases'], rw['total_deaths'],rw['new_deaths']) , \n",
        "                tooltip=tooltip).add_to(marker_cluster)\n",
        "m\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "m4UWFOwJctsS"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://cdn2.iconfinder.com/data/icons/coronavirus-118/82/coronavirus_corona-15-512.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Plot Corona Virus Cases in Countries of World (Tabular)</h2></center><br>\n",
        "Sort_By = \"total_cases\" #@param ['total_cases','total_cases_per_million', 'new_cases','new_cases_per_million','total_deaths','total_deaths_per_million', 'new_deaths','new_deaths_per_million']\n",
        "Plot_Top = 10 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "Date = \"2020-12-07\" #@param {type:\"date\"}\n",
        "\n",
        "# Date = '2020-'+Plot_Month.zfill(2)+'-'+Plot_Date.zfill(2)\n",
        "if Date not in world_dates_unique:\n",
        "  Date = World_['date'].max()\n",
        "\n",
        "display(Markdown(\"<h2> COUNTRY WISE CONFIRMED, DEATH AND CURED CASES of 2019-nCoV AS OF {}</h2>\".format(Date)))\n",
        "temp = World_[World_['location']!='World']\n",
        "temp[temp['date'] == Date][['location','total_cases','total_cases_per_million', 'new_cases','new_cases_per_million','total_deaths','total_deaths_per_million', 'new_deaths','new_deaths_per_million']]\\\n",
        "                        .sort_values(Sort_By, ascending= False).fillna(0)\\\n",
        "                        .iloc[:Plot_Top].style\\\n",
        "                        .background_gradient(cmap='YlOrBr',subset=[\"total_cases\"])\\\n",
        "                        .background_gradient(cmap='YlOrBr',subset=[\"total_cases_per_million\"])\\\n",
        "                        .background_gradient(cmap='bone_r',subset=[\"total_deaths\"])\\\n",
        "                        .background_gradient(cmap='bone',subset=[\"total_deaths_per_million\"])\\\n",
        "                        .background_gradient(cmap='Greens',subset=[\"new_cases\"])\\\n",
        "                        .background_gradient(cmap='Greens',subset=[\"new_cases_per_million\"])\\\n",
        "                        .background_gradient(cmap='Blues',subset=[\"new_deaths\"])\\\n",
        "                        .background_gradient(cmap='Blues',subset=[\"new_deaths_per_million\"])\\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "7mEXnSwflTAh"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://cdn0.iconfinder.com/data/icons/coronavirus-88/64/worldwide-global-world-virus-covid-Corona_virus-512.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Plot Corona Virus Cases in World (Bar Plot)</h2></center><br>\n",
        "\n",
        "Plot_Column = \"total_cases\" #@param ['total_cases', 'new_cases','new_cases_smoothed', 'total_deaths', 'new_deaths', 'new_deaths_smoothed', 'total_cases_per_million', 'new_cases_per_million', 'new_cases_smoothed_per_million', 'total_deaths_per_million', 'new_deaths_per_million', 'new_deaths_smoothed_per_million', 'reproduction_rate', 'icu_patients', 'icu_patients_per_million', 'hosp_patients', 'hosp_patients_per_million', 'weekly_icu_admissions', 'weekly_icu_admissions_per_million', 'weekly_hosp_admissions','weekly_hosp_admissions_per_million', 'total_tests', 'new_tests', 'total_tests_per_thousand', 'new_tests_per_thousand', 'new_tests_smoothed', 'new_tests_smoothed_per_thousand', 'tests_per_case', 'positive_rate', 'tests_units', 'stringency_index', 'population']\n",
        "#Plot_Month = \"12\" #@param ['3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
        "#Plot_Date = \"9\" #@param ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30']\n",
        "Plot_Only = 25 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "Date = \"2020-12-07\" #@param {type:\"date\"}\n",
        "\n",
        "\n",
        "# Date = '2020-'+Plot_Month.zfill(2)+'-'+Plot_Date.zfill(2)\n",
        "if Date not in world_dates_unique:\n",
        "  display(Markdown('<h5> Invalid Date Encountered.. <br>Setting Date to last Date</h5>'))\n",
        "  time.sleep(2)\n",
        "  Date = World_['date'].max()\n",
        "\n",
        "display(Markdown(\"<center><h2>Bar Plot for Top {} Countries with Highest {} of SARS-CoV-2 On {} \\n</h2></center>\".format(Plot_Only , Plot_Column.replace('_',' ').title() , Date)))\n",
        "\n",
        "state_cases = World_[World_.date == Date]\n",
        "state_cases = state_cases[state_cases['location']!='World']\n",
        "state_cases=state_cases.sort_values(Plot_Column, ascending= False)\n",
        "total_cases = state_cases[Plot_Column].sum()\n",
        "\n",
        "state_cases=state_cases.head(int(Plot_Only))\n",
        "\n",
        "plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "ax = plt.subplot(1,1,1)\n",
        "plt.suptitle(Sup_Title, fontsize = 29)\n",
        "plt.title('\\nBar Plot for Top {} Countries with Highest {} of SARS-CoV-2 On {} \\n'.format(Plot_Only , Plot_Column.replace('_',' ').title() , Date) , fontsize = 19)\n",
        "\n",
        "graph = sns.barplot(data=state_cases,y='location',x= Plot_Column , saturation = Plot_Saturation , alpha = Plot_Alpha, palette =Style_Color, label = Plot_Column+' Cases' , ci = 'sd' , orient = 'h')\n",
        "plt.xlim(0,state_cases[Plot_Column].max()+state_cases[Plot_Column].max()/10 )\n",
        "\n",
        "plt.ylabel('Countries ')\n",
        "plt.xlabel('Number of Cases')\n",
        "plt.legend(loc = 8 , fontsize = 16)\n",
        "anchored_text = AnchoredText(\"Column: {}\\nDate : {}\\nTotal Cases (Sum): {}\".format(Plot_Column,state_cases.date.unique()[0] ,int(total_cases)), borderpad=1.0, pad = 1.0, loc=7 , frameon= True )\n",
        "ax.add_artist(anchored_text)\n",
        "# plt.text(0.95, 0.01, 'colored text in axes coords',\n",
        "#         verticalalignment='bottom', horizontalalignment='right',\n",
        "#         color='green', fontsize=15)\n",
        "for p in graph.patches[:int(Plot_Only)]:\n",
        "  _x = p.get_x() + p.get_width() \n",
        "  _y = p.get_y() + p.get_height()/2 + float(0.2)\n",
        "  value = ((int(p.get_width())/total_cases)*100)\n",
        "  if np.isnan(value):\n",
        "    value = 0.0\n",
        "  graph.text(_x , _y , ' {:.2f}%'.format(value) , ha = 'left', color = sns.color_palette('rocket')[1])\n",
        "plt.subplots_adjust(top=SubPlot_Top)\n",
        "\n",
        "plt.savefig(File_Prefix+'World Bar Plot on {} _{}.{}'.format(Date , time.time() , Format_To_Save) , bbox_inches = 'tight')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GH04c8_l914"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='http://cdn.onlinewebfonts.com/svg/img_569508.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Plot Corona Virus Cases in Country with Polynomial Regression</h2></center><br>\n",
        "Plot_Column = \"new_cases\" #@param ['total_cases', 'new_cases','new_cases_smoothed', 'total_deaths', 'new_deaths', 'new_deaths_smoothed', 'total_cases_per_million', 'new_cases_per_million', 'new_cases_smoothed_per_million', 'total_deaths_per_million', 'new_deaths_per_million', 'new_deaths_smoothed_per_million', 'reproduction_rate', 'icu_patients', 'icu_patients_per_million', 'hosp_patients', 'hosp_patients_per_million', 'weekly_icu_admissions', 'weekly_icu_admissions_per_million', 'weekly_hosp_admissions','weekly_hosp_admissions_per_million', 'total_tests', 'new_tests', 'total_tests_per_thousand', 'new_tests_per_thousand', 'new_tests_smoothed', 'new_tests_smoothed_per_thousand', 'tests_per_case', 'positive_rate', 'tests_units', 'stringency_index', 'population', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand', 'life_expectancy', 'human_development_index']\n",
        "Location = \"United States\" #@param [\"Aruba\", \"Afghanistan\", \"Angola\", \"Anguilla\", \"Albania\", \"Andorra\",\"United Arab Emirates\", \"Argentina\", \"Armenia\",\"Antigua and Barbuda\", \"Australia\", \"Austria\", \"Azerbaijan\",\"Burundi\", \"Belgium\", \"Benin\", \"Bonaire Sint Eustatius and Saba\",\"Burkina Faso\", \"Bangladesh\", \"Bulgaria\", \"Bahrain\", \"Bahamas\",\"Bosnia and Herzegovina\", \"Belarus\", \"Belize\", \"Bermuda\",\"Bolivia\", \"Brazil\", \"Barbados\", \"Brunei\", \"Bhutan\", \"Botswana\",\"Central African Republic\", \"Canada\", \"Switzerland\", \"Chile\",\"China\", \"Cameroon\",\"Democratic Republic of Congo\", \"Congo\", \"Colombia\", \"Comoros\",\"Cape Verde\", \"Costa Rica\", \"Cuba\", \"Curacao\", \"Cayman Islands\",\"Cyprus\", \"Czech Republic\", \"Germany\", \"Djibouti\", \"Dominica\",\"Denmark\", \"Dominican Republic\", \"Algeria\", \"Ecuador\", \"Egypt\",\"Eritrea\", \"Western Sahara\", \"Spain\", \"Estonia\", \"Ethiopia\",\"Finland\", \"Fiji\", \"Falkland Islands\", \"France\", \"Faeroe Islands\",\"Gabon\", \"United Kingdom\", \"Georgia\", \"Guernsey\", \"Ghana\",\"Gibraltar\", \"Guinea\", \"Gambia\", \"Equatorial Guinea\", \"Greece\", \"Grenada\", \"Greenland\", \"Guatemala\",\"Guam\", \"Guyana\", \"Hong Kong\", \"Honduras\", \"Croatia\", \"Haiti\",\"Hungary\", \"Indonesia\", \"Isle of Man\", \"India\", \"Ireland\", \"Iran\",\"Iraq\", \"Iceland\", \"Israel\", \"Italy\", \"Jamaica\", \"Jersey\",\"Jordan\", \"Japan\", \"Kazakhstan\", \"Kenya\", \"Kyrgyzstan\", \"Cambodia\", \"Saint Kitts and Nevis\", \"South Korea\", \"Kuwait\", \"Laos\",\"Lebanon\", \"Liberia\", \"Libya\", \"Saint Lucia\", \"Liechtenstein\",\"Sri Lanka\", \"Lesotho\", \"Lithuania\", \"Luxembourg\", \"Latvia\",\"Morocco\", \"Monaco\", \"Moldova\", \"Madagascar\", \"Maldives\", \"Mexico\",\"Marshall Islands\", \"Macedonia\", \"Mali\", \"Malta\", \"Myanmar\",\"Montenegro\", \"Mongolia\", \"Northern Mariana Islands\", \"Mozambique\",\"Mauritania\", \"Montserrat\", \"Mauritius\", \"Malawi\", \"Malaysia\",\"Namibia\", \"New Caledonia\", \"Niger\", \"Nigeria\", \"Nicaragua\",\"Netherlands\", \"Norway\", \"Nepal\", \"New Zealand\", \"Oman\",\"Pakistan\", \"Panama\", \"Peru\", \"Philippines\", \"Papua New Guinea\",\"Poland\", \"Puerto Rico\", \"Portugal\", \"Paraguay\", \"Palestine\",\"French Polynesia\", \"Qatar\", \"Romania\", \"Russia\", \"Rwanda\",\"Saudi Arabia\", \"Sudan\", \"Senegal\", \"Singapore\", \"Solomon Islands\",\"Sierra Leone\", \"El Salvador\", \"San Marino\", \"Somalia\", \"Serbia\",\"South Sudan\", \"Sao Tome and Principe\", \"Suriname\", \"Slovakia\",\"Slovenia\", \"Sweden\", \"Swaziland\" ,\"Seychelles\", \"Syria\", \"Turks and Caicos Islands\", \"Chad\", \"Togo\",\"Thailand\", \"Tajikistan\", \"Timor\", \"Trinidad and Tobago\",\"Tunisia\", \"Turkey\", \"Taiwan\", \"Tanzania\", \"Uganda\", \"Ukraine\",\"Uruguay\", \"United States\", \"Uzbekistan\", \"Vatican\",\"Saint Vincent and the Grenadines\", \"Venezuela\",\"British Virgin Islands\", \"United States Virgin Islands\",\"Vietnam\", \"Vanuatu\", \"Wallis and Futuna\", \"Kosovo\", \"Yemen\",\"South Africa\", \"Zambia\", \"Zimbabwe\", \"World\", \"International\"]\n",
        "Apply_Rolling_Mean = 4 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "Regression_Power = 4 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "Train_on_days_from = 20 #@param {type:\"slider\", min:20, max:300, step:1}\n",
        "Predict_of_future_days = 15 #@param {type:\"slider\", min:0, max:200, step:1}\n",
        "Plot_Lib = \"MatplotLib\" #@param [\"Plotly\", \"MatplotLib\"]\n",
        "Bar_Plot = 25 #@param {type:\"slider\", min:0, max:30, step:1}\n",
        "Line_Plot = True #@param {type:\"boolean\"}\n",
        "Use_Log = True #@param {type:\"boolean\"}\n",
        "Date = 'date'\n",
        "display(Markdown(\"<center><h2>Time Series Plot of {} for {} of SARS-CoV-2 \\n</h2></center>\".format(Location , Plot_Column.replace('_',' ').title())))\n",
        "\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=2).as_hex())\n",
        "data = World_[World_.location == Location]\n",
        "times = pd.date_range(data[Date].min(), periods = data.shape[0]+Predict_of_future_days , freq='D')\n",
        "\n",
        "if Use_Log:\n",
        "  data[Plot_Column] = np.log1p(data[Plot_Column])\n",
        "bar_data = data.resample('M').mean()\n",
        "if Plot_Lib == 'MatplotLib':\n",
        "  plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "\n",
        "  # Bar Plot\n",
        "  if Bar_Plot:\n",
        "    plt.bar(bar_data.index,bar_data[Plot_Column], align = 'edge',width = -Bar_Plot , linewidth = 0 , color = list(sns.color_palette(Style_Color,n_colors=len(bar_data[Plot_Column].values)).as_hex()) , alpha = .9 ,label = 'Monthly Average')\n",
        "  #Applying Rolling Mean\n",
        "  if Apply_Rolling_Mean > 1:\n",
        "    data[Plot_Column] = data[Plot_Column].rolling(Apply_Rolling_Mean, min_periods = 1).mean()\n",
        "  # Line Plot of Data\n",
        "  if Line_Plot:\n",
        "    plt.plot(data[Plot_Column], label = 'Confirmed {} (per day)'.format(Plot_Column.replace('_',' ').title()) , color = plot_color[0] )\n",
        "  # Applying Regression Power\n",
        "  if Regression_Power:\n",
        "    model = np.poly1d(np.polyfit(data['Days_Passed'].values[Train_on_days_from-20:], data[Plot_Column].values[Train_on_days_from-20:], Regression_Power))\n",
        "    polyline = np.linspace(Train_on_days_from, World_['Days_Passed'].max()+Predict_of_future_days, len(times[Train_on_days_from:])) \n",
        "    plt.plot( pd.Series([0 if i<0 else i for i in model(polyline)] , index = times[Train_on_days_from:])  , label = 'Predicted {} Cases'.format(Plot_Column.replace('_',' ').title()) , color = plot_color[1])\n",
        "\n",
        "  plt.suptitle(Sup_Title, fontsize = 29)\n",
        "  plt.title('{} Cases In {} of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' ').title() , Location ) , fontsize = 19)\n",
        "  plt.legend()\n",
        "  plt.ylabel('Cases')\n",
        "  plt.xlabel('Days Passed Since {}'.format(World_['date'].min()))\n",
        "  plt.subplots_adjust(top=SubPlot_Top)\n",
        "\n",
        "  plt.savefig(File_Prefix+'{} Regression  Plot on {} _{}.{}'.format(Location,World_.date.max() , time.time() , Format_To_Save) , bbox_inches = 'tight')\n",
        "else:\n",
        "  fig=go.Figure()\n",
        "  if Regression_Power:\n",
        "    model = np.poly1d(np.polyfit(data['Days_Passed'].values[Train_on_days_from-20:], data[Plot_Column].values[Train_on_days_from-20:], Regression_Power))\n",
        "    polyline = np.linspace(Train_on_days_from, World_['Days_Passed'].max()+Predict_of_future_days, len(times[Train_on_days_from:])) \n",
        "    reg_plot = pd.Series([0 if i<0 else i for i in model(polyline)] , index = times[Train_on_days_from:])  \n",
        "    # fig.add_trace(go.Scatter(x = reg_plot.index , y = reg_plot , mode = 'lines' ))\n",
        "    fig.add_trace(go.Scatter(x = reg_plot.index ,y = reg_plot , mode = 'lines' , name = ' Fitted Line on {} '.format(Plot_Column.replace('_',' ').title())))\n",
        "  if Apply_Rolling_Mean > 1:\n",
        "    data[Plot_Column] = data[Plot_Column].rolling(Apply_Rolling_Mean, min_periods = 1).mean()\n",
        "  fig.add_trace(go.Scatter(x = data.index , y = data[Plot_Column] , mode = 'lines' , name = '{} Cases'.format(Plot_Column.replace('_',' ').title() ) ) )\n",
        "  if Bar_Plot:\n",
        "    fig.add_trace(go.Bar(x = bar_data.index,y = bar_data[Plot_Column] , name = 'Monthly Average', marker=dict(color = list(sns.color_palette(Style_Color,n_colors=len(bar_data[Plot_Column].values)).as_hex()))))\n",
        "  fig.update_layout(title='{} Cases In {} of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' ').title() , Location ),\n",
        "                  xaxis_title='Days Passed Since {}'.format(data[Date].min()),yaxis_title=\"Cases\",legend=dict(x=0,y=1,traceorder=\"normal\"),\n",
        "                  height =Graphs_Height*96/3)\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "FX6DHz2cTFXt"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://cdn1.iconfinder.com/data/icons/life-of-amazon-outline/340/brazil_map_amazon_country_travel_ocean-256.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Plot Corona Virus Cases in 5 Countries</h2></center><br>\n",
        "Plot_Column = \"stringency_index\" #@param ['total_cases', 'new_cases','new_cases_smoothed', 'total_deaths', 'new_deaths', 'new_deaths_smoothed', 'total_cases_per_million', 'new_cases_per_million', 'new_cases_smoothed_per_million', 'total_deaths_per_million', 'new_deaths_per_million', 'new_deaths_smoothed_per_million', 'reproduction_rate', 'icu_patients', 'icu_patients_per_million', 'hosp_patients', 'hosp_patients_per_million', 'weekly_icu_admissions', 'weekly_icu_admissions_per_million', 'weekly_hosp_admissions','weekly_hosp_admissions_per_million', 'total_tests', 'new_tests', 'total_tests_per_thousand', 'new_tests_per_thousand', 'new_tests_smoothed', 'new_tests_smoothed_per_thousand', 'tests_per_case', 'positive_rate', 'tests_units', 'stringency_index', 'population', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand', 'life_expectancy', 'human_development_index']\n",
        "Apply_Rolling_Mean = 4 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "Location_1 = \"Pakistan\" #@param [\"None\" ,\"Aruba\", \"Afghanistan\", \"Angola\", \"Anguilla\", \"Albania\", \"Andorra\",\"United Arab Emirates\", \"Argentina\", \"Armenia\",\"Antigua and Barbuda\", \"Australia\", \"Austria\", \"Azerbaijan\",\"Burundi\", \"Belgium\", \"Benin\", \"Bonaire Sint Eustatius and Saba\",\"Burkina Faso\", \"Bangladesh\", \"Bulgaria\", \"Bahrain\", \"Bahamas\",\"Bosnia and Herzegovina\", \"Belarus\", \"Belize\", \"Bermuda\",\"Bolivia\", \"Brazil\", \"Barbados\", \"Brunei\", \"Bhutan\", \"Botswana\",\"Central African Republic\", \"Canada\", \"Switzerland\", \"Chile\",\"China\", \"Cameroon\",\"Democratic Republic of Congo\", \"Congo\", \"Colombia\", \"Comoros\",\"Cape Verde\", \"Costa Rica\", \"Cuba\", \"Curacao\", \"Cayman Islands\",\"Cyprus\", \"Czech Republic\", \"Germany\", \"Djibouti\", \"Dominica\",\"Denmark\", \"Dominican Republic\", \"Algeria\", \"Ecuador\", \"Egypt\",\"Eritrea\", \"Western Sahara\", \"Spain\", \"Estonia\", \"Ethiopia\",\"Finland\", \"Fiji\", \"Falkland Islands\", \"France\", \"Faeroe Islands\",\"Gabon\", \"United Kingdom\", \"Georgia\", \"Guernsey\", \"Ghana\",\"Gibraltar\", \"Guinea\", \"Gambia\", \"Equatorial Guinea\", \"Greece\", \"Grenada\", \"Greenland\", \"Guatemala\",\"Guam\", \"Guyana\", \"Hong Kong\", \"Honduras\", \"Croatia\", \"Haiti\",\"Hungary\", \"Indonesia\", \"Isle of Man\", \"India\", \"Ireland\", \"Iran\",\"Iraq\", \"Iceland\", \"Israel\", \"Italy\", \"Jamaica\", \"Jersey\",\"Jordan\", \"Japan\", \"Kazakhstan\", \"Kenya\", \"Kyrgyzstan\", \"Cambodia\", \"Saint Kitts and Nevis\", \"South Korea\", \"Kuwait\", \"Laos\",\"Lebanon\", \"Liberia\", \"Libya\", \"Saint Lucia\", \"Liechtenstein\",\"Sri Lanka\", \"Lesotho\", \"Lithuania\", \"Luxembourg\", \"Latvia\",\"Morocco\", \"Monaco\", \"Moldova\", \"Madagascar\", \"Maldives\", \"Mexico\",\"Marshall Islands\", \"Macedonia\", \"Mali\", \"Malta\", \"Myanmar\",\"Montenegro\", \"Mongolia\", \"Northern Mariana Islands\", \"Mozambique\",\"Mauritania\", \"Montserrat\", \"Mauritius\", \"Malawi\", \"Malaysia\",\"Namibia\", \"New Caledonia\", \"Niger\", \"Nigeria\", \"Nicaragua\",\"Netherlands\", \"Norway\", \"Nepal\", \"New Zealand\", \"Oman\",\"Pakistan\", \"Panama\", \"Peru\", \"Philippines\", \"Papua New Guinea\",\"Poland\", \"Puerto Rico\", \"Portugal\", \"Paraguay\", \"Palestine\",\"French Polynesia\", \"Qatar\", \"Romania\", \"Russia\", \"Rwanda\",\"Saudi Arabia\", \"Sudan\", \"Senegal\", \"Singapore\", \"Solomon Islands\",\"Sierra Leone\", \"El Salvador\", \"San Marino\", \"Somalia\", \"Serbia\",\"South Sudan\", \"Sao Tome and Principe\", \"Suriname\", \"Slovakia\",\"Slovenia\", \"Sweden\", \"Swaziland\" ,\"Seychelles\", \"Syria\", \"Turks and Caicos Islands\", \"Chad\", \"Togo\",\"Thailand\", \"Tajikistan\", \"Timor\", \"Trinidad and Tobago\",\"Tunisia\", \"Turkey\", \"Taiwan\", \"Tanzania\", \"Uganda\", \"Ukraine\",\"Uruguay\", \"United States\", \"Uzbekistan\", \"Vatican\",\"Saint Vincent and the Grenadines\", \"Venezuela\",\"British Virgin Islands\", \"United States Virgin Islands\",\"Vietnam\", \"Vanuatu\", \"Wallis and Futuna\", \"Kosovo\", \"Yemen\",\"South Africa\", \"Zambia\", \"Zimbabwe\", \"World\", \"International\"]\n",
        "Location_2 = \"United States\" #@param [\"None\" ,\"Aruba\", \"Afghanistan\", \"Angola\", \"Anguilla\", \"Albania\", \"Andorra\",\"United Arab Emirates\", \"Argentina\", \"Armenia\",\"Antigua and Barbuda\", \"Australia\", \"Austria\", \"Azerbaijan\",\"Burundi\", \"Belgium\", \"Benin\", \"Bonaire Sint Eustatius and Saba\",\"Burkina Faso\", \"Bangladesh\", \"Bulgaria\", \"Bahrain\", \"Bahamas\",\"Bosnia and Herzegovina\", \"Belarus\", \"Belize\", \"Bermuda\",\"Bolivia\", \"Brazil\", \"Barbados\", \"Brunei\", \"Bhutan\", \"Botswana\",\"Central African Republic\", \"Canada\", \"Switzerland\", \"Chile\",\"China\", \"Cameroon\",\"Democratic Republic of Congo\", \"Congo\", \"Colombia\", \"Comoros\",\"Cape Verde\", \"Costa Rica\", \"Cuba\", \"Curacao\", \"Cayman Islands\",\"Cyprus\", \"Czech Republic\", \"Germany\", \"Djibouti\", \"Dominica\",\"Denmark\", \"Dominican Republic\", \"Algeria\", \"Ecuador\", \"Egypt\",\"Eritrea\", \"Western Sahara\", \"Spain\", \"Estonia\", \"Ethiopia\",\"Finland\", \"Fiji\", \"Falkland Islands\", \"France\", \"Faeroe Islands\",\"Gabon\", \"United Kingdom\", \"Georgia\", \"Guernsey\", \"Ghana\",\"Gibraltar\", \"Guinea\", \"Gambia\", \"Equatorial Guinea\", \"Greece\", \"Grenada\", \"Greenland\", \"Guatemala\",\"Guam\", \"Guyana\", \"Hong Kong\", \"Honduras\", \"Croatia\", \"Haiti\",\"Hungary\", \"Indonesia\", \"Isle of Man\", \"India\", \"Ireland\", \"Iran\",\"Iraq\", \"Iceland\", \"Israel\", \"Italy\", \"Jamaica\", \"Jersey\",\"Jordan\", \"Japan\", \"Kazakhstan\", \"Kenya\", \"Kyrgyzstan\", \"Cambodia\", \"Saint Kitts and Nevis\", \"South Korea\", \"Kuwait\", \"Laos\",\"Lebanon\", \"Liberia\", \"Libya\", \"Saint Lucia\", \"Liechtenstein\",\"Sri Lanka\", \"Lesotho\", \"Lithuania\", \"Luxembourg\", \"Latvia\",\"Morocco\", \"Monaco\", \"Moldova\", \"Madagascar\", \"Maldives\", \"Mexico\",\"Marshall Islands\", \"Macedonia\", \"Mali\", \"Malta\", \"Myanmar\",\"Montenegro\", \"Mongolia\", \"Northern Mariana Islands\", \"Mozambique\",\"Mauritania\", \"Montserrat\", \"Mauritius\", \"Malawi\", \"Malaysia\",\"Namibia\", \"New Caledonia\", \"Niger\", \"Nigeria\", \"Nicaragua\",\"Netherlands\", \"Norway\", \"Nepal\", \"New Zealand\", \"Oman\",\"Pakistan\", \"Panama\", \"Peru\", \"Philippines\", \"Papua New Guinea\",\"Poland\", \"Puerto Rico\", \"Portugal\", \"Paraguay\", \"Palestine\",\"French Polynesia\", \"Qatar\", \"Romania\", \"Russia\", \"Rwanda\",\"Saudi Arabia\", \"Sudan\", \"Senegal\", \"Singapore\", \"Solomon Islands\",\"Sierra Leone\", \"El Salvador\", \"San Marino\", \"Somalia\", \"Serbia\",\"South Sudan\", \"Sao Tome and Principe\", \"Suriname\", \"Slovakia\",\"Slovenia\", \"Sweden\", \"Swaziland\" ,\"Seychelles\", \"Syria\", \"Turks and Caicos Islands\", \"Chad\", \"Togo\",\"Thailand\", \"Tajikistan\", \"Timor\", \"Trinidad and Tobago\",\"Tunisia\", \"Turkey\", \"Taiwan\", \"Tanzania\", \"Uganda\", \"Ukraine\",\"Uruguay\", \"United States\", \"Uzbekistan\", \"Vatican\",\"Saint Vincent and the Grenadines\", \"Venezuela\",\"British Virgin Islands\", \"United States Virgin Islands\",\"Vietnam\", \"Vanuatu\", \"Wallis and Futuna\", \"Kosovo\", \"Yemen\",\"South Africa\", \"Zambia\", \"Zimbabwe\", \"World\", \"International\"]\n",
        "Location_3 = \"India\" #@param [\"None\" ,\"Aruba\", \"Afghanistan\", \"Angola\", \"Anguilla\", \"Albania\", \"Andorra\",\"United Arab Emirates\", \"Argentina\", \"Armenia\",\"Antigua and Barbuda\", \"Australia\", \"Austria\", \"Azerbaijan\",\"Burundi\", \"Belgium\", \"Benin\", \"Bonaire Sint Eustatius and Saba\",\"Burkina Faso\", \"Bangladesh\", \"Bulgaria\", \"Bahrain\", \"Bahamas\",\"Bosnia and Herzegovina\", \"Belarus\", \"Belize\", \"Bermuda\",\"Bolivia\", \"Brazil\", \"Barbados\", \"Brunei\", \"Bhutan\", \"Botswana\",\"Central African Republic\", \"Canada\", \"Switzerland\", \"Chile\",\"China\", \"Cameroon\",\"Democratic Republic of Congo\", \"Congo\", \"Colombia\", \"Comoros\",\"Cape Verde\", \"Costa Rica\", \"Cuba\", \"Curacao\", \"Cayman Islands\",\"Cyprus\", \"Czech Republic\", \"Germany\", \"Djibouti\", \"Dominica\",\"Denmark\", \"Dominican Republic\", \"Algeria\", \"Ecuador\", \"Egypt\",\"Eritrea\", \"Western Sahara\", \"Spain\", \"Estonia\", \"Ethiopia\",\"Finland\", \"Fiji\", \"Falkland Islands\", \"France\", \"Faeroe Islands\",\"Gabon\", \"United Kingdom\", \"Georgia\", \"Guernsey\", \"Ghana\",\"Gibraltar\", \"Guinea\", \"Gambia\", \"Equatorial Guinea\", \"Greece\", \"Grenada\", \"Greenland\", \"Guatemala\",\"Guam\", \"Guyana\", \"Hong Kong\", \"Honduras\", \"Croatia\", \"Haiti\",\"Hungary\", \"Indonesia\", \"Isle of Man\", \"India\", \"Ireland\", \"Iran\",\"Iraq\", \"Iceland\", \"Israel\", \"Italy\", \"Jamaica\", \"Jersey\",\"Jordan\", \"Japan\", \"Kazakhstan\", \"Kenya\", \"Kyrgyzstan\", \"Cambodia\", \"Saint Kitts and Nevis\", \"South Korea\", \"Kuwait\", \"Laos\",\"Lebanon\", \"Liberia\", \"Libya\", \"Saint Lucia\", \"Liechtenstein\",\"Sri Lanka\", \"Lesotho\", \"Lithuania\", \"Luxembourg\", \"Latvia\",\"Morocco\", \"Monaco\", \"Moldova\", \"Madagascar\", \"Maldives\", \"Mexico\",\"Marshall Islands\", \"Macedonia\", \"Mali\", \"Malta\", \"Myanmar\",\"Montenegro\", \"Mongolia\", \"Northern Mariana Islands\", \"Mozambique\",\"Mauritania\", \"Montserrat\", \"Mauritius\", \"Malawi\", \"Malaysia\",\"Namibia\", \"New Caledonia\", \"Niger\", \"Nigeria\", \"Nicaragua\",\"Netherlands\", \"Norway\", \"Nepal\", \"New Zealand\", \"Oman\",\"Pakistan\", \"Panama\", \"Peru\", \"Philippines\", \"Papua New Guinea\",\"Poland\", \"Puerto Rico\", \"Portugal\", \"Paraguay\", \"Palestine\",\"French Polynesia\", \"Qatar\", \"Romania\", \"Russia\", \"Rwanda\",\"Saudi Arabia\", \"Sudan\", \"Senegal\", \"Singapore\", \"Solomon Islands\",\"Sierra Leone\", \"El Salvador\", \"San Marino\", \"Somalia\", \"Serbia\",\"South Sudan\", \"Sao Tome and Principe\", \"Suriname\", \"Slovakia\",\"Slovenia\", \"Sweden\", \"Swaziland\" ,\"Seychelles\", \"Syria\", \"Turks and Caicos Islands\", \"Chad\", \"Togo\",\"Thailand\", \"Tajikistan\", \"Timor\", \"Trinidad and Tobago\",\"Tunisia\", \"Turkey\", \"Taiwan\", \"Tanzania\", \"Uganda\", \"Ukraine\",\"Uruguay\", \"United States\", \"Uzbekistan\", \"Vatican\",\"Saint Vincent and the Grenadines\", \"Venezuela\",\"British Virgin Islands\", \"United States Virgin Islands\",\"Vietnam\", \"Vanuatu\", \"Wallis and Futuna\", \"Kosovo\", \"Yemen\",\"South Africa\", \"Zambia\", \"Zimbabwe\", \"World\", \"International\"]\n",
        "Location_4 = \"United Kingdom\" #@param [\"None\" ,\"Aruba\", \"Afghanistan\", \"Angola\", \"Anguilla\", \"Albania\", \"Andorra\",\"United Arab Emirates\", \"Argentina\", \"Armenia\",\"Antigua and Barbuda\", \"Australia\", \"Austria\", \"Azerbaijan\",\"Burundi\", \"Belgium\", \"Benin\", \"Bonaire Sint Eustatius and Saba\",\"Burkina Faso\", \"Bangladesh\", \"Bulgaria\", \"Bahrain\", \"Bahamas\",\"Bosnia and Herzegovina\", \"Belarus\", \"Belize\", \"Bermuda\",\"Bolivia\", \"Brazil\", \"Barbados\", \"Brunei\", \"Bhutan\", \"Botswana\",\"Central African Republic\", \"Canada\", \"Switzerland\", \"Chile\",\"China\", \"Cameroon\",\"Democratic Republic of Congo\", \"Congo\", \"Colombia\", \"Comoros\",\"Cape Verde\", \"Costa Rica\", \"Cuba\", \"Curacao\", \"Cayman Islands\",\"Cyprus\", \"Czech Republic\", \"Germany\", \"Djibouti\", \"Dominica\",\"Denmark\", \"Dominican Republic\", \"Algeria\", \"Ecuador\", \"Egypt\",\"Eritrea\", \"Western Sahara\", \"Spain\", \"Estonia\", \"Ethiopia\",\"Finland\", \"Fiji\", \"Falkland Islands\", \"France\", \"Faeroe Islands\",\"Gabon\", \"United Kingdom\", \"Georgia\", \"Guernsey\", \"Ghana\",\"Gibraltar\", \"Guinea\", \"Gambia\", \"Equatorial Guinea\", \"Greece\", \"Grenada\", \"Greenland\", \"Guatemala\",\"Guam\", \"Guyana\", \"Hong Kong\", \"Honduras\", \"Croatia\", \"Haiti\",\"Hungary\", \"Indonesia\", \"Isle of Man\", \"India\", \"Ireland\", \"Iran\",\"Iraq\", \"Iceland\", \"Israel\", \"Italy\", \"Jamaica\", \"Jersey\",\"Jordan\", \"Japan\", \"Kazakhstan\", \"Kenya\", \"Kyrgyzstan\", \"Cambodia\", \"Saint Kitts and Nevis\", \"South Korea\", \"Kuwait\", \"Laos\",\"Lebanon\", \"Liberia\", \"Libya\", \"Saint Lucia\", \"Liechtenstein\",\"Sri Lanka\", \"Lesotho\", \"Lithuania\", \"Luxembourg\", \"Latvia\",\"Morocco\", \"Monaco\", \"Moldova\", \"Madagascar\", \"Maldives\", \"Mexico\",\"Marshall Islands\", \"Macedonia\", \"Mali\", \"Malta\", \"Myanmar\",\"Montenegro\", \"Mongolia\", \"Northern Mariana Islands\", \"Mozambique\",\"Mauritania\", \"Montserrat\", \"Mauritius\", \"Malawi\", \"Malaysia\",\"Namibia\", \"New Caledonia\", \"Niger\", \"Nigeria\", \"Nicaragua\",\"Netherlands\", \"Norway\", \"Nepal\", \"New Zealand\", \"Oman\",\"Pakistan\", \"Panama\", \"Peru\", \"Philippines\", \"Papua New Guinea\",\"Poland\", \"Puerto Rico\", \"Portugal\", \"Paraguay\", \"Palestine\",\"French Polynesia\", \"Qatar\", \"Romania\", \"Russia\", \"Rwanda\",\"Saudi Arabia\", \"Sudan\", \"Senegal\", \"Singapore\", \"Solomon Islands\",\"Sierra Leone\", \"El Salvador\", \"San Marino\", \"Somalia\", \"Serbia\",\"South Sudan\", \"Sao Tome and Principe\", \"Suriname\", \"Slovakia\",\"Slovenia\", \"Sweden\", \"Swaziland\" ,\"Seychelles\", \"Syria\", \"Turks and Caicos Islands\", \"Chad\", \"Togo\",\"Thailand\", \"Tajikistan\", \"Timor\", \"Trinidad and Tobago\",\"Tunisia\", \"Turkey\", \"Taiwan\", \"Tanzania\", \"Uganda\", \"Ukraine\",\"Uruguay\", \"United States\", \"Uzbekistan\", \"Vatican\",\"Saint Vincent and the Grenadines\", \"Venezuela\",\"British Virgin Islands\", \"United States Virgin Islands\",\"Vietnam\", \"Vanuatu\", \"Wallis and Futuna\", \"Kosovo\", \"Yemen\",\"South Africa\", \"Zambia\", \"Zimbabwe\", \"World\", \"International\"]\n",
        "Location_5 = \"China\" #@param [\"None\" ,\"Aruba\", \"Afghanistan\", \"Angola\", \"Anguilla\", \"Albania\", \"Andorra\",\"United Arab Emirates\", \"Argentina\", \"Armenia\",\"Antigua and Barbuda\", \"Australia\", \"Austria\", \"Azerbaijan\",\"Burundi\", \"Belgium\", \"Benin\", \"Bonaire Sint Eustatius and Saba\",\"Burkina Faso\", \"Bangladesh\", \"Bulgaria\", \"Bahrain\", \"Bahamas\",\"Bosnia and Herzegovina\", \"Belarus\", \"Belize\", \"Bermuda\",\"Bolivia\", \"Brazil\", \"Barbados\", \"Brunei\", \"Bhutan\", \"Botswana\",\"Central African Republic\", \"Canada\", \"Switzerland\", \"Chile\",\"China\", \"Cameroon\",\"Democratic Republic of Congo\", \"Congo\", \"Colombia\", \"Comoros\",\"Cape Verde\", \"Costa Rica\", \"Cuba\", \"Curacao\", \"Cayman Islands\",\"Cyprus\", \"Czech Republic\", \"Germany\", \"Djibouti\", \"Dominica\",\"Denmark\", \"Dominican Republic\", \"Algeria\", \"Ecuador\", \"Egypt\",\"Eritrea\", \"Western Sahara\", \"Spain\", \"Estonia\", \"Ethiopia\",\"Finland\", \"Fiji\", \"Falkland Islands\", \"France\", \"Faeroe Islands\",\"Gabon\", \"United Kingdom\", \"Georgia\", \"Guernsey\", \"Ghana\",\"Gibraltar\", \"Guinea\", \"Gambia\", \"Equatorial Guinea\", \"Greece\", \"Grenada\", \"Greenland\", \"Guatemala\",\"Guam\", \"Guyana\", \"Hong Kong\", \"Honduras\", \"Croatia\", \"Haiti\",\"Hungary\", \"Indonesia\", \"Isle of Man\", \"India\", \"Ireland\", \"Iran\",\"Iraq\", \"Iceland\", \"Israel\", \"Italy\", \"Jamaica\", \"Jersey\",\"Jordan\", \"Japan\", \"Kazakhstan\", \"Kenya\", \"Kyrgyzstan\", \"Cambodia\", \"Saint Kitts and Nevis\", \"South Korea\", \"Kuwait\", \"Laos\",\"Lebanon\", \"Liberia\", \"Libya\", \"Saint Lucia\", \"Liechtenstein\",\"Sri Lanka\", \"Lesotho\", \"Lithuania\", \"Luxembourg\", \"Latvia\",\"Morocco\", \"Monaco\", \"Moldova\", \"Madagascar\", \"Maldives\", \"Mexico\",\"Marshall Islands\", \"Macedonia\", \"Mali\", \"Malta\", \"Myanmar\",\"Montenegro\", \"Mongolia\", \"Northern Mariana Islands\", \"Mozambique\",\"Mauritania\", \"Montserrat\", \"Mauritius\", \"Malawi\", \"Malaysia\",\"Namibia\", \"New Caledonia\", \"Niger\", \"Nigeria\", \"Nicaragua\",\"Netherlands\", \"Norway\", \"Nepal\", \"New Zealand\", \"Oman\",\"Pakistan\", \"Panama\", \"Peru\", \"Philippines\", \"Papua New Guinea\",\"Poland\", \"Puerto Rico\", \"Portugal\", \"Paraguay\", \"Palestine\",\"French Polynesia\", \"Qatar\", \"Romania\", \"Russia\", \"Rwanda\",\"Saudi Arabia\", \"Sudan\", \"Senegal\", \"Singapore\", \"Solomon Islands\",\"Sierra Leone\", \"El Salvador\", \"San Marino\", \"Somalia\", \"Serbia\",\"South Sudan\", \"Sao Tome and Principe\", \"Suriname\", \"Slovakia\",\"Slovenia\", \"Sweden\", \"Swaziland\" ,\"Seychelles\", \"Syria\", \"Turks and Caicos Islands\", \"Chad\", \"Togo\",\"Thailand\", \"Tajikistan\", \"Timor\", \"Trinidad and Tobago\",\"Tunisia\", \"Turkey\", \"Taiwan\", \"Tanzania\", \"Uganda\", \"Ukraine\",\"Uruguay\", \"United States\", \"Uzbekistan\", \"Vatican\",\"Saint Vincent and the Grenadines\", \"Venezuela\",\"British Virgin Islands\", \"United States Virgin Islands\",\"Vietnam\", \"Vanuatu\", \"Wallis and Futuna\", \"Kosovo\", \"Yemen\",\"South Africa\", \"Zambia\", \"Zimbabwe\", \"World\", \"International\"]\n",
        "Plot_Lib = \"MatplotLib\" #@param [\"Plotly\", \"MatplotLib\"]\n",
        "Fill_Alpha = 0.13 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "Use_Log = False #@param {type:\"boolean\"}\n",
        "\n",
        "Locations = [Location_1 ,Location_2 ,Location_3 ,Location_4 ,Location_5]\n",
        "Date = 'date'\n",
        "\n",
        "display(Markdown(\"<center><h2>Time Series Plot of 5 Countries for {} of SARS-CoV-2 On {} \\n</h2></center>\".format(Plot_Column.replace('_',' ').title() , World_.date.max())))\n",
        "\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=len(Locations)).as_hex())\n",
        "\n",
        "if Plot_Lib == 'MatplotLib':\n",
        "  plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "\n",
        "  for i,Location in enumerate(Locations):\n",
        "    if Location in World_.location.unique():\n",
        "      data = World_[World_.location == Location]\n",
        "      data[Plot_Column] = data[Plot_Column].rolling(Apply_Rolling_Mean , min_periods = 1).mean()\n",
        "      if Use_Log:\n",
        "        data[Plot_Column] = np.log1p(data[Plot_Column])\n",
        "      plt.plot(data[Plot_Column], label = '{}'.format(Location) , color = plot_color[i] )\n",
        "      plt.fill_between(data.index , 0 , data[Plot_Column], color =  plot_color[i] , alpha = Fill_Alpha)\n",
        "  plt.suptitle(Sup_Title, fontsize = 29)\n",
        "  plt.title('Most Effected Countries with {} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' ').title() ) , fontsize = 19)\n",
        "  plt.legend()\n",
        "  if Use_Log:\n",
        "    plt.ylabel('Cases (After Log)')\n",
        "  else:\n",
        "    plt.ylabel('Cases')\n",
        "  plt.xlabel('Days Passed Since {}'.format(World_.date.min()))\n",
        "  plt.subplots_adjust(top=SubPlot_Top)\n",
        "  plt.savefig(File_Prefix+'5 Countries Regression  Plot on {} _{}.{}'.format(World_.date.max() , time.time() , Format_To_Save) , bbox_inches = 'tight')\n",
        "\n",
        "else:\n",
        "  fig=go.Figure()\n",
        "  # go.update_layout( )\n",
        "  for i,Location in enumerate(Locations):\n",
        "    if Location in World_.location.unique():\n",
        "      data = World_[World_.location == Location]\n",
        "      data[Plot_Column] = data[Plot_Column].rolling(Apply_Rolling_Mean , min_periods = 1).mean()\n",
        "      if Use_Log:\n",
        "        data[Plot_Column] = np.log1p(data[Plot_Column])\n",
        "      fig.add_trace(go.Scatter(x = data.index , y = data[Plot_Column] , mode = 'lines' ,  name = '{}'.format(Location) ) )\n",
        "  fig.update_layout(title='{} Cases In {} of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' ').title() , Location ),\n",
        "                  xaxis_title='Days Passed Since {}'.format(data[Date].min()),yaxis_title=\"Cases\",legend=dict(x=0,y=1,traceorder=\"normal\"),\n",
        "                  height =Graphs_Height*96/3)\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "kk0AiQZso1bE"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://assets.website-files.com/5d9ba0eb5f6edb77992a99d0/5e62506c9394b24aa66cf385_iconfinder_connection-route-spread-virus-global_5728179.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Time Series Plot of Corona Virus Cases in Top Countries</h2></center><br>\n",
        "Plot_Column = \"stringency_index\" #@param ['total_cases', 'new_cases','new_cases_smoothed', 'total_deaths', 'new_deaths', 'new_deaths_smoothed', 'total_cases_per_million', 'new_cases_per_million', 'new_cases_smoothed_per_million', 'total_deaths_per_million', 'new_deaths_per_million', 'new_deaths_smoothed_per_million', 'reproduction_rate', 'icu_patients', 'icu_patients_per_million', 'hosp_patients', 'hosp_patients_per_million', 'weekly_icu_admissions', 'weekly_icu_admissions_per_million', 'weekly_hosp_admissions','weekly_hosp_admissions_per_million', 'total_tests', 'new_tests', 'total_tests_per_thousand', 'new_tests_per_thousand', 'new_tests_smoothed', 'new_tests_smoothed_per_thousand', 'tests_per_case', 'positive_rate', 'tests_units', 'stringency_index', 'population', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand', 'life_expectancy', 'human_development_index']\n",
        "Use_Method = \"mean\" #@param [\"sum\", \"mean\", \"max\", \"median\", \"min\", \"std\", \"var\"]\n",
        "Plot_top = 8 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "Apply_Rolling_Mean = 9 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "Plot_Lib = \"Plotly\" #@param [\"Plotly\", \"MatplotLib\"]\n",
        "Fill_Alpha = 0.13 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "Use_Log = False #@param {type:\"boolean\"}\n",
        "Date = 'date'\n",
        "Locations = World_.groupby('location').agg({Plot_Column:Use_Method}).sort_values(by=[Plot_Column] , ascending = False).reset_index()['location'].head(Plot_top+1).values\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=len(Locations)*2).as_hex())\n",
        "\n",
        "display(Markdown(\"<center><h2>Time Series Plot of Top Countries for {} of SARS-CoV-2  \\n</h2></center>\".format(Plot_Column.replace('_',' ').title())))\n",
        "\n",
        "if Plot_Lib == 'MatplotLib':\n",
        "  plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  for i,Location in enumerate(Locations):\n",
        "    if Location in World_.location.unique() and Location != 'World' :\n",
        "      data = World_[World_.location == Location]\n",
        "      data[Plot_Column] = data[Plot_Column].rolling(Apply_Rolling_Mean, min_periods = 1).mean()\n",
        "\n",
        "      if Use_Log:\n",
        "        data[Plot_Column] = np.log1p(data[Plot_Column])\n",
        "      if Fill_Alpha:\n",
        "        plt.fill_between(data.index , 0 , data[Plot_Column], color =  plot_color[i] , alpha = Fill_Alpha)\n",
        "      plt.plot(data.index , data[Plot_Column], label = '{}'.format(Location) , color = plot_color[i*2] )\n",
        "\n",
        "  plt.suptitle(Sup_Title, fontsize = 29)\n",
        "  plt.title('{} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' ').title() ) , fontsize = 19)\n",
        "  plt.legend()\n",
        "  plt.ylabel('Cases')\n",
        "  plt.xlabel('Days Passed Since {}'.format(World_.date.min()))\n",
        "  plt.subplots_adjust(top=SubPlot_Top)\n",
        "  plt.savefig(File_Prefix+'Top Countries Regression  Plot on {} _{}.{}'.format(World_.date.max() , time.time() , Format_To_Save) , bbox_inches = 'tight')\n",
        "else:\n",
        "  fig=go.Figure()\n",
        "  for i,Location in enumerate(Locations):\n",
        "    if Location in World_.location.unique() and Location != 'World' :\n",
        "      data = World_[World_.location == Location]\n",
        "      data[Plot_Column] = data[Plot_Column].rolling(Apply_Rolling_Mean, min_periods = 1).mean()\n",
        "\n",
        "      if Use_Log:\n",
        "        data[Plot_Column] = np.log1p(data[Plot_Column])\n",
        "\n",
        "      fig.add_trace(go.Scatter(x = data.index , y = data[Plot_Column] , mode = 'lines' , name = '{}'.format(Location) ) ) \n",
        "  \n",
        "  fig.update_layout(title='Top {} Cases In World of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' ').title()  ),\n",
        "                  xaxis_title='Days Passed Since {}'.format(data[Date].min()),yaxis_title=\"Cases\",legend=dict(x=0,y=1,traceorder=\"normal\"),\n",
        "                  height =Graphs_Height*96/3)\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "WaixvmLajbOS"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://images.vexels.com/media/users/3/151175/isolated/preview/c8cccfd752a2c029daaa084aca6bb2bc-percent-pie-chart-doodle-by-vexels.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Plot Corona Virus Cases in Countries of World (Pie Chart)</h2></center><br>\n",
        "Plot_By = \"new_deaths_per_million\" #@param ['total_cases','total_cases_per_million', 'new_cases','new_cases_per_million','total_deaths','total_deaths_per_million', 'new_deaths','new_deaths_per_million']\n",
        "Date = \"2020-12-07\" #@param {type:\"date\"}\n",
        " \n",
        "if Date not in world_dates_unique:\n",
        "  display(Markdown('<h5> Invalid Date Encountered.. <br>Setting Date to last Date</h5>'))\n",
        "  time.sleep(2)\n",
        "  Date = World_['date'].max()\n",
        "display(Markdown(\"<h2> COUNTRY WISE PIE CHART CASES of 2019-nCoV AS OF {}</h2>\".format(Date)))\n",
        " \n",
        "temp = World_[World_['location']!= 'World']\n",
        "fig = px.sunburst(temp[temp['date'] == Date].sort_values(by=Plot_By, ascending=False).reset_index(drop=True), \n",
        "                  path=[\"continent\", \"location\"], values=Plot_By, height=700,\n",
        "                 title='Number of {} Reported As Of {}'.format(Plot_By.replace('_',' ').title(), Date),\n",
        "                 color_discrete_sequence = px.colors.qualitative.Prism ,)\n",
        "fig.data[0].textinfo = 'label+text+value'\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxISqtaUi-cU",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='https://cdn0.iconfinder.com/data/icons/chart-22/20/chart_box_plot-256.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2><br>Mathematical functions on Data</h2></center><br>\n",
        "\n",
        "Plot_Column = \"new_cases\" #@param ['total_cases', 'new_cases','new_cases_smoothed', 'total_deaths', 'new_deaths', 'new_deaths_smoothed', 'total_cases_per_million', 'new_cases_per_million', 'new_cases_smoothed_per_million', 'total_deaths_per_million', 'new_deaths_per_million', 'new_deaths_smoothed_per_million', 'reproduction_rate', 'icu_patients', 'icu_patients_per_million', 'hosp_patients', 'hosp_patients_per_million', 'weekly_icu_admissions', 'weekly_icu_admissions_per_million', 'weekly_hosp_admissions','weekly_hosp_admissions_per_million', 'total_tests', 'new_tests', 'total_tests_per_thousand', 'new_tests_per_thousand', 'new_tests_smoothed', 'new_tests_smoothed_per_thousand', 'tests_per_case', 'positive_rate', 'tests_units', 'stringency_index', 'population', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand', 'life_expectancy', 'human_development_index']\n",
        "Location = \"India\" #@param [\"Aruba\", \"Afghanistan\", \"Angola\", \"Anguilla\", \"Albania\", \"Andorra\",\"United Arab Emirates\", \"Argentina\", \"Armenia\",\"Antigua and Barbuda\", \"Australia\", \"Austria\", \"Azerbaijan\",\"Burundi\", \"Belgium\", \"Benin\", \"Bonaire Sint Eustatius and Saba\",\"Burkina Faso\", \"Bangladesh\", \"Bulgaria\", \"Bahrain\", \"Bahamas\",\"Bosnia and Herzegovina\", \"Belarus\", \"Belize\", \"Bermuda\",\"Bolivia\", \"Brazil\", \"Barbados\", \"Brunei\", \"Bhutan\", \"Botswana\",\"Central African Republic\", \"Canada\", \"Switzerland\", \"Chile\",\"China\", \"Cameroon\",\"Democratic Republic of Congo\", \"Congo\", \"Colombia\", \"Comoros\",\"Cape Verde\", \"Costa Rica\", \"Cuba\", \"Curacao\", \"Cayman Islands\",\"Cyprus\", \"Czech Republic\", \"Germany\", \"Djibouti\", \"Dominica\",\"Denmark\", \"Dominican Republic\", \"Algeria\", \"Ecuador\", \"Egypt\",\"Eritrea\", \"Western Sahara\", \"Spain\", \"Estonia\", \"Ethiopia\",\"Finland\", \"Fiji\", \"Falkland Islands\", \"France\", \"Faeroe Islands\",\"Gabon\", \"United Kingdom\", \"Georgia\", \"Guernsey\", \"Ghana\",\"Gibraltar\", \"Guinea\", \"Gambia\", \"Equatorial Guinea\", \"Greece\", \"Grenada\", \"Greenland\", \"Guatemala\",\"Guam\", \"Guyana\", \"Hong Kong\", \"Honduras\", \"Croatia\", \"Haiti\",\"Hungary\", \"Indonesia\", \"Isle of Man\", \"India\", \"Ireland\", \"Iran\",\"Iraq\", \"Iceland\", \"Israel\", \"Italy\", \"Jamaica\", \"Jersey\",\"Jordan\", \"Japan\", \"Kazakhstan\", \"Kenya\", \"Kyrgyzstan\", \"Cambodia\", \"Saint Kitts and Nevis\", \"South Korea\", \"Kuwait\", \"Laos\",\"Lebanon\", \"Liberia\", \"Libya\", \"Saint Lucia\", \"Liechtenstein\",\"Sri Lanka\", \"Lesotho\", \"Lithuania\", \"Luxembourg\", \"Latvia\",\"Morocco\", \"Monaco\", \"Moldova\", \"Madagascar\", \"Maldives\", \"Mexico\",\"Marshall Islands\", \"Macedonia\", \"Mali\", \"Malta\", \"Myanmar\",\"Montenegro\", \"Mongolia\", \"Northern Mariana Islands\", \"Mozambique\",\"Mauritania\", \"Montserrat\", \"Mauritius\", \"Malawi\", \"Malaysia\",\"Namibia\", \"New Caledonia\", \"Niger\", \"Nigeria\", \"Nicaragua\",\"Netherlands\", \"Norway\", \"Nepal\", \"New Zealand\", \"Oman\",\"Pakistan\", \"Panama\", \"Peru\", \"Philippines\", \"Papua New Guinea\",\"Poland\", \"Puerto Rico\", \"Portugal\", \"Paraguay\", \"Palestine\",\"French Polynesia\", \"Qatar\", \"Romania\", \"Russia\", \"Rwanda\",\"Saudi Arabia\", \"Sudan\", \"Senegal\", \"Singapore\", \"Solomon Islands\",\"Sierra Leone\", \"El Salvador\", \"San Marino\", \"Somalia\", \"Serbia\",\"South Sudan\", \"Sao Tome and Principe\", \"Suriname\", \"Slovakia\",\"Slovenia\", \"Sweden\", \"Swaziland\" ,\"Seychelles\", \"Syria\", \"Turks and Caicos Islands\", \"Chad\", \"Togo\",\"Thailand\", \"Tajikistan\", \"Timor\", \"Trinidad and Tobago\",\"Tunisia\", \"Turkey\", \"Taiwan\", \"Tanzania\", \"Uganda\", \"Ukraine\",\"Uruguay\", \"United States\", \"Uzbekistan\", \"Vatican\",\"Saint Vincent and the Grenadines\", \"Venezuela\",\"British Virgin Islands\", \"United States Virgin Islands\",\"Vietnam\", \"Vanuatu\", \"Wallis and Futuna\", \"Kosovo\", \"Yemen\",\"South Africa\", \"Zambia\", \"Zimbabwe\", \"World\", \"International\"]\n",
        "Plt_Col = 4 #@param {type:\"slider\", min:1, max:6, step:1}\n",
        "Date = 'date'\n",
        "\n",
        "data = World_[World_['location'] == Location]\n",
        "freq = []\n",
        "\n",
        "\n",
        "# freq.append([np.spacing(data[Plot_Column]).values , 'Spacing Function'])\n",
        "freq.append([data[Plot_Column].values.reshape(-1)  , 'Original Data'])\n",
        "freq.append([data[Plot_Column].diff().values.reshape(-1)  , 'Difference of Original Data'])\n",
        "freq.append([np.log1p(data[Plot_Column]).values.reshape(-1) , 'Log1p Fuction'])\n",
        "freq.append([np.log1p(data[Plot_Column]).diff().values.reshape(-1) , 'Difference of Log1p Fuction'])\n",
        "freq.append([np.sqrt(data[Plot_Column]).values.reshape(-1) , 'Square Root Function'])\n",
        "freq.append([np.sqrt(data[Plot_Column]).diff().values.reshape(-1) , 'Difference of Square Root Function'])\n",
        "freq.append([np.cbrt(data[Plot_Column]).values.reshape(-1) , 'Cube Root Function'])\n",
        "freq.append([np.cbrt(data[Plot_Column]).diff().values.reshape(-1) , 'Difference of Cube Root Function'])\n",
        "freq.append([np.sqrt(np.sqrt(data[Plot_Column])).values.reshape(-1) , 'Quad Root Function'])\n",
        "freq.append([np.sqrt(np.sqrt(data[Plot_Column])).diff().values.reshape(-1) , 'Difference of Quad Root Function'])\n",
        "freq.append([np.square(data[Plot_Column]).values.reshape(-1) , 'Square Function'])\n",
        "freq.append([np.square(data[Plot_Column]).diff().values.reshape(-1) , 'Difference of Square Function'])\n",
        "freq.append([preprocessing.MinMaxScaler().fit_transform(data[Plot_Column].values.reshape(-1,1)).reshape(-1) , 'Min Max Scaler Function'])\n",
        "freq.append([preprocessing.RobustScaler().fit_transform(data[Plot_Column].values.reshape(-1,1)).reshape(-1) , 'Robust Scaler Function'])\n",
        "freq.append([preprocessing.StandardScaler().fit_transform(data[Plot_Column].values.reshape(-1,1)).reshape(-1) , 'Standard Scaler Function'])\n",
        "freq.append([preprocessing.PowerTransformer().fit_transform(data[Plot_Column].values.reshape(-1,1)).reshape(-1) , 'Power Transformer Scaler'])\n",
        "freq.append([sm.tsa.filters.bkfilter(data[Plot_Column]).values.reshape(-1) , 'BKFilter Band Pass Filter'])\n",
        "freq.append([sm.tsa.filters.hpfilter(data[Plot_Column])[1].values.reshape(-1) , 'HPFilter Smoothing Filter'])\n",
        "freq.append([BoxCoxEndogTransformer().fit_transform(data[Plot_Column]+0.00000001)[0], 'BoxCoxEndogTransformer Filter'])\n",
        "\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=len(freq)).as_hex())\n",
        "Plt_Row = math.ceil(len(freq)/Plt_Col)\n",
        "plt.figure(figsize=(Graphs_Width,Graphs_Height*Plt_Row/Plt_Col))\n",
        "\n",
        "for i,j in enumerate(freq):\n",
        "  plt.subplot(Plt_Row , Plt_Col , i+1)\n",
        "  # plt.bar(range(len(j[0])) , j[0], width = 0.2 , linewidth = 0 , color = list(sns.color_palette(Style_Color,n_colors=len(j[0])).as_hex()) )\n",
        "  plt.plot(j[0], label = j[1] , color = plot_color[i])\n",
        "  plt.fill_between(list(range(len(j[0]))) ,0, j[0] ,color = plot_color[i] , alpha =0.4)\n",
        "  \n",
        "  plt.legend(loc = 2)\n",
        "  # plt.title(j[1]+' Over Data')\n",
        "  # plt.xlabel('Days Passed Since {}'.format(data.Date.min()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO3GQZCS-83A"
      },
      "source": [
        "World_.columns  'total_cases', 'new_cases', 'total_deaths', 'new_deaths', 'hosp_patients', 'new_tests', 'total_tests', 'positive_rate' , 'total_cases total_deaths total_tests' , 'new_cases new_deaths new_tests' , 'total_cases total_deaths total_tests new_cases new_deaths new_tests hosp_patients positive_rate'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "D0n6hajv7xs1"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://cdn2.iconfinder.com/data/icons/round-varieties/60/Rounded_-_High_Ultra_Colour19_-_Graph-256.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Month Wise Effect of Corona Virus in States of India</h2></center><br>\n",
        "\n",
        "Plot_Column = \"total_cases total_deaths total_tests new_cases new_deaths new_tests hosp_patients positive_rate\" #@param ['total_cases', 'new_cases', 'total_deaths', 'new_deaths', 'hosp_patients', 'new_tests', 'total_tests', 'positive_rate' , 'total_cases total_deaths total_tests' , 'new_cases new_deaths new_tests' , 'total_cases total_deaths total_tests new_cases new_deaths new_tests hosp_patients positive_rate']\n",
        "Location = \"India\" #@param [\"Aruba\", \"Afghanistan\", \"Angola\", \"Anguilla\", \"Albania\", \"Andorra\",\"United Arab Emirates\", \"Argentina\", \"Armenia\",\"Antigua and Barbuda\", \"Australia\", \"Austria\", \"Azerbaijan\",\"Burundi\", \"Belgium\", \"Benin\", \"Bonaire Sint Eustatius and Saba\",\"Burkina Faso\", \"Bangladesh\", \"Bulgaria\", \"Bahrain\", \"Bahamas\",\"Bosnia and Herzegovina\", \"Belarus\", \"Belize\", \"Bermuda\",\"Bolivia\", \"Brazil\", \"Barbados\", \"Brunei\", \"Bhutan\", \"Botswana\",\"Central African Republic\", \"Canada\", \"Switzerland\", \"Chile\",\"China\", \"Cameroon\",\"Democratic Republic of Congo\", \"Congo\", \"Colombia\", \"Comoros\",\"Cape Verde\", \"Costa Rica\", \"Cuba\", \"Curacao\", \"Cayman Islands\",\"Cyprus\", \"Czech Republic\", \"Germany\", \"Djibouti\", \"Dominica\",\"Denmark\", \"Dominican Republic\", \"Algeria\", \"Ecuador\", \"Egypt\",\"Eritrea\", \"Western Sahara\", \"Spain\", \"Estonia\", \"Ethiopia\",\"Finland\", \"Fiji\", \"Falkland Islands\", \"France\", \"Faeroe Islands\",\"Gabon\", \"United Kingdom\", \"Georgia\", \"Guernsey\", \"Ghana\",\"Gibraltar\", \"Guinea\", \"Gambia\", \"Equatorial Guinea\", \"Greece\", \"Grenada\", \"Greenland\", \"Guatemala\",\"Guam\", \"Guyana\", \"Hong Kong\", \"Honduras\", \"Croatia\", \"Haiti\",\"Hungary\", \"Indonesia\", \"Isle of Man\", \"India\", \"Ireland\", \"Iran\",\"Iraq\", \"Iceland\", \"Israel\", \"Italy\", \"Jamaica\", \"Jersey\",\"Jordan\", \"Japan\", \"Kazakhstan\", \"Kenya\", \"Kyrgyzstan\", \"Cambodia\", \"Saint Kitts and Nevis\", \"South Korea\", \"Kuwait\", \"Laos\",\"Lebanon\", \"Liberia\", \"Libya\", \"Saint Lucia\", \"Liechtenstein\",\"Sri Lanka\", \"Lesotho\", \"Lithuania\", \"Luxembourg\", \"Latvia\",\"Morocco\", \"Monaco\", \"Moldova\", \"Madagascar\", \"Maldives\", \"Mexico\",\"Marshall Islands\", \"Macedonia\", \"Mali\", \"Malta\", \"Myanmar\",\"Montenegro\", \"Mongolia\", \"Northern Mariana Islands\", \"Mozambique\",\"Mauritania\", \"Montserrat\", \"Mauritius\", \"Malawi\", \"Malaysia\",\"Namibia\", \"New Caledonia\", \"Niger\", \"Nigeria\", \"Nicaragua\",\"Netherlands\", \"Norway\", \"Nepal\", \"New Zealand\", \"Oman\",\"Pakistan\", \"Panama\", \"Peru\", \"Philippines\", \"Papua New Guinea\",\"Poland\", \"Puerto Rico\", \"Portugal\", \"Paraguay\", \"Palestine\",\"French Polynesia\", \"Qatar\", \"Romania\", \"Russia\", \"Rwanda\",\"Saudi Arabia\", \"Sudan\", \"Senegal\", \"Singapore\", \"Solomon Islands\",\"Sierra Leone\", \"El Salvador\", \"San Marino\", \"Somalia\", \"Serbia\",\"South Sudan\", \"Sao Tome and Principe\", \"Suriname\", \"Slovakia\",\"Slovenia\", \"Sweden\", \"Swaziland\" ,\"Seychelles\", \"Syria\", \"Turks and Caicos Islands\", \"Chad\", \"Togo\",\"Thailand\", \"Tajikistan\", \"Timor\", \"Trinidad and Tobago\",\"Tunisia\", \"Turkey\", \"Taiwan\", \"Tanzania\", \"Uganda\", \"Ukraine\",\"Uruguay\", \"United States\", \"Uzbekistan\", \"Vatican\",\"Saint Vincent and the Grenadines\", \"Venezuela\",\"British Virgin Islands\", \"United States Virgin Islands\",\"Vietnam\", \"Vanuatu\", \"Wallis and Futuna\", \"Kosovo\", \"Yemen\",\"South Africa\", \"Zambia\", \"Zimbabwe\", \"World\", \"International\"]\n",
        "Apply_Rolling = 5 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "Plot_Method = \"Mean\" #@param [\"None\", \"Median\", \"Mean\", \"Max\", \"Min\"]\n",
        "\n",
        "Fill_Below = True #@param {type:\"boolean\"}\n",
        "data = World_[World_.location == Location]\n",
        "Plot_Column = Plot_Column.split(' ')\n",
        "\n",
        "n_cols = len(World_['Month'].unique())\n",
        "n_rows = len(Plot_Column)\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=n_rows*n_cols).as_hex())\n",
        "plt.figure(figsize = (Graphs_Width*4.5,int(Graphs_Height/2)*n_rows))\n",
        "i=0\n",
        "Months = data['Month'].unique()\n",
        "for plot_row in Plot_Column:\n",
        "  for col in Months:\n",
        "    temp = data[data['Month'] == col].reset_index(drop = True)\n",
        "    plt.subplot( n_rows , n_cols , i+1)\n",
        "    if Plot_Method == 'Mean':\n",
        "      plt.plot(temp[plot_row].rolling(Apply_Rolling, min_periods = 1).mean() , color = plot_color[i] , label = '{} Rolling Mean'.format(col))\n",
        "    elif Plot_Method == 'Median':\n",
        "      plt.plot(temp[plot_row].rolling(Apply_Rolling, min_periods = 1).median() , color = plot_color[i] , label = '{} Rolling Median'.format(col))\n",
        "    elif Plot_Method == 'Max':\n",
        "      plt.plot(temp[plot_row].rolling(Apply_Rolling, min_periods = 1).max() , color = plot_color[i] , label = '{} Rolling Max'.format(col))\n",
        "    elif Plot_Method == 'Min':\n",
        "      plt.plot(temp[plot_row].rolling(Apply_Rolling, min_periods = 1).min() , color = plot_color[i] , label = '{} Rolling Min'.format(col))\n",
        "    else:\n",
        "      plt.plot(temp[plot_row] , color = plot_color[i] , label = '{}'.format(col))\n",
        "      \n",
        "    if Fill_Below:\n",
        "      plt.fill_between(list(temp.index) ,0, temp[plot_row] ,color = plot_color[i] , alpha =0.4, label = '{}'.format(col))\n",
        "  \n",
        "    plt.legend()\n",
        "    plt.title('{}  in Month {}'.format(plot_row.replace('_',' (Per Day) ') , col) , fontsize = 19)\n",
        "    i+=1\n",
        "plt.plot()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rf0LY96kZ7V"
      },
      "source": [
        "#COVID - 19 Analysis in India\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "bzTGWmXCXsi4"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://cdn2.iconfinder.com/data/icons/coronavirus-118/82/coronavirus_corona-15-512.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Plot Corona Virus Cases in States of India</h2></center><br>\n",
        "Sort_By = \"Confirmed\" #@param ['Confirmed', 'Recovered', 'Deceased','Active','Confirmed_','Recovered_','Deceased_','Tested','Death Rate (per 100)','Cure Rate (per 100)']\n",
        "Plot_Top = 19 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "Date = \"2020-12-07\" #@param {type:\"date\"}\n",
        "\n",
        "# Date = '2020-'+Plot_Month.zfill(2)+'-'+Plot_Date.zfill(2)\n",
        "if Date not in Completed_['Date'].unique():\n",
        "  Date = Completed_['Date'].max()\n",
        "display(Markdown(\"<h2> STATE WISE CONFIRMED, DEATH AND CURED CASES of 2019-nCoV AS OF {}</h2>\".format(Date)))\n",
        "\n",
        "\n",
        "temp = Completed_[Completed_['State']!='India']\n",
        "temp[temp['Date'] == Date][['State','Confirmed', 'Recovered', 'Deceased','Active','Confirmed_','Recovered_','Deceased_','Tested','Death Rate (per 100)','Cure Rate (per 100)']]\\\n",
        "                        .sort_values(Sort_By, ascending= False).fillna(0)\\\n",
        "                        .iloc[:Plot_Top].style\\\n",
        "                        .background_gradient(cmap='YlOrBr',subset=[\"Confirmed\"])\\\n",
        "                        .background_gradient(cmap='Reds',subset=[\"Deceased\"])\\\n",
        "                        .background_gradient(cmap='Greens',subset=[\"Recovered\"])\\\n",
        "                        .background_gradient(cmap='Blues',subset=[\"Active\"])\\\n",
        "                        .background_gradient(cmap='Reds',subset=[\"Death Rate (per 100)\"])\\\n",
        "                        .background_gradient(cmap='Greens',subset=[\"Cure Rate (per 100)\"])\\\n",
        "                        .background_gradient(cmap='crest',subset=[\"Confirmed_\"])\\\n",
        "                        .background_gradient(cmap='PuRd',subset=[\"Recovered_\"])\\\n",
        "                        .background_gradient(cmap='Blues',subset=[\"Deceased_\"])\\\n",
        "                        .background_gradient(cmap='rocket',subset=[\"Tested\"])\\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "W7qu-fMMsvqf"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://media.9curry.com/uploads/state/image/2/Uttar_Pradesh.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Plot Corona Virus Cases in States of India</h2></center><br>\n",
        "Plot_Status = \"Plot Cumulative Graph\" #@param [\"Plot Cumulative Graph\" , \"Plot Today's Graph\"]\n",
        "Plot_Only = \"Confirmed, Recovered and Deceased Cases\" #@param [\"Confirmed, Recovered and Deceased Cases\", \"Confirmed Cases\", \"Recovered Cases\", \"Deceased Cases\", \"Other Cases\" , \"Tests Cases\", \"Active Cases\"]\n",
        "Plot_Top = 20 #@param {type:\"slider\", min:0, max:30, step:1}\n",
        "Date = \"2020-12-03\" #@param {type:\"date\"}\n",
        "Population_Ratio = False #@param {type:\"boolean\"}\n",
        "\n",
        "if Date not in date_unique:\n",
        "  display(Markdown('<h3> Invalid Date Encountered.. <br>Setting Date to last Date</h3>'))\n",
        "  time.sleep(2)\n",
        "  Date = date_unique[-1]\n",
        "display(Markdown(\"<center><h2>Bar Plot of Most Effected States of India of SARS-CoV-2 On {} \\n</h2></center>\".format( Date)))\n",
        "\n",
        "if Plot_Status == 'Plot Cumulative Graph':\n",
        "  plot_using = ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active']\n",
        "else:\n",
        "  plot_using = ['Confirmed_', 'Recovered_', 'Deceased_', 'Other_', 'Tested_', 'Active']\n",
        "\n",
        "state_cases = Completed_[Completed_.Date == Date]\n",
        "if Population_Ratio:\n",
        "  for i in plot_using:\n",
        "    state_cases[i] = state_cases[i]/state_cases['Population']\n",
        "\n",
        "\n",
        "if Plot_Only == \"Confirmed, Recovered and Deceased Cases\":\n",
        "  state_cases=state_cases.sort_values(plot_using[0], ascending= False)\n",
        "  total_cases = state_cases[plot_using[0]].sum()\n",
        "elif Plot_Only == 'Confirmed Cases':\n",
        "  state_cases=state_cases.sort_values(plot_using[0], ascending= False)\n",
        "  total_cases = state_cases[plot_using[0]].sum()\n",
        "elif Plot_Only == 'Recovered Cases':\n",
        "  state_cases=state_cases.sort_values(plot_using[1], ascending= False)\n",
        "  total_cases = state_cases[plot_using[1]].sum()\n",
        "elif Plot_Only == 'Deceased Cases':\n",
        "  state_cases=state_cases.sort_values(plot_using[2], ascending= False)\n",
        "  total_cases = state_cases[plot_using[2]].sum()\n",
        "elif Plot_Only == 'Other Cases':\n",
        "  state_cases=state_cases.sort_values(plot_using[3], ascending= False)\n",
        "  total_cases = state_cases[plot_using[3]].sum()\n",
        "elif Plot_Only == 'Tests Cases':\n",
        "  state_cases=state_cases.sort_values(plot_using[4], ascending= False)\n",
        "  total_cases = state_cases[plot_using[4]].sum()\n",
        "else:\n",
        "  state_cases=state_cases.sort_values(plot_using[5], ascending= False)\n",
        "  total_cases = state_cases[plot_using[5]].sum()\n",
        "\n",
        "# state_cases=state_cases.sort_values(plot_using[0], ascending= False)\n",
        "# total_cases = state_cases[plot_using[0]].sum()\n",
        "state_cases=state_cases[state_cases.State!='India'].head(int(Plot_Top))\n",
        "plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "ax = plt.subplot(1,1,1)\n",
        "plt.suptitle(Sup_Title, fontsize = 29)\n",
        "plt.title('\\n{} of Top {} States with SARS-CoV-2 Cases On {} \\n'.format(Plot_Status , Plot_Top , Date) , fontsize = 19)\n",
        "if Plot_Only == \"Confirmed, Recovered and Deceased Cases\":\n",
        "  graph = sns.barplot(data = state_cases , y='State', x = plot_using[0] , saturation = Plot_Saturation, alpha = Plot_Alpha , color =Style_Palettes[0] , label = plot_using[0]+' Cases' , ci = 'sd' , orient = 'h')\n",
        "  sns.barplot(data=state_cases,y='State',x = plot_using[1] , saturation = Plot_Saturation, alpha = Plot_Alpha, color =Style_Palettes[1], label = plot_using[1]+' Cases' , ci = 'sd' , orient = 'h')\n",
        "  sns.barplot(data=state_cases,y='State',x= plot_using[2] , saturation = Plot_Saturation , alpha = Plot_Alpha, color =Style_Palettes[2], label = plot_using[2]+' Cases' , ci = 'sd' , orient = 'h')\n",
        "  plt.xlim(0,state_cases[plot_using[0]].max()+state_cases[plot_using[0]].max()/10 )\n",
        "\n",
        "elif Plot_Only == 'Confirmed Cases':\n",
        "  graph = sns.barplot(data = state_cases , y='State', x = plot_using[0] , saturation = Plot_Saturation, alpha = Plot_Alpha , palette =Style_Color , label = plot_using[0]+' Cases' , ci = 'sd' , orient = 'h')\n",
        "  plt.xlim(0,state_cases[plot_using[0]].max()+state_cases[plot_using[0]].max()/10 )\n",
        "elif Plot_Only == 'Recovered Cases':\n",
        "  graph = sns.barplot(data=state_cases,y='State',x = plot_using[1] , saturation = Plot_Saturation, alpha = Plot_Alpha, palette =Style_Color, label = plot_using[1]+' Cases' , ci = 'sd' , orient = 'h')\n",
        "  plt.xlim(0,state_cases[plot_using[1]].max()+state_cases[plot_using[1]].max()/10 )\n",
        "\n",
        "elif Plot_Only == 'Deceased Cases':\n",
        "  graph = sns.barplot(data=state_cases,y='State',x= plot_using[2] , saturation = Plot_Saturation , alpha = Plot_Alpha, palette =Style_Color, label = plot_using[2]+' Cases' , ci = 'sd' , orient = 'h')\n",
        "  plt.xlim(0,state_cases[plot_using[2]].max()+state_cases[plot_using[2]].max()/10 )\n",
        "\n",
        "elif Plot_Only == 'Other Cases':\n",
        "  graph = sns.barplot(data=state_cases,y='State',x= plot_using[3] , saturation = Plot_Saturation , alpha = Plot_Alpha, palette =Style_Color, label = plot_using[3]+' Cases' , ci = 'sd' , orient = 'h')\n",
        "  plt.xlim(0,state_cases[plot_using[3]].max()+state_cases[plot_using[3]].max()/10 )\n",
        "\n",
        "elif Plot_Only == 'Tests Cases':\n",
        "  graph = sns.barplot(data=state_cases,y='State',x= plot_using[4] , saturation = Plot_Saturation , alpha = Plot_Alpha, palette =Style_Color, label = plot_using[4]+' Cases' , ci = 'sd' , orient = 'h')\n",
        "  plt.xlim(0,state_cases[plot_using[4]].max()+state_cases[plot_using[4]].max()/10 )\n",
        "\n",
        "else:\n",
        "  graph = sns.barplot(data=state_cases,y='State',x= plot_using[5] , saturation = Plot_Saturation , alpha = Plot_Alpha, palette =Style_Color, label = plot_using[5]+' Cases' , ci = 'sd' , orient = 'h')\n",
        "  plt.xlim(0,state_cases[plot_using[5]].max()+state_cases[plot_using[5]].max()/10 )\n",
        "\n",
        "\n",
        "# plt.xticks(rotation=90)\n",
        "plt.ylabel('States (India)')\n",
        "plt.xlabel('Number of Cases')\n",
        "# plt.xlim(0,Completed_['Confirmed'].max()+Completed_['Confirmed'].max()/10 )\n",
        "# plt.xlim(0,state_cases[plot_using[0]].max()+state_cases[plot_using[0]].max()/10 )\n",
        "plt.legend(loc = 8)\n",
        "anchored_text = AnchoredText(\"Month : {}\\nDays Passed : {}\\nTotal Cases (Sum): {}\".format(state_cases.Month.unique()[0] ,  state_cases.Days_Passed.unique()[0],int(total_cases)), borderpad=1.0, pad = 1.0, loc=7 , frameon= True )\n",
        "ax.add_artist(anchored_text)\n",
        "# plt.text(0.95, 0.01, 'colored text in axes coords',\n",
        "#         verticalalignment='bottom', horizontalalignment='right',\n",
        "#         color='green', fontsize=15)\n",
        "for p in graph.patches[:int(Plot_Top)]:\n",
        "  _x = p.get_x() + p.get_width() \n",
        "  _y = p.get_y() + p.get_height()/2 + float(0.2)\n",
        "  value = ((p.get_width()/total_cases)*100)\n",
        "  if np.isnan(value):\n",
        "    value = 0.0\n",
        "  graph.text(_x , _y , ' {:.2f}%'.format(value) , ha = 'left', color = sns.color_palette('rocket')[1])\n",
        "plt.subplots_adjust(top=SubPlot_Top)\n",
        "\n",
        "plt.savefig(File_Prefix+'India States Bar Plot  on {} _{}.{}'.format(Date , time.time() , Format_To_Save) , bbox_inches = 'tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "vs-AEy43svkp"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://cdn4.iconfinder.com/data/icons/coronavirus-1/512/wuhan-coronavirus-virus-outbreak-14-512.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Plot Tested & Negative of COVID-19 Virus in States of India</h2></center><br>\n",
        "Plot_Top = 20 #@param {type:\"slider\", min:0, max:30, step:1}\n",
        "Date = \"2020-12-03\" #@param {type:\"date\"}\n",
        "Population_Ratio = True #@param {type:\"boolean\"}\n",
        "\n",
        "if Date not in date_unique:\n",
        "  display(Markdown('<h3> Invalid Date Encountered.. <br>Setting Date to last Date</h3>'))\n",
        "  time.sleep(2)\n",
        "  Date = date_unique[-1]\n",
        "display(Markdown(\"<center><h2>Bar Plot of Most Tested States of India of SARS-CoV-2 On {} \\n</h2></center>\".format( Date)))\n",
        "\n",
        "plot_using = ['Tested_', 'Negative' , 'Confirmed_']\n",
        "state_cases = Completed_[Completed_.Date == Date]\n",
        "if Population_Ratio:\n",
        "  for i in plot_using:\n",
        "    state_cases[i] = state_cases[i]/state_cases['Population']\n",
        "state_cases=state_cases[state_cases.State!='India'].head(int(Plot_Top))\n",
        "\n",
        "state_cases=state_cases.sort_values('Tested_', ascending= False)\n",
        "state_cases=state_cases.head(20)\n",
        "\n",
        "total_cases = state_cases['Tested_'].sum()\n",
        "plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "ax = plt.subplot(1,1,1)\n",
        "plt.suptitle(Sup_Title, fontsize = 29)\n",
        "plt.title('\\n{} of Top {} States with SARS-CoV-2 Cases On {} \\n'.format(Plot_Status , Plot_Top , Date) , fontsize = 19)\n",
        "\n",
        "graph = sns.barplot(data = state_cases , y='State', x = plot_using[0] , saturation = Plot_Saturation, alpha = Plot_Alpha , color =Style_Palettes[0] , label = plot_using[0]+' Cases' , ci = 'sd' , orient = 'h')\n",
        "sns.barplot(data=state_cases,y='State',x = plot_using[1] , saturation = Plot_Saturation, alpha = Plot_Alpha, color =Style_Palettes[1], label = plot_using[1]+' Cases' , ci = 'sd' , orient = 'h')\n",
        "sns.barplot(data=state_cases,y='State',x= plot_using[2] , saturation = Plot_Saturation , alpha = Plot_Alpha, color =Style_Palettes[2], label = plot_using[2]+' Cases' , ci = 'sd' , orient = 'h')\n",
        "plt.xlim(0,state_cases[plot_using[0]].max()+state_cases[plot_using[0]].max()/10 )\n",
        "\n",
        "plt.ylabel('States (India)')\n",
        "plt.xlabel('Number of Tests')\n",
        "\n",
        "plt.legend(loc = 8)\n",
        "anchored_text = AnchoredText(\"Month : {}\\nDays Passed : {}\\nTotal Tests  Today : {}\".format(state_cases.Month.unique()[0] ,  state_cases.Days_Passed.unique()[0],int(total_cases)), borderpad=1.0, pad = 1.0, loc=7 , frameon= True )\n",
        "ax.add_artist(anchored_text)\n",
        "\n",
        "for p in graph.patches[:20]:\n",
        "  _x = p.get_x() + p.get_width() \n",
        "  _y = p.get_y() + p.get_height()/2 + float(0.2)\n",
        "  value = ((p.get_width()/total_cases)*100)\n",
        "  if np.isnan(value):\n",
        "    value = 0.0\n",
        "  graph.text(_x , _y , ' {:.5f}%'.format(value) , ha = 'left', color = sns.color_palette('rocket')[1])\n",
        "plt.subplots_adjust(top=SubPlot_Top)\n",
        "\n",
        "plt.savefig(File_Prefix+'India States Tested Bar Plot  on {} _{}.{}'.format(Date , time.time() , Format_To_Save) , bbox_inches = 'tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOBLTR31aiOx",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://cdn.pixabay.com/photo/2013/07/13/12/36/india-159941_960_720.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Plot Corona Virus Cases in India</h2></center><br>\n",
        "Plot_Column = \"C/R/D\" #@param ['C/R/D' , 'C/R/D/A', 'C/R/D(Daily)' ,'Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_', 'Negative']\n",
        "Location = \"UP\" #@param ['Kerala', 'Delhi', 'Telangana', 'India', 'Rajasthan', 'Haryana','UP', 'Ladakh', 'TN', 'J&K', 'Karnataka', 'Maharashtra', 'Punjab','Andra P', 'HP', 'Uttarakhand', 'Odisha', 'Puducherry','West Bengal', 'Chandigarh', 'Chhattisgarh', 'Gujarat', 'MP','Bihar', 'Manipur', 'Goa', 'Mizoram', 'A&N', 'Assam', 'Jharkhand','Arun P', 'Nagaland', 'Tripura', 'D&D', 'Meghalaya', 'Sikkim','Other']\n",
        "Regression_Power = 1 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "Apply_Rolling_Mean = 7 #@param {type:\"slider\", min:0, max:30, step:1}\n",
        "Train_on_days_from = 42 #@param {type:\"slider\", min:20, max:300, step:1}\n",
        "Predict_of_future_days = 15 #@param {type:\"slider\", min:0, max:200, step:1}\n",
        "Bar_Plot = 25 #@param {type:\"slider\", min:0, max:30, step:1}\n",
        "Plot_Lib = \"Plotly\" #@param [\"Plotly\", \"MatplotLib\"]\n",
        "\n",
        "Line_Plot = True #@param {type:\"boolean\"}\n",
        "Use_Log = True #@param {type:\"boolean\"}\n",
        "Date = 'Date'\n",
        "display(Markdown(\"<center><h2>Line Plot of {} By SARS-CoV-2</h2></center>\".format(Location)))\n",
        "\n",
        "if Plot_Column == 'C/R/D':\n",
        "  Plot_Column = ['Confirmed' , 'Recovered' , 'Deceased']\n",
        "elif Plot_Column == 'C/R/D/A':\n",
        "  Plot_Column = ['Confirmed' , 'Recovered' , 'Deceased' , 'Active']\n",
        "elif Plot_Column == 'C/R/D(Daily)':\n",
        "  Plot_Column = ['Confirmed_' , 'Recovered_' , 'Deceased_']\n",
        "else:\n",
        "  Plot_Column = [Plot_Column]\n",
        "data = Completed_[Completed_.State == Location]\n",
        "bar_data = data.resample('M').mean()\n",
        "times = pd.date_range(data[Date].min(), periods = data.shape[0]+Predict_of_future_days , freq='D')\n",
        "if Use_Log:\n",
        "  bar_data[Plot_Column[0]] = np.log1p(bar_data[Plot_Column[0]])\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=len(Plot_Column)*2).as_hex())\n",
        "if Plot_Lib == 'MatplotLib':\n",
        "  plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  if Bar_Plot:\n",
        "    plt.bar(bar_data.index, bar_data[Plot_Column[0]], align = 'edge',width = -Bar_Plot , linewidth = 0 , color = list(sns.color_palette(Style_Color,n_colors=len(bar_data[Plot_Column].values)).as_hex()) , alpha = .9 ,label = 'Monthly Average')\n",
        "\n",
        "  for col,i in enumerate(Plot_Column):\n",
        "    data[i] = data[i].rolling(Apply_Rolling_Mean, min_periods = 1).mean()\n",
        "    if Use_Log:\n",
        "      data[i] = np.log1p(data[i])\n",
        "    if Line_Plot:\n",
        "      plt.plot(data[i], label = '{} Cases(per day)'.format(i.replace('_',' (Daily)').title()) , color = plot_color[col*2] )\n",
        "    if Regression_Power:\n",
        "      model = np.poly1d(np.polyfit(data['Days_Passed'].values[Train_on_days_from-20:], data[i].values[Train_on_days_from-20:], Regression_Power))\n",
        "      polyline = np.linspace(Train_on_days_from, data['Days_Passed'].max()+Predict_of_future_days, len(times[Train_on_days_from:])) \n",
        "      plt.plot( pd.Series([0 if i<0 else i for i in model(polyline)] , index = times[Train_on_days_from:])  , label = 'Predicted {} Cases'.format(i.replace('_',' (Daily)').title()) , color = plot_color[1])\n",
        "\n",
        "  plt.suptitle(Sup_Title, fontsize = 29)\n",
        "  plt.title('\\nLine Plot in {} with SARS-CoV-2 Cases  \\n'.format(Location ) , fontsize = 19)\n",
        "\n",
        "  plt.legend()\n",
        "  plt.ylabel('Cases')\n",
        "  plt.xlabel('Days Passed Since {}'.format(Completed_['Date'].min()))\n",
        "  plt.subplots_adjust(top=SubPlot_Top)\n",
        "  plt.savefig(File_Prefix+'Time Series India State Reg Plot  on {} _{}.{}'.format(Completed_[Date].max() , time.time() , Format_To_Save) , bbox_inches = 'tight')\n",
        "else:\n",
        "  fig=go.Figure()\n",
        "  for col,i in enumerate(Plot_Column):\n",
        "    if Use_Log:\n",
        "      data[i] = np.log1p(data[i])\n",
        "    if Regression_Power:\n",
        "      model = np.poly1d(np.polyfit(data['Days_Passed'].values[Train_on_days_from-20:], data[i].values[Train_on_days_from-20:], Regression_Power))\n",
        "      polyline = np.linspace(Train_on_days_from, data['Days_Passed'].max()+Predict_of_future_days, len(times[Train_on_days_from:])) \n",
        "      reg_plot = pd.Series([0 if i<0 else i for i in model(polyline)] , index = times[Train_on_days_from:])  \n",
        "      fig.add_trace(go.Scatter(x = reg_plot.index ,y = reg_plot , mode = 'lines' , name = ' Fitted Line on {} '.format(i.replace('_',' ').title())))\n",
        "    if Apply_Rolling_Mean > 1:\n",
        "      data[i] = data[i].rolling(Apply_Rolling_Mean, min_periods = 1).mean()\n",
        "    fig.add_trace(go.Scatter(x = data.index , y = data[i] , mode = 'lines' , name = '{} Cases'.format(i.replace('_',' ').title() ) ) )\n",
        "  if Bar_Plot:\n",
        "    fig.add_trace(go.Bar(x = bar_data.index,y = bar_data[Plot_Column[0]] , name = 'Monthly Average Confirmed Cases', marker=dict(color = list(sns.color_palette(Style_Color,n_colors=len(bar_data[Plot_Column[0]].values)).as_hex()))))\n",
        "  fig.update_layout(title='Cases of {} SARS-CoV-2 \\n'.format(Location),\n",
        "                  xaxis_title='Days Passed Since {}'.format(data[Date].min()),yaxis_title=\"Cases\",legend=dict(x=0,y=1,traceorder=\"normal\"),\n",
        "                  height =Graphs_Height*96/3)\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "vNeiH0ZNlVku"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://assets.website-files.com/5d9ba0eb5f6edb77992a99d0/5e62506c9394b24aa66cf385_iconfinder_connection-route-spread-virus-global_5728179.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Top Effected States by Corona Virus</h2></center><br>\n",
        "\n",
        "Plot_Column = \"Confirmed_\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_', 'Negative']\n",
        "Use_Method = \"mean\" #@param [\"sum\", \"mean\", \"max\", \"median\", \"min\", \"std\", \"var\"]\n",
        "Plot_top = 4 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "Apply_Rolling_Mean = 11 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "Plot_Lib = \"MatplotLib\" #@param [\"Plotly\", \"MatplotLib\"]\n",
        "Fill_Alpha = 0.13 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "Use_Log = False #@param {type:\"boolean\"}\n",
        "Date = 'Date'\n",
        "\n",
        "display(Markdown(\"<center><h2>Line Plot for {} Most Effected Indian States By SARS-CoV-2</h2></center>\".format(Plot_top)))\n",
        "\n",
        "Locations = Completed_.groupby('State').agg({Plot_By:Use_Method}).sort_values(by=[Plot_By] , ascending = False).reset_index()['State'].head(Plot_top+1).values\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=len(Locations)*2).as_hex())\n",
        "\n",
        "\n",
        "if Plot_Lib == 'MatplotLib':\n",
        "  plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  for i,Location in enumerate(Locations):\n",
        "    if Location in Completed_.State.unique() and Location != 'India' :\n",
        "      data = Completed_[Completed_.State == Location]\n",
        "      data[Plot_Column] = data[Plot_Column].rolling(Apply_Rolling_Mean, min_periods = 1).mean()\n",
        "\n",
        "      if Use_Log:\n",
        "        data[Plot_Column] = np.log1p(data[Plot_Column])\n",
        "      if Fill_Alpha:\n",
        "        plt.fill_between(data.index , 0 , data[Plot_Column], color =  plot_color[i] , alpha = Fill_Alpha)\n",
        "      plt.plot(data.index , data[Plot_Column], label = '{}'.format(Location) , color = plot_color[i*2] )\n",
        "\n",
        "  plt.suptitle(Sup_Title, fontsize = 29)\n",
        "  plt.title('{} Cases of  SARS-CoV-2 in States \\n'.format(Plot_By.replace('_',' (Daily)').title() ) , fontsize = 19)\n",
        "  plt.legend()\n",
        "  plt.ylabel('Cases')\n",
        "  plt.xlabel('Days Passed Since {}'.format(Completed_['Date'].min()))\n",
        "  plt.subplots_adjust(top=SubPlot_Top)\n",
        "  plt.savefig(File_Prefix+'Time Series Top Effected India  Reg Plot  on {} _{}.{}'.format(World_.date.max() , time.time() , Format_To_Save) , bbox_inches = 'tight')\n",
        "\n",
        "else:\n",
        "  fig=go.Figure()\n",
        "  for i,Location in enumerate(Locations):\n",
        "    if Location in Completed_.State.unique() and Location != 'India' :\n",
        "      data = Completed_[Completed_.State == Location]\n",
        "      data[Plot_Column] = data[Plot_Column].rolling(Apply_Rolling_Mean, min_periods = 1).mean()\n",
        "\n",
        "      if Use_Log:\n",
        "        data[Plot_Column] = np.log1p(data[Plot_Column])\n",
        "\n",
        "      fig.add_trace(go.Scatter(x = data.index , y = data[Plot_Column] , mode = 'lines' , name = '{}'.format(Location) ) ) \n",
        "  \n",
        "  fig.update_layout(title='Top {} Cases In India of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title()  ),\n",
        "                  xaxis_title='Days Passed Since {}'.format(data[Date].min()),yaxis_title=\"Cases\",legend=dict(x=0,y=1,traceorder=\"normal\"),\n",
        "                  height =Graphs_Height*96/3)\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "aoFJLCEgsmKZ"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://images.vexels.com/media/users/3/151175/isolated/preview/c8cccfd752a2c029daaa084aca6bb2bc-percent-pie-chart-doodle-by-vexels.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Pie Plot of Corona Virus Cases in States of India (Pie Chart)</h2></center><br>\n",
        "Plot_By = \"Confirmed\" #@param ['Confirmed', 'Recovered', 'Deceased','Tested','Active','Confirmed_', 'Recovered_', 'Deceased_','Death Rate (per 100)','Cure Rate (per 100)']\n",
        "Date = \"2020-12-08\" #@param {type:\"date\"}\n",
        "Population_Ratio = True #@param {type:\"boolean\"}\n",
        "\n",
        "if Date not in date_unique:\n",
        "  display(Markdown('<h3> Invalid Date Encountered.. <br>Setting Date to last Date</h3>'))\n",
        "  time.sleep(2)\n",
        "  Date = date_unique[-1]\n",
        "\n",
        "if Date not in Completed_['Date'].unique():\n",
        "  Date = Completed_['Date'].max()\n",
        "display(Markdown(\"<h2> State WISE PIE CHART CASES of 2019-nCoV AS OF {}</h2>\".format(Date )))\n",
        "\n",
        "temp = Completed_[Completed_['State']!= 'India']\n",
        "\n",
        "if Population_Ratio:\n",
        "  temp[Plot_By] = temp[Plot_By]/temp['Population']\n",
        "fig = px.sunburst(temp[temp['Date'] == Date].sort_values(by=Plot_By, ascending=False).reset_index(drop=True), \n",
        "                  path=[ \"State\"], values=Plot_By, height=700,\n",
        "                 title='Number of {} Reported as of {}'.format(Plot_By.replace('_',' (New) ').title() , Date),\n",
        "                 color_discrete_sequence = px.colors.qualitative.Prism ,)\n",
        "fig.data[0].textinfo = 'label+text+value'\n",
        "fig.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "QQMDLG1ZKSzg"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://s3.amazonaws.com/iconbros/icons/icon_pngs/000/000/566/original/pie-chart.png?1511983049' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Pie Plot of Corona Virus Cases for Different Months in States of India (Pie Chart)</h2></center><br>\n",
        " \n",
        "Use_Method = \"mean\" #@param [\"sum\", \"mean\", \"max\", \"median\", \"min\", \"std\", \"var\"]\n",
        "Plot_Column = \"Death Rate (per 100)\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other','Tested', 'Active', 'Death Rate (per 100)','Cure Rate (per 100)']\n",
        "Month_After_State = False #@param {type:\"boolean\"}\n",
        " \n",
        "temp = Completed_.groupby(['Month','State'], as_index = False).agg({ Plot_Column:[Use_Method] })\n",
        "temp.columns =  [' '.join(col).strip() for col in temp.columns.values]\n",
        " \n",
        "if Month_After_State:\n",
        "  Paths = [ \"State\" , \"Month\"]\n",
        "else:\n",
        "  Paths = [ \"Month\" , \"State\"]\n",
        " \n",
        "fig = px.sunburst(temp[temp['State']!='India'].sort_values(by=Plot_Column + ' ' + Use_Method, ascending=False).reset_index(drop=True), \n",
        "                  path=Paths, values=Plot_Column  + ' ' +  Use_Method, height=700,\n",
        "                 title='Number of {} Reported'.format((Plot_Column  + ' ' + Use_Method).replace('_',' (New) ').title()),\n",
        "                 color_discrete_sequence = px.colors.qualitative.Prism ,)\n",
        "fig.data[0].textinfo = 'label+text+value'\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGCAP2wbizTk",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='https://cdn0.iconfinder.com/data/icons/chart-22/20/chart_box_plot-256.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2><br>Mathematical functions on Data</h2></center><br>\n",
        "\n",
        "Plot_Column = \"Confirmed\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_']\n",
        "Location = \"India\" #@param ['Kerala', 'Delhi', 'Telangana', 'India', 'Rajasthan', 'Haryana','UP', 'Ladakh', 'TN', 'J&K', 'Karnataka', 'Maharashtra', 'Punjab','Andra P', 'HP', 'Uttarakhand', 'Odisha', 'Puducherry','West Bengal', 'Chandigarh', 'Chhattisgarh', 'Gujarat', 'MP','Bihar', 'Manipur', 'Goa', 'Mizoram', 'A&N', 'Assam', 'Jharkhand','Arun P', 'Nagaland', 'Tripura', 'D&D', 'Meghalaya', 'Sikkim','Other']\n",
        "Plt_Col = 4 #@param {type:\"slider\", min:1, max:6, step:1}\n",
        "Date = 'Date'\n",
        "\n",
        "data = Completed_[Completed_['State'] == Location]\n",
        "freq = []\n",
        "\n",
        "# freq.append([np.spacing(data[Plot_Column]).values , 'Spacing Function'])\n",
        "freq.append([data[Plot_Column].values.reshape(-1)  , 'Original Data'])\n",
        "freq.append([data[Plot_Column].diff().values.reshape(-1)  , 'Difference of Original Data'])\n",
        "freq.append([np.log1p(data[Plot_Column]).values.reshape(-1) , 'Log1p Fuction'])\n",
        "freq.append([np.log1p(data[Plot_Column]).diff().values.reshape(-1) , 'Difference of Log1p Fuction'])\n",
        "freq.append([np.sqrt(data[Plot_Column]).values.reshape(-1) , 'Square Root Function'])\n",
        "freq.append([np.sqrt(data[Plot_Column]).diff().values.reshape(-1) , 'Difference of Square Root Function'])\n",
        "freq.append([np.cbrt(data[Plot_Column]).values.reshape(-1) , 'Cube Root Function'])\n",
        "freq.append([np.cbrt(data[Plot_Column]).diff().values.reshape(-1) , 'Difference of Cube Root Function'])\n",
        "freq.append([np.sqrt(np.sqrt(data[Plot_Column])).values.reshape(-1) , 'Quad Root Function'])\n",
        "freq.append([np.sqrt(np.sqrt(data[Plot_Column])).diff().values.reshape(-1) , 'Difference of Quad Root Function'])\n",
        "freq.append([np.square(data[Plot_Column]).values.reshape(-1) , 'Square Function'])\n",
        "freq.append([np.square(data[Plot_Column]).diff().values.reshape(-1) , 'Difference of Square Function'])\n",
        "freq.append([preprocessing.MinMaxScaler().fit_transform(data[Plot_Column].values.reshape(-1,1)).reshape(-1) , 'Min Max Scaler Function'])\n",
        "freq.append([preprocessing.RobustScaler().fit_transform(data[Plot_Column].values.reshape(-1,1)).reshape(-1) , 'Robust Scaler Function'])\n",
        "freq.append([preprocessing.StandardScaler().fit_transform(data[Plot_Column].values.reshape(-1,1)).reshape(-1) , 'Standard Scaler Function'])\n",
        "freq.append([preprocessing.PowerTransformer().fit_transform(data[Plot_Column].values.reshape(-1,1)).reshape(-1) , 'Power Transformer Scaler'])\n",
        "freq.append([sm.tsa.filters.bkfilter(data[Plot_Column]).values.reshape(-1) , 'BKFilter Band Pass Filter'])\n",
        "freq.append([sm.tsa.filters.hpfilter(data[Plot_Column])[1].values.reshape(-1) , 'HPFilter Smoothing Filter'])\n",
        "freq.append([BoxCoxEndogTransformer().fit_transform(data[Plot_Column]+0.00000001)[0], 'BoxCoxEndogTransformer Filter'])\n",
        "\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=len(freq)).as_hex())\n",
        "Plt_Row = math.ceil(len(freq)/Plt_Col)\n",
        "plt.figure(figsize=(Graphs_Width,Graphs_Height*Plt_Row/Plt_Col))\n",
        "\n",
        "for i,j in enumerate(freq):\n",
        "  plt.subplot(Plt_Row , Plt_Col , i+1)\n",
        "  # plt.bar(range(len(j[0])) , j[0], width = 0.2 , linewidth = 0 , color = list(sns.color_palette(Style_Color,n_colors=len(j[0])).as_hex()) )\n",
        "  plt.plot(j[0], label = j[1] , color = plot_color[i])\n",
        "  plt.fill_between(list(range(len(j[0]))) ,0, j[0] ,color = plot_color[i] , alpha =0.4)\n",
        "  \n",
        "  plt.legend(loc = 2)\n",
        "  # plt.title(j[1]+' Over Data')\n",
        "  # plt.xlabel('Days Passed Since {}'.format(data.Date.min()))\n",
        "  \n",
        "plt.suptitle(Sup_Title, fontsize = 29)\n",
        "plt.subplots_adjust(top=SubPlot_Top)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3pzZTT4wYg8"
      },
      "source": [
        "India_['Confirmed'].rolling(5, min_periods = 1).median()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUn15y06NGTB"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://cdn2.iconfinder.com/data/icons/round-varieties/60/Rounded_-_High_Ultra_Colour19_-_Graph-256.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Month Wise Effect of Corona Virus in States of India</h2></center><br>\n",
        "\n",
        "Plot_Column = \"Confirmed Recovered Deceased Confirmed_ Recovered_ Deceased_ Tested Active Death-Rate-(per-100) Cure-Rate-(per-100)\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_', 'Negative', 'Confirmed Recovered Deceased','Confirmed_ Recovered_ Deceased_','Confirmed Recovered Deceased Confirmed_ Recovered_ Deceased_','Confirmed Recovered Deceased Confirmed_ Recovered_ Deceased_ Tested Active Death-Rate-(per-100) Cure-Rate-(per-100)']\n",
        "Location = \"India\" #@param ['Kerala', 'Delhi', 'Telangana', 'India', 'Rajasthan', 'Haryana','UP', 'Ladakh', 'TN', 'J&K', 'Karnataka', 'Maharashtra', 'Punjab','Andra P', 'HP', 'Uttarakhand', 'Odisha', 'Puducherry','West Bengal', 'Chandigarh', 'Chhattisgarh', 'Gujarat', 'MP','Bihar', 'Manipur', 'Goa', 'Mizoram', 'A&N', 'Assam', 'Jharkhand','Arun P', 'Nagaland', 'Tripura', 'D&D', 'Meghalaya', 'Sikkim','Other']\n",
        "Apply_Rolling = 10 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "Plot_Method = \"Median\" #@param [\"None\", \"Median\", \"Mean\", \"Max\", \"Min\"]\n",
        "\n",
        "Fill_Below = True #@param {type:\"boolean\"}\n",
        "data = Completed_[Completed_.State == Location]\n",
        "Plot_Column = Plot_Column.split(' ')\n",
        "\n",
        "\n",
        "n_cols = len(India_['Month'].unique())\n",
        "n_rows = len(Plot_Column)\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=n_rows*n_cols).as_hex())\n",
        "plt.figure(figsize = (Graphs_Width*4.5,int(Graphs_Height/2)*n_rows))\n",
        "i=0\n",
        "\n",
        "for plot_row in Plot_Column:\n",
        "  plot_row = plot_row.replace('-',' ')\n",
        "  for col in data['Month'].unique():\n",
        "    temp = data[data['Month'] == col].reset_index(drop = True)\n",
        "    plt.subplot( n_rows , n_cols , i+1)\n",
        "    if Plot_Method == 'Mean':\n",
        "      plt.plot(temp[plot_row].rolling(Apply_Rolling, min_periods = 1).mean() , color = plot_color[i] , label = '{} Rolling Mean'.format(col))\n",
        "    elif Plot_Method == 'Median':\n",
        "      plt.plot(temp[plot_row].rolling(Apply_Rolling, min_periods = 1).median() , color = plot_color[i] , label = '{} Rolling Median'.format(col))\n",
        "    elif Plot_Method == 'Max':\n",
        "      plt.plot(temp[plot_row].rolling(Apply_Rolling, min_periods = 1).max() , color = plot_color[i] , label = '{} Rolling Max'.format(col))\n",
        "    elif Plot_Method == 'Min':\n",
        "      plt.plot(temp[plot_row].rolling(Apply_Rolling, min_periods = 1).min() , color = plot_color[i] , label = '{} Rolling Min'.format(col))\n",
        "    else:\n",
        "      plt.plot(temp[plot_row] , color = plot_color[i] , label = '{}'.format(col))\n",
        "      \n",
        "    if Fill_Below:\n",
        "      plt.fill_between(list(temp.index) ,0, temp[plot_row] ,color = plot_color[i] , alpha =0.4, label = '{}'.format(col))\n",
        "  \n",
        "    plt.legend()\n",
        "    plt.title('{}  in Month {}'.format(plot_row.replace('_',' (Per Day) ') , col) , fontsize = 19)\n",
        "    i+=1\n",
        "plt.plot()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5BTCNHPzke4"
      },
      "source": [
        "# COVID-19 Analysis At District Level (India)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "94YVwFEfzi_V"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://images.vexels.com/media/users/3/151175/isolated/preview/c8cccfd752a2c029daaa084aca6bb2bc-percent-pie-chart-doodle-by-vexels.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Plot Corona Virus Cases in Countries of Districts of India (Pie Chart)</h2></center><br>\n",
        "Plot_By = \"Confirmed\" #@param ['Confirmed', 'Recovered', 'Deceased','Tested','Active']\n",
        "Date = \"2020-12-08\" #@param {type:\"date\"}\n",
        "\n",
        "display(Markdown(\"<h2> District WISE PIE CHART CASES of 2019-nCoV</h2>\"))\n",
        "if Date not in District_['Date'].astype(str).unique():\n",
        "  Date = District_['Date'].max()\n",
        "\n",
        "temp = District_[District_['District']!= 'Unknown']\n",
        "fig = px.sunburst(temp[temp['Date'] == Date].sort_values(by=Plot_By, ascending=False).reset_index(drop=True), \n",
        "                  path=[\"State\" , \"District\"], values=Plot_By, height=700,\n",
        "                 title='Number of {} Reported as {}'.format(Plot_By.replace('_',' (New) ').title() , Date),\n",
        "                 color_discrete_sequence = px.colors.qualitative.Prism ,)\n",
        "fig.data[0].textinfo = 'label+text+value'\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "3HQo8YDb85d1"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='http://www.pngpix.com/wp-content/uploads/2016/10/PNGPIX-COM-Pie-Chart-PNG-Transparent-Image.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Plot Corona Virus Cases in District on Day (Pie Chart)</h2></center><br>\n",
        "Plot_District = \"Delhi\" #@param ['Agar Malwa', 'Agra', 'Ahmedabad', 'Ahmednagar','Airport Quarantine', 'Aizawl', 'Ajmer', 'Akola', 'Alappuzha','Aligarh', 'Alipurduar', 'Alirajpur', 'Almora', 'Alwar', 'Ambala','Ambedkar Nagar', 'Amethi', 'Amravati', 'Amreli', 'Amritsar','Amroha', 'Anand', 'Anantapur', 'Anantnag', 'Angul', 'Anjaw','Anuppur', 'Araria', 'Aravalli', 'Ariyalur', 'Arwal', 'Ashoknagar','Auraiya', 'Aurangabad', 'Ayodhya', 'Azamgarh', 'BSF Camp','Bagalkote', 'Bageshwar', 'Baghpat', 'Bahraich', 'Balaghat','Balangir', 'Balasore', 'Ballari', 'Ballia', 'Balod','Baloda Bazar', 'Balrampur', 'Bametara', 'Banaskantha', 'Banda','Bandipora', 'Banka', 'Bankura', 'Banswara', 'Barabanki','Baramulla', 'Baran', 'Bareilly', 'Bargarh', 'Barmer', 'Barnala','Barwani', 'Bastar', 'Basti', 'Bathinda', 'Beed', 'Begusarai','Belagavi', 'Bengaluru Rural', 'Bengaluru Urban', 'Betul','Bhadohi', 'Bhadrak', 'Bhagalpur', 'Bhandara', 'Bharatpur','Bharuch', 'Bhavnagar', 'Bhilwara', 'Bhind', 'Bhiwani', 'Bhojpur','Bhopal', 'Bidar', 'Bijapur', 'Bijnor', 'Bikaner', 'Bilaspur','Birbhum', 'Bokaro', 'Botad', 'Boudh', 'Budaun', 'Budgam','Bulandshahr', 'Buldhana', 'Bundi', 'Burhanpur', 'Buxar','Capital Complex', 'Chamarajanagara', 'Chamba', 'Chamoli','Champawat', 'Champhai', 'Chandauli', 'Chandigarh', 'Chandrapur','Changlang', 'Charkhi Dadri', 'Chatra', 'Chengalpattu', 'Chennai','Chhatarpur', 'Chhindwara', 'Chhota Udaipur', 'Chikkaballapura','Chikkamagaluru', 'Chitradurga', 'Chitrakoot', 'Chittoor','Chittorgarh', 'Churu', 'Coimbatore', 'Cooch Behar', 'Cuddalore','Cuttack', 'Dadra and Nagar Haveli', 'Dahod','Dakshin Bastar Dantewada', 'Dakshin Dinajpur', 'Dakshina Kannada','Daman', 'Damoh', 'Dang', 'Darbhanga', 'Darjeeling', 'Datia','Dausa', 'Davanagere', 'Dehradun', 'Delhi', 'Deogarh', 'Deoghar','Deoria', 'Devbhumi Dwarka', 'Dewas', 'Dhalai', 'Dhamtari','Dhanbad', 'Dhar', 'Dharmapuri', 'Dharwad', 'Dhenkanal', 'Dholpur','Dhule', 'Dimapur', 'Dindigul', 'Dindori', 'Diu', 'Doda', 'Dumka','Dungarpur', 'Durg', 'East Champaran', 'East Garo Hills','East Godavari', 'East Jaintia Hills', 'East Kameng','East Khasi Hills', 'East Siang', 'East Singhbhum', 'Ernakulam','Erode', 'Etah', 'Etawah', 'Evacuees', 'Faridabad', 'Faridkot','Farrukhabad', 'Fatehabad', 'Fatehgarh Sahib', 'Fatehpur','Fazilka', 'Ferozepur', 'Firozabad', 'Foreign Evacuees', 'Gadag','Gadchiroli', 'Gajapati', 'Ganderbal', 'Gandhinagar', 'Ganganagar','Ganjam', 'Garhwa', 'Gariaband', 'Gaurela Pendra Marwahi','Gautam Buddha Nagar', 'Gaya', 'Ghaziabad', 'Ghazipur','Gir Somnath', 'Giridih', 'Godda', 'Gomati', 'Gonda', 'Gondia','Gopalganj', 'Gorakhpur', 'Gumla', 'Guna', 'Guntur', 'Gurdaspur','Gurugram', 'Gwalior', 'Hamirpur', 'Hanumangarh', 'Hapur', 'Harda','Hardoi', 'Haridwar', 'Hassan', 'Hathras', 'Haveri', 'Hazaribagh','Hingoli', 'Hisar', 'Hnahthial', 'Hooghly', 'Hoshangabad','Hoshiarpur', 'Howrah', 'Idukki', 'Indore', 'Italians', 'Jabalpur','Jagatsinghpur', 'Jaipur', 'Jaisalmer', 'Jajpur', 'Jalandhar','Jalaun', 'Jalgaon', 'Jalna', 'Jalore', 'Jalpaiguri', 'Jammu','Jamnagar', 'Jamtara', 'Jamui', 'Janjgir Champa', 'Jashpur','Jaunpur', 'Jehanabad', 'Jhabua', 'Jhajjar', 'Jhalawar', 'Jhansi','Jhargram', 'Jharsuguda', 'Jhunjhunu', 'Jind', 'Jodhpur','Junagadh', 'Kabeerdham', 'Kaimur', 'Kaithal', 'Kalaburagi','Kalahandi', 'Kalimpong', 'Kallakurichi', 'Kamle', 'Kancheepuram','Kandhamal', 'Kangra', 'Kannauj', 'Kannur', 'Kanpur Dehat','Kanpur Nagar', 'Kanyakumari', 'Kapurthala', 'Karaikal', 'Karauli','Kargil', 'Karnal', 'Karur', 'Kasaragod', 'Kasganj', 'Kathua','Katihar', 'Katni', 'Kaushambi', 'Kendrapara', 'Kendujhar','Khagaria', 'Khandwa', 'Khargone', 'Khawzawl', 'Kheda', 'Khordha','Khowai', 'Khunti', 'Kinnaur', 'Kiphire', 'Kishanganj', 'Kishtwar','Kodagu', 'Koderma', 'Kohima', 'Kolar', 'Kolasib', 'Kolhapur','Kolkata', 'Kollam', 'Kondagaon', 'Koppal', 'Koraput', 'Korba','Koriya', 'Kota', 'Kottayam', 'Kozhikode', 'Kra Daadi', 'Krishna','Krishnagiri', 'Kulgam', 'Kullu', 'Kupwara', 'Kurnool','Kurukshetra', 'Kurung Kumey', 'Kushinagar', 'Kutch','Lahaul and Spiti', 'Lakhimpur Kheri', 'Lakhisarai', 'Lalitpur','Latehar', 'Latur', 'Lawngtlai', 'Leh', 'Lepa Rada', 'Lohardaga','Lohit', 'Longding', 'Longleng', 'Lower Dibang Valley','Lower Siang', 'Lower Subansiri', 'Lucknow', 'Ludhiana', 'Lunglei','Madhepura', 'Madhubani', 'Madurai', 'Maharajganj', 'Mahasamund','Mahe', 'Mahendragarh', 'Mahisagar', 'Mahoba', 'Mainpuri','Malappuram', 'Malda', 'Malkangiri', 'Mamit', 'Mandi', 'Mandla','Mandsaur', 'Mandya', 'Mansa', 'Mathura', 'Mau', 'Mayurbhanj','Meerut', 'Mehsana', 'Mirzapur', 'Moga', 'Mokokchung', 'Mon','Moradabad', 'Morbi', 'Morena', 'Mumbai', 'Mungeli', 'Munger','Murshidabad', 'Muzaffarnagar', 'Muzaffarpur', 'Mysuru','Nabarangapur', 'Nadia', 'Nagapattinam', 'Nagaur', 'Nagpur','Nainital', 'Nalanda', 'Namakkal', 'Namsai', 'Nanded', 'Nandurbar','Narayanpur', 'Narmada', 'Narsinghpur', 'Nashik', 'Navsari','Nawada', 'Nayagarh', 'Neemuch', 'Nilgiris', 'Niwari','North 24 Parganas', 'North Garo Hills', 'North Tripura','Nuapada', 'Nuh', 'Osmanabad', 'Other Region', 'Other State','Others', 'Pakke Kessang', 'Pakur', 'Palakkad', 'Palamu','Palghar', 'Pali', 'Palwal', 'Panchkula', 'Panchmahal', 'Panipat','Panna', 'Papum Pare', 'Parbhani', 'Paschim Bardhaman','Paschim Medinipur', 'Patan', 'Pathanamthitta', 'Pathankot','Patiala', 'Patna', 'Pauri Garhwal', 'Perambalur', 'Peren', 'Phek','Pilibhit', 'Pithoragarh', 'Porbandar', 'Prakasam', 'Pratapgarh','Prayagraj', 'Puducherry', 'Pudukkottai', 'Pulwama', 'Punch','Pune', 'Purba Bardhaman', 'Purba Medinipur', 'Puri', 'Purnia','Purulia', 'Rae Bareli', 'Raichur', 'Raigad', 'Raigarh','Railway Quarantine', 'Raipur', 'Raisen', 'Rajgarh', 'Rajkot','Rajnandgaon', 'Rajouri', 'Rajsamand', 'Ramanagara','Ramanathapuram', 'Ramban', 'Ramgarh', 'Rampur', 'Ranchi','Ranipet', 'Ratlam', 'Ratnagiri', 'Rayagada', 'Reasi', 'Rewa','Rewari', 'Ribhoi', 'Rohtak', 'Rohtas', 'Rudraprayag', 'Rupnagar','S.A.S. Nagar', 'S.P.S. Nellore', 'Sabarkantha', 'Sagar','Saharanpur', 'Saharsa', 'Sahibganj', 'Saiha', 'Saitual', 'Salem','Samastipur', 'Samba', 'Sambalpur', 'Sambhal', 'Sangli', 'Sangrur','Sant Kabir Nagar', 'Saraikela-Kharsawan', 'Saran', 'Satara','Satna', 'Sawai Madhopur', 'Sehore', 'Seoni', 'Serchhip','Shahdol', 'Shahid Bhagat Singh Nagar', 'Shahjahanpur', 'Shajapur','Shamli', 'Sheikhpura', 'Sheohar', 'Sheopur', 'Shi Yomi', 'Shimla','Shivamogga', 'Shivpuri', 'Shopiyan', 'Shrawasti', 'Siang','Siddharthnagar', 'Sidhi', 'Sikar', 'Simdega', 'Sindhudurg','Singrauli', 'Sipahijala', 'Sirmaur', 'Sirohi', 'Sirsa','Sitamarhi', 'Sitapur', 'Sivaganga', 'Siwan', 'Solan', 'Solapur','Sonbhadra', 'Sonipat', 'South 24 Parganas', 'South Garo Hills','South Tripura', 'South West Garo Hills', 'South West Khasi Hills','Sri Muktsar Sahib', 'Srikakulam', 'Srinagar', 'State Pool','Subarnapur', 'Sukma', 'Sultanpur', 'Sundargarh', 'Supaul','Surajpur', 'Surat', 'Surendranagar', 'Surguja', 'Tapi','Tarn Taran', 'Tawang', 'Tehri Garhwal', 'Tenkasi', 'Thane','Thanjavur', 'Theni', 'Thiruvallur', 'Thiruvananthapuram','Thiruvarur', 'Thoothukkudi', 'Thrissur', 'Tikamgarh', 'Tirap','Tiruchirappalli', 'Tirunelveli', 'Tirupathur', 'Tiruppur','Tiruvannamalai', 'Tonk', 'Tuensang', 'Tumakuru', 'Udaipur','Udham Singh Nagar', 'Udhampur', 'Udupi', 'Ujjain', 'Umaria','Una', 'Unknown', 'Unnao', 'Unokoti', 'Upper Dibang Valley','Upper Siang', 'Upper Subansiri', 'Uttar Bastar Kanker','Uttar Dinajpur', 'Uttara Kannada', 'Uttarkashi', 'Vadodara','Vaishali', 'Valsad', 'Varanasi', 'Vellore', 'Vidisha','Vijayapura', 'Viluppuram', 'Virudhunagar', 'Visakhapatnam','Vizianagaram', 'Wardha', 'Washim', 'Wayanad', 'West Champaran','West Garo Hills', 'West Godavari', 'West Jaintia Hills','West Kameng', 'West Khasi Hills', 'West Siang', 'West Singhbhum','West Tripura', 'Wokha', 'Y.S.R. Kadapa', 'Yadgir', 'Yamunanagar','Yanam', 'Yavatmal', 'Zunheboto']\n",
        "Date = \"2020-12-06\" #@param {type:\"date\"}\n",
        "\n",
        "\n",
        "# display(Markdown(\"<h2> District WISE PIE CHART CASES of 2019-nCoV</h2>\"))\n",
        "if Date not in District_['Date'].astype(str).unique():\n",
        "  Date = District_['Date'].max()\n",
        "\n",
        "Plot_Pie = True\n",
        "if Plot_Pie:\n",
        "  temp = District_[District_['District'] == Plot_District]\n",
        "  temp = temp[temp['Date'] == Date]\n",
        "  dic_temp = dict(\n",
        "              total_values = temp[['Confirmed', 'Recovered', 'Deceased']].values[0],\n",
        "              daily_values = temp[['Confirmed_', 'Recovered_', 'Deceased_']].values[0],\n",
        "              names = ['Confirmed', 'Recovered', 'Deceased'],\n",
        "              par = ['Corona Cases','Corona Cases','Corona Cases']\n",
        "              )\n",
        "  fig = make_subplots(1, 2, specs=[[{\"type\": \"domain\"}, {\"type\": \"domain\"}]],)\n",
        "  fig = px.sunburst(dic_temp, names = 'names',\n",
        "                   parents = 'par',\n",
        "                   values='daily_values', height=700,\n",
        "                 title='Number of {} Cases Reported as {}'.format('New' , Date),\n",
        "                 color_discrete_sequence = px.colors.qualitative.T10)\n",
        "  fig.data[0].textinfo = 'label+text+value'\n",
        "  fig.show()\n",
        "  fig = px.sunburst(dic_temp, names = 'names',\n",
        "                   parents = 'par',\n",
        "                   values='total_values', height=700,\n",
        "                 title='Number of {} Cases Reported as {}'.format('Total' , Date),\n",
        "                 color_discrete_sequence = px.colors.qualitative.T10)\n",
        "\n",
        "  fig.data[0].textinfo = 'label+text+value'\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "svXNO8-UfUiH"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='http://icons.iconarchive.com/icons/paomedia/small-n-flat/512/file-excel-icon.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Plot Corona Virus Cases in District (Table View)</h2></center><br>\n",
        "Plot_District = \"Delhi\" #@param ['Agar Malwa', 'Agra', 'Ahmedabad', 'Ahmednagar','Airport Quarantine', 'Aizawl', 'Ajmer', 'Akola', 'Alappuzha','Aligarh', 'Alipurduar', 'Alirajpur', 'Almora', 'Alwar', 'Ambala','Ambedkar Nagar', 'Amethi', 'Amravati', 'Amreli', 'Amritsar','Amroha', 'Anand', 'Anantapur', 'Anantnag', 'Angul', 'Anjaw','Anuppur', 'Araria', 'Aravalli', 'Ariyalur', 'Arwal', 'Ashoknagar','Auraiya', 'Aurangabad', 'Ayodhya', 'Azamgarh', 'BSF Camp','Bagalkote', 'Bageshwar', 'Baghpat', 'Bahraich', 'Balaghat','Balangir', 'Balasore', 'Ballari', 'Ballia', 'Balod','Baloda Bazar', 'Balrampur', 'Bametara', 'Banaskantha', 'Banda','Bandipora', 'Banka', 'Bankura', 'Banswara', 'Barabanki','Baramulla', 'Baran', 'Bareilly', 'Bargarh', 'Barmer', 'Barnala','Barwani', 'Bastar', 'Basti', 'Bathinda', 'Beed', 'Begusarai','Belagavi', 'Bengaluru Rural', 'Bengaluru Urban', 'Betul','Bhadohi', 'Bhadrak', 'Bhagalpur', 'Bhandara', 'Bharatpur','Bharuch', 'Bhavnagar', 'Bhilwara', 'Bhind', 'Bhiwani', 'Bhojpur','Bhopal', 'Bidar', 'Bijapur', 'Bijnor', 'Bikaner', 'Bilaspur','Birbhum', 'Bokaro', 'Botad', 'Boudh', 'Budaun', 'Budgam','Bulandshahr', 'Buldhana', 'Bundi', 'Burhanpur', 'Buxar','Capital Complex', 'Chamarajanagara', 'Chamba', 'Chamoli','Champawat', 'Champhai', 'Chandauli', 'Chandigarh', 'Chandrapur','Changlang', 'Charkhi Dadri', 'Chatra', 'Chengalpattu', 'Chennai','Chhatarpur', 'Chhindwara', 'Chhota Udaipur', 'Chikkaballapura','Chikkamagaluru', 'Chitradurga', 'Chitrakoot', 'Chittoor','Chittorgarh', 'Churu', 'Coimbatore', 'Cooch Behar', 'Cuddalore','Cuttack', 'Dadra and Nagar Haveli', 'Dahod','Dakshin Bastar Dantewada', 'Dakshin Dinajpur', 'Dakshina Kannada','Daman', 'Damoh', 'Dang', 'Darbhanga', 'Darjeeling', 'Datia','Dausa', 'Davanagere', 'Dehradun', 'Delhi', 'Deogarh', 'Deoghar','Deoria', 'Devbhumi Dwarka', 'Dewas', 'Dhalai', 'Dhamtari','Dhanbad', 'Dhar', 'Dharmapuri', 'Dharwad', 'Dhenkanal', 'Dholpur','Dhule', 'Dimapur', 'Dindigul', 'Dindori', 'Diu', 'Doda', 'Dumka','Dungarpur', 'Durg', 'East Champaran', 'East Garo Hills','East Godavari', 'East Jaintia Hills', 'East Kameng','East Khasi Hills', 'East Siang', 'East Singhbhum', 'Ernakulam','Erode', 'Etah', 'Etawah', 'Evacuees', 'Faridabad', 'Faridkot','Farrukhabad', 'Fatehabad', 'Fatehgarh Sahib', 'Fatehpur','Fazilka', 'Ferozepur', 'Firozabad', 'Foreign Evacuees', 'Gadag','Gadchiroli', 'Gajapati', 'Ganderbal', 'Gandhinagar', 'Ganganagar','Ganjam', 'Garhwa', 'Gariaband', 'Gaurela Pendra Marwahi','Gautam Buddha Nagar', 'Gaya', 'Ghaziabad', 'Ghazipur','Gir Somnath', 'Giridih', 'Godda', 'Gomati', 'Gonda', 'Gondia','Gopalganj', 'Gorakhpur', 'Gumla', 'Guna', 'Guntur', 'Gurdaspur','Gurugram', 'Gwalior', 'Hamirpur', 'Hanumangarh', 'Hapur', 'Harda','Hardoi', 'Haridwar', 'Hassan', 'Hathras', 'Haveri', 'Hazaribagh','Hingoli', 'Hisar', 'Hnahthial', 'Hooghly', 'Hoshangabad','Hoshiarpur', 'Howrah', 'Idukki', 'Indore', 'Italians', 'Jabalpur','Jagatsinghpur', 'Jaipur', 'Jaisalmer', 'Jajpur', 'Jalandhar','Jalaun', 'Jalgaon', 'Jalna', 'Jalore', 'Jalpaiguri', 'Jammu','Jamnagar', 'Jamtara', 'Jamui', 'Janjgir Champa', 'Jashpur','Jaunpur', 'Jehanabad', 'Jhabua', 'Jhajjar', 'Jhalawar', 'Jhansi','Jhargram', 'Jharsuguda', 'Jhunjhunu', 'Jind', 'Jodhpur','Junagadh', 'Kabeerdham', 'Kaimur', 'Kaithal', 'Kalaburagi','Kalahandi', 'Kalimpong', 'Kallakurichi', 'Kamle', 'Kancheepuram','Kandhamal', 'Kangra', 'Kannauj', 'Kannur', 'Kanpur Dehat','Kanpur Nagar', 'Kanyakumari', 'Kapurthala', 'Karaikal', 'Karauli','Kargil', 'Karnal', 'Karur', 'Kasaragod', 'Kasganj', 'Kathua','Katihar', 'Katni', 'Kaushambi', 'Kendrapara', 'Kendujhar','Khagaria', 'Khandwa', 'Khargone', 'Khawzawl', 'Kheda', 'Khordha','Khowai', 'Khunti', 'Kinnaur', 'Kiphire', 'Kishanganj', 'Kishtwar','Kodagu', 'Koderma', 'Kohima', 'Kolar', 'Kolasib', 'Kolhapur','Kolkata', 'Kollam', 'Kondagaon', 'Koppal', 'Koraput', 'Korba','Koriya', 'Kota', 'Kottayam', 'Kozhikode', 'Kra Daadi', 'Krishna','Krishnagiri', 'Kulgam', 'Kullu', 'Kupwara', 'Kurnool','Kurukshetra', 'Kurung Kumey', 'Kushinagar', 'Kutch','Lahaul and Spiti', 'Lakhimpur Kheri', 'Lakhisarai', 'Lalitpur','Latehar', 'Latur', 'Lawngtlai', 'Leh', 'Lepa Rada', 'Lohardaga','Lohit', 'Longding', 'Longleng', 'Lower Dibang Valley','Lower Siang', 'Lower Subansiri', 'Lucknow', 'Ludhiana', 'Lunglei','Madhepura', 'Madhubani', 'Madurai', 'Maharajganj', 'Mahasamund','Mahe', 'Mahendragarh', 'Mahisagar', 'Mahoba', 'Mainpuri','Malappuram', 'Malda', 'Malkangiri', 'Mamit', 'Mandi', 'Mandla','Mandsaur', 'Mandya', 'Mansa', 'Mathura', 'Mau', 'Mayurbhanj','Meerut', 'Mehsana', 'Mirzapur', 'Moga', 'Mokokchung', 'Mon','Moradabad', 'Morbi', 'Morena', 'Mumbai', 'Mungeli', 'Munger','Murshidabad', 'Muzaffarnagar', 'Muzaffarpur', 'Mysuru','Nabarangapur', 'Nadia', 'Nagapattinam', 'Nagaur', 'Nagpur','Nainital', 'Nalanda', 'Namakkal', 'Namsai', 'Nanded', 'Nandurbar','Narayanpur', 'Narmada', 'Narsinghpur', 'Nashik', 'Navsari','Nawada', 'Nayagarh', 'Neemuch', 'Nilgiris', 'Niwari','North 24 Parganas', 'North Garo Hills', 'North Tripura','Nuapada', 'Nuh', 'Osmanabad', 'Other Region', 'Other State','Others', 'Pakke Kessang', 'Pakur', 'Palakkad', 'Palamu','Palghar', 'Pali', 'Palwal', 'Panchkula', 'Panchmahal', 'Panipat','Panna', 'Papum Pare', 'Parbhani', 'Paschim Bardhaman','Paschim Medinipur', 'Patan', 'Pathanamthitta', 'Pathankot','Patiala', 'Patna', 'Pauri Garhwal', 'Perambalur', 'Peren', 'Phek','Pilibhit', 'Pithoragarh', 'Porbandar', 'Prakasam', 'Pratapgarh','Prayagraj', 'Puducherry', 'Pudukkottai', 'Pulwama', 'Punch','Pune', 'Purba Bardhaman', 'Purba Medinipur', 'Puri', 'Purnia','Purulia', 'Rae Bareli', 'Raichur', 'Raigad', 'Raigarh','Railway Quarantine', 'Raipur', 'Raisen', 'Rajgarh', 'Rajkot','Rajnandgaon', 'Rajouri', 'Rajsamand', 'Ramanagara','Ramanathapuram', 'Ramban', 'Ramgarh', 'Rampur', 'Ranchi','Ranipet', 'Ratlam', 'Ratnagiri', 'Rayagada', 'Reasi', 'Rewa','Rewari', 'Ribhoi', 'Rohtak', 'Rohtas', 'Rudraprayag', 'Rupnagar','S.A.S. Nagar', 'S.P.S. Nellore', 'Sabarkantha', 'Sagar','Saharanpur', 'Saharsa', 'Sahibganj', 'Saiha', 'Saitual', 'Salem','Samastipur', 'Samba', 'Sambalpur', 'Sambhal', 'Sangli', 'Sangrur','Sant Kabir Nagar', 'Saraikela-Kharsawan', 'Saran', 'Satara','Satna', 'Sawai Madhopur', 'Sehore', 'Seoni', 'Serchhip','Shahdol', 'Shahid Bhagat Singh Nagar', 'Shahjahanpur', 'Shajapur','Shamli', 'Sheikhpura', 'Sheohar', 'Sheopur', 'Shi Yomi', 'Shimla','Shivamogga', 'Shivpuri', 'Shopiyan', 'Shrawasti', 'Siang','Siddharthnagar', 'Sidhi', 'Sikar', 'Simdega', 'Sindhudurg','Singrauli', 'Sipahijala', 'Sirmaur', 'Sirohi', 'Sirsa','Sitamarhi', 'Sitapur', 'Sivaganga', 'Siwan', 'Solan', 'Solapur','Sonbhadra', 'Sonipat', 'South 24 Parganas', 'South Garo Hills','South Tripura', 'South West Garo Hills', 'South West Khasi Hills','Sri Muktsar Sahib', 'Srikakulam', 'Srinagar', 'State Pool','Subarnapur', 'Sukma', 'Sultanpur', 'Sundargarh', 'Supaul','Surajpur', 'Surat', 'Surendranagar', 'Surguja', 'Tapi','Tarn Taran', 'Tawang', 'Tehri Garhwal', 'Tenkasi', 'Thane','Thanjavur', 'Theni', 'Thiruvallur', 'Thiruvananthapuram','Thiruvarur', 'Thoothukkudi', 'Thrissur', 'Tikamgarh', 'Tirap','Tiruchirappalli', 'Tirunelveli', 'Tirupathur', 'Tiruppur','Tiruvannamalai', 'Tonk', 'Tuensang', 'Tumakuru', 'Udaipur','Udham Singh Nagar', 'Udhampur', 'Udupi', 'Ujjain', 'Umaria','Una', 'Unknown', 'Unnao', 'Unokoti', 'Upper Dibang Valley','Upper Siang', 'Upper Subansiri', 'Uttar Bastar Kanker','Uttar Dinajpur', 'Uttara Kannada', 'Uttarkashi', 'Vadodara','Vaishali', 'Valsad', 'Varanasi', 'Vellore', 'Vidisha','Vijayapura', 'Viluppuram', 'Virudhunagar', 'Visakhapatnam','Vizianagaram', 'Wardha', 'Washim', 'Wayanad', 'West Champaran','West Garo Hills', 'West Godavari', 'West Jaintia Hills','West Kameng', 'West Khasi Hills', 'West Siang', 'West Singhbhum','West Tripura', 'Wokha', 'Y.S.R. Kadapa', 'Yadgir', 'Yamunanagar','Yanam', 'Yavatmal', 'Zunheboto']\n",
        "# For Tabular Plot\n",
        "Sort_By = \"Confirmed\" #@param ['Confirmed', 'Recovered', 'Deceased','Tested','Active','Confirmed_', 'Recovered_', 'Deceased_','Death Rate (per 100)', 'Cure Rate (per 100)']\n",
        "Plot_Last = 14 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "\n",
        "display(Markdown(\"<h2> STATE WISE CONFIRMED, DEATH AND CURED CASES of 2019-nCoV AS OF {}</h2>\".format(District_['Date'].max())))\n",
        "temp = District_[District_['District'] == Plot_District]\n",
        "temp['Date'] = temp['Date'].astype(str)\n",
        "# tabular_index = temp[temp['Date'] == Date].index.values[0]\n",
        "temp[['Date','District','Confirmed', 'Recovered', 'Deceased','Active','Confirmed_','Recovered_','Deceased_','Tested','Death Rate (per 100)','Cure Rate (per 100)']]\\\n",
        "                          .sort_values(Sort_By, ascending= False).fillna(0)\\\n",
        "                          .head(Plot_Last)\\\n",
        "                          .style\\\n",
        "                          .background_gradient(cmap='YlOrBr',subset=[\"Confirmed\"])\\\n",
        "                          .background_gradient(cmap='Reds',subset=[\"Deceased\"])\\\n",
        "                          .background_gradient(cmap='Greens',subset=[\"Recovered\"])\\\n",
        "                          .background_gradient(cmap='Blues',subset=[\"Active\"])\\\n",
        "                          .background_gradient(cmap='Reds',subset=[\"Death Rate (per 100)\"])\\\n",
        "                          .background_gradient(cmap='Greens',subset=[\"Cure Rate (per 100)\"])\\\n",
        "                          .background_gradient(cmap='crest',subset=[\"Confirmed_\"])\\\n",
        "                          .background_gradient(cmap='PuRd',subset=[\"Recovered_\"])\\\n",
        "                          .background_gradient(cmap='Blues',subset=[\"Deceased_\"])\\\n",
        "                          .background_gradient(cmap='rocket',subset=[\"Tested\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Kwh3HnSOgntD"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://images.vexels.com/media/users/3/151175/isolated/preview/c8cccfd752a2c029daaa084aca6bb2bc-percent-pie-chart-doodle-by-vexels.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Plot Corona Virus Cases in Countries of Districts of India (Bar Chart)</h2></center><br>\n",
        "Plot_State = \"Uttar Pradesh\" #@param [\"India\",'Andaman and Nicobar Islands', 'Andhra Pradesh','Arunachal Pradesh', 'Assam', 'Bihar', 'Chandigarh','Chhattisgarh', 'Dadra and Nagar Haveli and Daman and Diu','Gujarat', 'Haryana', 'Himachal Pradesh','Jammu and Kashmir', 'Jharkhand', 'Karnataka', 'Kerala', 'Ladakh','Madhya Pradesh', 'Maharashtra', 'Manipur', 'Meghalaya', 'Mizoram','Nagaland', 'Odisha', 'Puducherry', 'Punjab', 'Rajasthan', 'Tamil Nadu', 'Telangana', 'Tripura', 'Uttar Pradesh','Uttarakhand', 'West Bengal']\n",
        "Plot_By = \"Confirmed Recovered Deceased\" #@param ['Confirmed', 'Recovered', 'Deceased','Tested','Active','Confirmed Recovered Deceased' , 'Confirmed_','Recovered_', 'Deceased_' , 'Confirmed_ Recovered_ Deceased_']\n",
        "Plot_Top = 23 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "Date = \"2020-12-06\" #@param {type:\"date\"}\n",
        "Population_Ratio = True #@param {type:\"boolean\"}\n",
        "\n",
        "display(Markdown(\"<h2> District WISE Bar CHART CASES of 2019-nCoV</h2>\"))\n",
        "if Date not in District_['Date'].astype(str).unique():\n",
        "  Date = District_['Date'].max()\n",
        "  print('Invalid Date...Might Cause Error ...Reduce Date to Avoid any Error')\n",
        "Plot_By = Plot_By.split(' ')\n",
        "\n",
        "if Plot_State == 'India':\n",
        "  data = District_[District_['Date'] == Date]\n",
        "  if Population_Ratio:\n",
        "    for i in Plot_By:\n",
        "      data[i] = data[i]/data['Population']\n",
        "  data = data.sort_values(Plot_By[0] , ascending = False).head(Plot_Top)\n",
        "else:\n",
        "  data = District_[District_['State'] == Plot_State]\n",
        "  data = data[data['Date'] == Date]\n",
        "  if Population_Ratio:\n",
        "    for i in Plot_By:\n",
        "      data[i] = data[i]/data['Population']\n",
        "  data = data.sort_values(Plot_By[0] , ascending = False).head(Plot_Top)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "ax = plt.subplot(1,1,1)\n",
        "plt.suptitle(Sup_Title, fontsize = 29)\n",
        "plt.title('\\nTop {} Districts with SARS-CoV-2 Cases On {} \\n'.format(Plot_Top , Date) , fontsize = 19)\n",
        "\n",
        "Plot_Top = min(Plot_Top , data.shape[0])\n",
        "if len(Plot_By) ==1:\n",
        "  plt_by = Plot_By[0]\n",
        "  graph = sns.barplot(data=data,y='District',x= plt_by , saturation = Plot_Saturation , alpha = Plot_Alpha, palette =Style_Color, label = plt_by.replace('_', ' Daily ')+' Cases' , orient = 'h')\n",
        "\n",
        "else:\n",
        "  plot_color = list(sns.color_palette(Style_Color,n_colors=len(Plot_By)).as_hex())\n",
        "  for i,plt_by in enumerate(Plot_By):\n",
        "    # print(' Plot by',plt_by)\n",
        "    graph = sns.barplot(data=data,y='District', x= plt_by , \n",
        "                        saturation = Plot_Saturation , alpha = Plot_Alpha, \n",
        "                        color = plot_color[i], \n",
        "                        label = plt_by.replace('_', ' Daily ')+' Cases' , \n",
        "                        orient = 'h')\n",
        "plt.xlim(0,data[Plot_By[0]].max()+data[Plot_By[0]].max()/10 )\n",
        "plt.ylabel('Districts ')\n",
        "plt.xlabel('Number of Cases')\n",
        "plt.legend(loc = 8 , fontsize = 16)\n",
        "total_cases = data[Plot_By[0]].sum()\n",
        "for p in graph.patches[:int(Plot_Top)]:\n",
        "  _x = p.get_x() + p.get_width() \n",
        "  _y = p.get_y() + p.get_height()/2 + float(0.2)\n",
        "  value = ((p.get_width()/total_cases)*100)\n",
        "  if np.isnan(value):\n",
        "    value = 0.0\n",
        "  graph.text(_x , _y , ' {:.2f}%'.format(value) , ha = 'left', color = sns.color_palette('rocket')[1])\n",
        "plt.subplots_adjust(top=SubPlot_Top)\n",
        "\n",
        "plt.savefig(File_Prefix+'District Plot India  Bar Plot  on {} _{}.{}'.format(World_.date.max() , time.time() , Format_To_Save) , bbox_inches = 'tight')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eZFAa7SLnh1",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://cdn.pixabay.com/photo/2013/07/13/12/36/india-159941_960_720.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Plot Corona Virus Cases in India</h2></center><br>\n",
        "Plot_Column = \"C/R/D\" #@param ['C/R/D' , 'C/R/D/A', 'C/R/D(Daily)' ,'Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_', 'Negative']\n",
        "Plot_District = \"Ghaziabad\" #@param ['Agar Malwa', 'Agra', 'Ahmedabad', 'Ahmednagar','Airport Quarantine', 'Aizawl', 'Ajmer', 'Akola', 'Alappuzha','Aligarh', 'Alipurduar', 'Alirajpur', 'Almora', 'Alwar', 'Ambala','Ambedkar Nagar', 'Amethi', 'Amravati', 'Amreli', 'Amritsar','Amroha', 'Anand', 'Anantapur', 'Anantnag', 'Angul', 'Anjaw','Anuppur', 'Araria', 'Aravalli', 'Ariyalur', 'Arwal', 'Ashoknagar','Auraiya', 'Aurangabad', 'Ayodhya', 'Azamgarh', 'BSF Camp','Bagalkote', 'Bageshwar', 'Baghpat', 'Bahraich', 'Balaghat','Balangir', 'Balasore', 'Ballari', 'Ballia', 'Balod','Baloda Bazar', 'Balrampur', 'Bametara', 'Banaskantha', 'Banda','Bandipora', 'Banka', 'Bankura', 'Banswara', 'Barabanki','Baramulla', 'Baran', 'Bareilly', 'Bargarh', 'Barmer', 'Barnala','Barwani', 'Bastar', 'Basti', 'Bathinda', 'Beed', 'Begusarai','Belagavi', 'Bengaluru Rural', 'Bengaluru Urban', 'Betul','Bhadohi', 'Bhadrak', 'Bhagalpur', 'Bhandara', 'Bharatpur','Bharuch', 'Bhavnagar', 'Bhilwara', 'Bhind', 'Bhiwani', 'Bhojpur','Bhopal', 'Bidar', 'Bijapur', 'Bijnor', 'Bikaner', 'Bilaspur','Birbhum', 'Bokaro', 'Botad', 'Boudh', 'Budaun', 'Budgam','Bulandshahr', 'Buldhana', 'Bundi', 'Burhanpur', 'Buxar','Capital Complex', 'Chamarajanagara', 'Chamba', 'Chamoli','Champawat', 'Champhai', 'Chandauli', 'Chandigarh', 'Chandrapur','Changlang', 'Charkhi Dadri', 'Chatra', 'Chengalpattu', 'Chennai','Chhatarpur', 'Chhindwara', 'Chhota Udaipur', 'Chikkaballapura','Chikkamagaluru', 'Chitradurga', 'Chitrakoot', 'Chittoor','Chittorgarh', 'Churu', 'Coimbatore', 'Cooch Behar', 'Cuddalore','Cuttack', 'Dadra and Nagar Haveli', 'Dahod','Dakshin Bastar Dantewada', 'Dakshin Dinajpur', 'Dakshina Kannada','Daman', 'Damoh', 'Dang', 'Darbhanga', 'Darjeeling', 'Datia','Dausa', 'Davanagere', 'Dehradun', 'Delhi', 'Deogarh', 'Deoghar','Deoria', 'Devbhumi Dwarka', 'Dewas', 'Dhalai', 'Dhamtari','Dhanbad', 'Dhar', 'Dharmapuri', 'Dharwad', 'Dhenkanal', 'Dholpur','Dhule', 'Dimapur', 'Dindigul', 'Dindori', 'Diu', 'Doda', 'Dumka','Dungarpur', 'Durg', 'East Champaran', 'East Garo Hills','East Godavari', 'East Jaintia Hills', 'East Kameng','East Khasi Hills', 'East Siang', 'East Singhbhum', 'Ernakulam','Erode', 'Etah', 'Etawah', 'Evacuees', 'Faridabad', 'Faridkot','Farrukhabad', 'Fatehabad', 'Fatehgarh Sahib', 'Fatehpur','Fazilka', 'Ferozepur', 'Firozabad', 'Foreign Evacuees', 'Gadag','Gadchiroli', 'Gajapati', 'Ganderbal', 'Gandhinagar', 'Ganganagar','Ganjam', 'Garhwa', 'Gariaband', 'Gaurela Pendra Marwahi','Gautam Buddha Nagar', 'Gaya', 'Ghaziabad', 'Ghazipur','Gir Somnath', 'Giridih', 'Godda', 'Gomati', 'Gonda', 'Gondia','Gopalganj', 'Gorakhpur', 'Gumla', 'Guna', 'Guntur', 'Gurdaspur','Gurugram', 'Gwalior', 'Hamirpur', 'Hanumangarh', 'Hapur', 'Harda','Hardoi', 'Haridwar', 'Hassan', 'Hathras', 'Haveri', 'Hazaribagh','Hingoli', 'Hisar', 'Hnahthial', 'Hooghly', 'Hoshangabad','Hoshiarpur', 'Howrah', 'Idukki', 'Indore', 'Italians', 'Jabalpur','Jagatsinghpur', 'Jaipur', 'Jaisalmer', 'Jajpur', 'Jalandhar','Jalaun', 'Jalgaon', 'Jalna', 'Jalore', 'Jalpaiguri', 'Jammu','Jamnagar', 'Jamtara', 'Jamui', 'Janjgir Champa', 'Jashpur','Jaunpur', 'Jehanabad', 'Jhabua', 'Jhajjar', 'Jhalawar', 'Jhansi','Jhargram', 'Jharsuguda', 'Jhunjhunu', 'Jind', 'Jodhpur','Junagadh', 'Kabeerdham', 'Kaimur', 'Kaithal', 'Kalaburagi','Kalahandi', 'Kalimpong', 'Kallakurichi', 'Kamle', 'Kancheepuram','Kandhamal', 'Kangra', 'Kannauj', 'Kannur', 'Kanpur Dehat','Kanpur Nagar', 'Kanyakumari', 'Kapurthala', 'Karaikal', 'Karauli','Kargil', 'Karnal', 'Karur', 'Kasaragod', 'Kasganj', 'Kathua','Katihar', 'Katni', 'Kaushambi', 'Kendrapara', 'Kendujhar','Khagaria', 'Khandwa', 'Khargone', 'Khawzawl', 'Kheda', 'Khordha','Khowai', 'Khunti', 'Kinnaur', 'Kiphire', 'Kishanganj', 'Kishtwar','Kodagu', 'Koderma', 'Kohima', 'Kolar', 'Kolasib', 'Kolhapur','Kolkata', 'Kollam', 'Kondagaon', 'Koppal', 'Koraput', 'Korba','Koriya', 'Kota', 'Kottayam', 'Kozhikode', 'Kra Daadi', 'Krishna','Krishnagiri', 'Kulgam', 'Kullu', 'Kupwara', 'Kurnool','Kurukshetra', 'Kurung Kumey', 'Kushinagar', 'Kutch','Lahaul and Spiti', 'Lakhimpur Kheri', 'Lakhisarai', 'Lalitpur','Latehar', 'Latur', 'Lawngtlai', 'Leh', 'Lepa Rada', 'Lohardaga','Lohit', 'Longding', 'Longleng', 'Lower Dibang Valley','Lower Siang', 'Lower Subansiri', 'Lucknow', 'Ludhiana', 'Lunglei','Madhepura', 'Madhubani', 'Madurai', 'Maharajganj', 'Mahasamund','Mahe', 'Mahendragarh', 'Mahisagar', 'Mahoba', 'Mainpuri','Malappuram', 'Malda', 'Malkangiri', 'Mamit', 'Mandi', 'Mandla','Mandsaur', 'Mandya', 'Mansa', 'Mathura', 'Mau', 'Mayurbhanj','Meerut', 'Mehsana', 'Mirzapur', 'Moga', 'Mokokchung', 'Mon','Moradabad', 'Morbi', 'Morena', 'Mumbai', 'Mungeli', 'Munger','Murshidabad', 'Muzaffarnagar', 'Muzaffarpur', 'Mysuru','Nabarangapur', 'Nadia', 'Nagapattinam', 'Nagaur', 'Nagpur','Nainital', 'Nalanda', 'Namakkal', 'Namsai', 'Nanded', 'Nandurbar','Narayanpur', 'Narmada', 'Narsinghpur', 'Nashik', 'Navsari','Nawada', 'Nayagarh', 'Neemuch', 'Nilgiris', 'Niwari','North 24 Parganas', 'North Garo Hills', 'North Tripura','Nuapada', 'Nuh', 'Osmanabad', 'Other Region', 'Other State','Others', 'Pakke Kessang', 'Pakur', 'Palakkad', 'Palamu','Palghar', 'Pali', 'Palwal', 'Panchkula', 'Panchmahal', 'Panipat','Panna', 'Papum Pare', 'Parbhani', 'Paschim Bardhaman','Paschim Medinipur', 'Patan', 'Pathanamthitta', 'Pathankot','Patiala', 'Patna', 'Pauri Garhwal', 'Perambalur', 'Peren', 'Phek','Pilibhit', 'Pithoragarh', 'Porbandar', 'Prakasam', 'Pratapgarh','Prayagraj', 'Puducherry', 'Pudukkottai', 'Pulwama', 'Punch','Pune', 'Purba Bardhaman', 'Purba Medinipur', 'Puri', 'Purnia','Purulia', 'Rae Bareli', 'Raichur', 'Raigad', 'Raigarh','Railway Quarantine', 'Raipur', 'Raisen', 'Rajgarh', 'Rajkot','Rajnandgaon', 'Rajouri', 'Rajsamand', 'Ramanagara','Ramanathapuram', 'Ramban', 'Ramgarh', 'Rampur', 'Ranchi','Ranipet', 'Ratlam', 'Ratnagiri', 'Rayagada', 'Reasi', 'Rewa','Rewari', 'Ribhoi', 'Rohtak', 'Rohtas', 'Rudraprayag', 'Rupnagar','S.A.S. Nagar', 'S.P.S. Nellore', 'Sabarkantha', 'Sagar','Saharanpur', 'Saharsa', 'Sahibganj', 'Saiha', 'Saitual', 'Salem','Samastipur', 'Samba', 'Sambalpur', 'Sambhal', 'Sangli', 'Sangrur','Sant Kabir Nagar', 'Saraikela-Kharsawan', 'Saran', 'Satara','Satna', 'Sawai Madhopur', 'Sehore', 'Seoni', 'Serchhip','Shahdol', 'Shahid Bhagat Singh Nagar', 'Shahjahanpur', 'Shajapur','Shamli', 'Sheikhpura', 'Sheohar', 'Sheopur', 'Shi Yomi', 'Shimla','Shivamogga', 'Shivpuri', 'Shopiyan', 'Shrawasti', 'Siang','Siddharthnagar', 'Sidhi', 'Sikar', 'Simdega', 'Sindhudurg','Singrauli', 'Sipahijala', 'Sirmaur', 'Sirohi', 'Sirsa','Sitamarhi', 'Sitapur', 'Sivaganga', 'Siwan', 'Solan', 'Solapur','Sonbhadra', 'Sonipat', 'South 24 Parganas', 'South Garo Hills','South Tripura', 'South West Garo Hills', 'South West Khasi Hills','Sri Muktsar Sahib', 'Srikakulam', 'Srinagar', 'State Pool','Subarnapur', 'Sukma', 'Sultanpur', 'Sundargarh', 'Supaul','Surajpur', 'Surat', 'Surendranagar', 'Surguja', 'Tapi','Tarn Taran', 'Tawang', 'Tehri Garhwal', 'Tenkasi', 'Thane','Thanjavur', 'Theni', 'Thiruvallur', 'Thiruvananthapuram','Thiruvarur', 'Thoothukkudi', 'Thrissur', 'Tikamgarh', 'Tirap','Tiruchirappalli', 'Tirunelveli', 'Tirupathur', 'Tiruppur','Tiruvannamalai', 'Tonk', 'Tuensang', 'Tumakuru', 'Udaipur','Udham Singh Nagar', 'Udhampur', 'Udupi', 'Ujjain', 'Umaria','Una', 'Unknown', 'Unnao', 'Unokoti', 'Upper Dibang Valley','Upper Siang', 'Upper Subansiri', 'Uttar Bastar Kanker','Uttar Dinajpur', 'Uttara Kannada', 'Uttarkashi', 'Vadodara','Vaishali', 'Valsad', 'Varanasi', 'Vellore', 'Vidisha','Vijayapura', 'Viluppuram', 'Virudhunagar', 'Visakhapatnam','Vizianagaram', 'Wardha', 'Washim', 'Wayanad', 'West Champaran','West Garo Hills', 'West Godavari', 'West Jaintia Hills','West Kameng', 'West Khasi Hills', 'West Siang', 'West Singhbhum','West Tripura', 'Wokha', 'Y.S.R. Kadapa', 'Yadgir', 'Yamunanagar','Yanam', 'Yavatmal', 'Zunheboto']\n",
        "Regression_Power = 0 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "Apply_Rolling_Mean = 7 #@param {type:\"slider\", min:0, max:30, step:1}\n",
        "Train_on_days_from = 42 #@param {type:\"slider\", min:20, max:300, step:1}\n",
        "Predict_of_future_days = 15 #@param {type:\"slider\", min:0, max:200, step:1}\n",
        "Bar_Plot = 25 #@param {type:\"slider\", min:0, max:30, step:1}\n",
        "Plot_Lib = \"MatplotLib\" #@param [\"Plotly\", \"MatplotLib\"]\n",
        "\n",
        "Line_Plot = True #@param {type:\"boolean\"}\n",
        "Use_Log = False #@param {type:\"boolean\"}\n",
        "Date = 'Date'\n",
        "display(Markdown(\"<center><h2>Line Plot of {} District By SARS-CoV-2</h2></center>\".format(Plot_District)))\n",
        "\n",
        "if Plot_Column == 'C/R/D':\n",
        "  Plot_Column = ['Confirmed' , 'Recovered' , 'Deceased']\n",
        "elif Plot_Column == 'C/R/D/A':\n",
        "  Plot_Column = ['Confirmed' , 'Recovered' , 'Deceased' , 'Active']\n",
        "elif Plot_Column == 'C/R/D(Daily)':\n",
        "  Plot_Column = ['Confirmed_' , 'Recovered_' , 'Deceased_']\n",
        "else:\n",
        "  Plot_Column = [Plot_Column]\n",
        "\n",
        "data = District_[District_.District == Plot_District]\n",
        "\n",
        "bar_data = data.resample('M').mean()\n",
        "times = pd.date_range(data[Date].min(), periods = data.shape[0]+Predict_of_future_days , freq='D')\n",
        "if Use_Log:\n",
        "  bar_data[Plot_Column[0]] = np.log1p(bar_data[Plot_Column[0]])\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=len(Plot_Column)*2).as_hex())\n",
        "if Plot_Lib == 'MatplotLib':\n",
        "  plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  if Bar_Plot:\n",
        "    plt.bar(bar_data.index, bar_data[Plot_Column[0]], align = 'edge',width = -Bar_Plot , linewidth = 0 , color = list(sns.color_palette(Style_Color,n_colors=len(bar_data[Plot_Column].values)).as_hex()) , alpha = .9 ,label = 'Monthly Average')\n",
        "\n",
        "  for col,i in enumerate(Plot_Column):\n",
        "    data[i] = data[i].rolling(Apply_Rolling_Mean, min_periods = 1).mean()\n",
        "    if Use_Log:\n",
        "      data[i] = np.log1p(data[i])\n",
        "    if Line_Plot:\n",
        "      plt.plot(data[i], label = '{} Cases(per day)'.format(i.replace('_',' (Daily)').title()) , color = plot_color[col*2] )\n",
        "    if Regression_Power:\n",
        "      model = np.poly1d(np.polyfit(data['Days_Passed'].values[Train_on_days_from-20:], data[i].values[Train_on_days_from-20:], Regression_Power))\n",
        "      polyline = np.linspace(Train_on_days_from, data['Days_Passed'].max()+Predict_of_future_days, len(times[Train_on_days_from:])) \n",
        "      plt.plot( pd.Series([0 if i<0 else i for i in model(polyline)] , index = times[Train_on_days_from:])  , label = 'Predicted {} Cases'.format(i.replace('_',' (Daily)').title()) , color = plot_color[1])\n",
        "\n",
        "  plt.suptitle(Sup_Title, fontsize = 29)\n",
        "  plt.title('\\nLine Plot in {} with SARS-CoV-2 Cases  \\n'.format(Plot_District ) , fontsize = 19)\n",
        "\n",
        "  plt.legend()\n",
        "  plt.ylabel('Cases')\n",
        "  plt.xlabel('Days Passed Since {}'.format(District_['Date'].min()))\n",
        "  plt.subplots_adjust(top=SubPlot_Top)\n",
        "  plt.savefig(File_Prefix+'Time Series India District Reg Plot  on {} _{}.{}'.format(District_[Date].max() , time.time() , Format_To_Save) , bbox_inches = 'tight')\n",
        "else:\n",
        "  fig=go.Figure()\n",
        "  for col,i in enumerate(Plot_Column):\n",
        "    if Use_Log:\n",
        "      data[i] = np.log1p(data[i])\n",
        "    if Regression_Power:\n",
        "      model = np.poly1d(np.polyfit(data['Days_Passed'].values[Train_on_days_from-20:], data[i].values[Train_on_days_from-20:], Regression_Power))\n",
        "      polyline = np.linspace(Train_on_days_from, data['Days_Passed'].max()+Predict_of_future_days, len(times[Train_on_days_from:])) \n",
        "      reg_plot = pd.Series([0 if i<0 else i for i in model(polyline)] , index = times[Train_on_days_from:])  \n",
        "      fig.add_trace(go.Scatter(x = reg_plot.index ,y = reg_plot , mode = 'lines' , name = ' Fitted Line on {} '.format(i.replace('_',' ').title())))\n",
        "    if Apply_Rolling_Mean > 1:\n",
        "      data[i] = data[i].rolling(Apply_Rolling_Mean, min_periods = 1).mean()\n",
        "    fig.add_trace(go.Scatter(x = data.index , y = data[i] , mode = 'lines' , name = '{} Cases'.format(i.replace('_',' ').title() ) ) )\n",
        "  if Bar_Plot:\n",
        "    fig.add_trace(go.Bar(x = bar_data.index,y = bar_data[Plot_Column[0]] , name = 'Monthly Average Confirmed Cases', marker=dict(color = list(sns.color_palette(Style_Color,n_colors=len(bar_data[Plot_Column[0]].values)).as_hex()))))\n",
        "  fig.update_layout(title='Cases of {} SARS-CoV-2 \\n'.format(Location),\n",
        "                  xaxis_title='Days Passed Since {}'.format(data[Date].min()),yaxis_title=\"Cases\",legend=dict(x=0,y=1,traceorder=\"normal\"),\n",
        "                  height =Graphs_Height*96/3)\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKa3IrNtbzXy",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://assets.website-files.com/5d9ba0eb5f6edb77992a99d0/5e62506c9394b24aa66cf385_iconfinder_connection-route-spread-virus-global_5728179.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Top Effected States by Corona Virus</h2></center><br>\n",
        "\n",
        "Plot_State = \"Uttar Pradesh\" #@param [\"India\",'Andaman and Nicobar Islands', 'Andhra Pradesh','Arunachal Pradesh', 'Assam', 'Bihar', 'Chandigarh','Chhattisgarh', 'Dadra and Nagar Haveli and Daman and Diu','Gujarat', 'Haryana', 'Himachal Pradesh','Jammu and Kashmir', 'Jharkhand', 'Karnataka', 'Kerala', 'Ladakh','Madhya Pradesh', 'Maharashtra', 'Manipur', 'Meghalaya', 'Mizoram','Nagaland', 'Odisha', 'Puducherry', 'Punjab', 'Rajasthan', 'Tamil Nadu', 'Telangana', 'Tripura', 'Uttar Pradesh','Uttarakhand', 'West Bengal']\n",
        "Plot_Column = \"Confirmed_\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_', 'Negative']\n",
        "Use_Method = \"mean\" #@param [\"sum\", \"mean\", \"max\", \"median\", \"min\", \"std\", \"var\"]\n",
        "Plot_top = 4 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "Apply_Rolling_Mean = 11 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "Plot_Lib = \"MatplotLib\" #@param [\"Plotly\", \"MatplotLib\"]\n",
        "Fill_Alpha = 0.13 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "Use_Log = False #@param {type:\"boolean\"}\n",
        "Date = 'Date'\n",
        "\n",
        "display(Markdown(\"<center><h2>Line Plot for {} Most Effected Indian District By SARS-CoV-2</h2></center>\".format(Plot_top)))\n",
        "\n",
        "if Plot_State == 'India':\n",
        "  Locations = District_.groupby('District').agg({Plot_By:Use_Method}).sort_values(by=[Plot_Column] , ascending = False).reset_index()['District'].head(Plot_top+1).values\n",
        "else:\n",
        "  Locations = District_[District_['State']==Plot_State].groupby('District').agg({Plot_Column:Use_Method}).sort_values(by=[Plot_Column] , ascending = False).reset_index()['District'].head(Plot_top+1).values\n",
        "\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=len(Locations)*2).as_hex())\n",
        "\n",
        "\n",
        "if Plot_Lib == 'MatplotLib':\n",
        "  plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  for i,Location in enumerate(Locations):\n",
        "    if Location in District_.District.unique() and Location != 'Unknown' :\n",
        "      data = District_[District_.State == Plot_State]\n",
        "      data = data[data.District == Location]\n",
        "\n",
        "      data[Plot_Column] = data[Plot_Column].rolling(Apply_Rolling_Mean, min_periods = 1).mean()\n",
        "\n",
        "      if Use_Log:\n",
        "        data[Plot_Column] = np.log1p(data[Plot_Column])\n",
        "      if Fill_Alpha:\n",
        "        plt.fill_between(data.index , 0 , data[Plot_Column], color =  plot_color[i] , alpha = Fill_Alpha)\n",
        "      plt.plot(data.index , data[Plot_Column], label = '{}'.format(Location) , color = plot_color[i*2] )\n",
        "\n",
        "  plt.suptitle(Sup_Title, fontsize = 29)\n",
        "  plt.title('{} Cases of  SARS-CoV-2 in States \\n'.format(Plot_Column.replace('_',' (Daily)').title() ) , fontsize = 19)\n",
        "  plt.legend()\n",
        "  plt.ylabel('Cases')\n",
        "  plt.xlabel('Days Passed Since {}'.format(Completed_['Date'].min()))\n",
        "  plt.subplots_adjust(top=SubPlot_Top)\n",
        "  plt.savefig(File_Prefix+'Time Series Top Effected District  Reg Plot  on {} _{}.{}'.format(World_.date.max() , time.time() , Format_To_Save) , bbox_inches = 'tight')\n",
        "\n",
        "else:\n",
        "  fig=go.Figure()\n",
        "  for i,Location in enumerate(Locations):\n",
        "    if Location in District_.District.unique() and Location != 'Unknown' :\n",
        "      data = District_[District_.State == Plot_State]\n",
        "      data = data[data.District == Location]\n",
        "      \n",
        "      data[Plot_Column] = data[Plot_Column].rolling(Apply_Rolling_Mean, min_periods = 1).mean()\n",
        "\n",
        "      if Use_Log:\n",
        "        data[Plot_Column] = np.log1p(data[Plot_Column])\n",
        "\n",
        "      fig.add_trace(go.Scatter(x = data.index , y = data[Plot_Column] , mode = 'lines' , name = '{}'.format(Location) ) ) \n",
        "  \n",
        "  fig.update_layout(title='Top {} Cases In District of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title()  ),\n",
        "                  xaxis_title='Days Passed Since {}'.format(data[Date].min()),yaxis_title=\"Cases\",legend=dict(x=0,y=1,traceorder=\"normal\"),\n",
        "                  height =Graphs_Height*96/3)\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgfWGSR-oECP"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Plotting</h3>\n",
        "#@markdown <br><center><img src='https://cdn2.iconfinder.com/data/icons/round-varieties/60/Rounded_-_High_Ultra_Colour19_-_Graph-256.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2>Month Wise Effect of Corona Virus in States of India</h2></center><br>\n",
        "\n",
        "Plot_Column = \"Confirmed Recovered Deceased Confirmed_ Recovered_ Deceased_ Tested Active Death-Rate-(per-100) Cure-Rate-(per-100)\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_', 'Negative', 'Confirmed Recovered Deceased','Confirmed_ Recovered_ Deceased_','Confirmed Recovered Deceased Confirmed_ Recovered_ Deceased_','Confirmed Recovered Deceased Confirmed_ Recovered_ Deceased_ Tested Active Death-Rate-(per-100) Cure-Rate-(per-100)']\n",
        "Plot_District = \"Etawah\" #@param ['Agar Malwa', 'Agra', 'Ahmedabad', 'Ahmednagar','Airport Quarantine', 'Aizawl', 'Ajmer', 'Akola', 'Alappuzha','Aligarh', 'Alipurduar', 'Alirajpur', 'Almora', 'Alwar', 'Ambala','Ambedkar Nagar', 'Amethi', 'Amravati', 'Amreli', 'Amritsar','Amroha', 'Anand', 'Anantapur', 'Anantnag', 'Angul', 'Anjaw','Anuppur', 'Araria', 'Aravalli', 'Ariyalur', 'Arwal', 'Ashoknagar','Auraiya', 'Aurangabad', 'Ayodhya', 'Azamgarh', 'BSF Camp','Bagalkote', 'Bageshwar', 'Baghpat', 'Bahraich', 'Balaghat','Balangir', 'Balasore', 'Ballari', 'Ballia', 'Balod','Baloda Bazar', 'Balrampur', 'Bametara', 'Banaskantha', 'Banda','Bandipora', 'Banka', 'Bankura', 'Banswara', 'Barabanki','Baramulla', 'Baran', 'Bareilly', 'Bargarh', 'Barmer', 'Barnala','Barwani', 'Bastar', 'Basti', 'Bathinda', 'Beed', 'Begusarai','Belagavi', 'Bengaluru Rural', 'Bengaluru Urban', 'Betul','Bhadohi', 'Bhadrak', 'Bhagalpur', 'Bhandara', 'Bharatpur','Bharuch', 'Bhavnagar', 'Bhilwara', 'Bhind', 'Bhiwani', 'Bhojpur','Bhopal', 'Bidar', 'Bijapur', 'Bijnor', 'Bikaner', 'Bilaspur','Birbhum', 'Bokaro', 'Botad', 'Boudh', 'Budaun', 'Budgam','Bulandshahr', 'Buldhana', 'Bundi', 'Burhanpur', 'Buxar','Capital Complex', 'Chamarajanagara', 'Chamba', 'Chamoli','Champawat', 'Champhai', 'Chandauli', 'Chandigarh', 'Chandrapur','Changlang', 'Charkhi Dadri', 'Chatra', 'Chengalpattu', 'Chennai','Chhatarpur', 'Chhindwara', 'Chhota Udaipur', 'Chikkaballapura','Chikkamagaluru', 'Chitradurga', 'Chitrakoot', 'Chittoor','Chittorgarh', 'Churu', 'Coimbatore', 'Cooch Behar', 'Cuddalore','Cuttack', 'Dadra and Nagar Haveli', 'Dahod','Dakshin Bastar Dantewada', 'Dakshin Dinajpur', 'Dakshina Kannada','Daman', 'Damoh', 'Dang', 'Darbhanga', 'Darjeeling', 'Datia','Dausa', 'Davanagere', 'Dehradun', 'Delhi', 'Deogarh', 'Deoghar','Deoria', 'Devbhumi Dwarka', 'Dewas', 'Dhalai', 'Dhamtari','Dhanbad', 'Dhar', 'Dharmapuri', 'Dharwad', 'Dhenkanal', 'Dholpur','Dhule', 'Dimapur', 'Dindigul', 'Dindori', 'Diu', 'Doda', 'Dumka','Dungarpur', 'Durg', 'East Champaran', 'East Garo Hills','East Godavari', 'East Jaintia Hills', 'East Kameng','East Khasi Hills', 'East Siang', 'East Singhbhum', 'Ernakulam','Erode', 'Etah', 'Etawah', 'Evacuees', 'Faridabad', 'Faridkot','Farrukhabad', 'Fatehabad', 'Fatehgarh Sahib', 'Fatehpur','Fazilka', 'Ferozepur', 'Firozabad', 'Foreign Evacuees', 'Gadag','Gadchiroli', 'Gajapati', 'Ganderbal', 'Gandhinagar', 'Ganganagar','Ganjam', 'Garhwa', 'Gariaband', 'Gaurela Pendra Marwahi','Gautam Buddha Nagar', 'Gaya', 'Ghaziabad', 'Ghazipur','Gir Somnath', 'Giridih', 'Godda', 'Gomati', 'Gonda', 'Gondia','Gopalganj', 'Gorakhpur', 'Gumla', 'Guna', 'Guntur', 'Gurdaspur','Gurugram', 'Gwalior', 'Hamirpur', 'Hanumangarh', 'Hapur', 'Harda','Hardoi', 'Haridwar', 'Hassan', 'Hathras', 'Haveri', 'Hazaribagh','Hingoli', 'Hisar', 'Hnahthial', 'Hooghly', 'Hoshangabad','Hoshiarpur', 'Howrah', 'Idukki', 'Indore', 'Italians', 'Jabalpur','Jagatsinghpur', 'Jaipur', 'Jaisalmer', 'Jajpur', 'Jalandhar','Jalaun', 'Jalgaon', 'Jalna', 'Jalore', 'Jalpaiguri', 'Jammu','Jamnagar', 'Jamtara', 'Jamui', 'Janjgir Champa', 'Jashpur','Jaunpur', 'Jehanabad', 'Jhabua', 'Jhajjar', 'Jhalawar', 'Jhansi','Jhargram', 'Jharsuguda', 'Jhunjhunu', 'Jind', 'Jodhpur','Junagadh', 'Kabeerdham', 'Kaimur', 'Kaithal', 'Kalaburagi','Kalahandi', 'Kalimpong', 'Kallakurichi', 'Kamle', 'Kancheepuram','Kandhamal', 'Kangra', 'Kannauj', 'Kannur', 'Kanpur Dehat','Kanpur Nagar', 'Kanyakumari', 'Kapurthala', 'Karaikal', 'Karauli','Kargil', 'Karnal', 'Karur', 'Kasaragod', 'Kasganj', 'Kathua','Katihar', 'Katni', 'Kaushambi', 'Kendrapara', 'Kendujhar','Khagaria', 'Khandwa', 'Khargone', 'Khawzawl', 'Kheda', 'Khordha','Khowai', 'Khunti', 'Kinnaur', 'Kiphire', 'Kishanganj', 'Kishtwar','Kodagu', 'Koderma', 'Kohima', 'Kolar', 'Kolasib', 'Kolhapur','Kolkata', 'Kollam', 'Kondagaon', 'Koppal', 'Koraput', 'Korba','Koriya', 'Kota', 'Kottayam', 'Kozhikode', 'Kra Daadi', 'Krishna','Krishnagiri', 'Kulgam', 'Kullu', 'Kupwara', 'Kurnool','Kurukshetra', 'Kurung Kumey', 'Kushinagar', 'Kutch','Lahaul and Spiti', 'Lakhimpur Kheri', 'Lakhisarai', 'Lalitpur','Latehar', 'Latur', 'Lawngtlai', 'Leh', 'Lepa Rada', 'Lohardaga','Lohit', 'Longding', 'Longleng', 'Lower Dibang Valley','Lower Siang', 'Lower Subansiri', 'Lucknow', 'Ludhiana', 'Lunglei','Madhepura', 'Madhubani', 'Madurai', 'Maharajganj', 'Mahasamund','Mahe', 'Mahendragarh', 'Mahisagar', 'Mahoba', 'Mainpuri','Malappuram', 'Malda', 'Malkangiri', 'Mamit', 'Mandi', 'Mandla','Mandsaur', 'Mandya', 'Mansa', 'Mathura', 'Mau', 'Mayurbhanj','Meerut', 'Mehsana', 'Mirzapur', 'Moga', 'Mokokchung', 'Mon','Moradabad', 'Morbi', 'Morena', 'Mumbai', 'Mungeli', 'Munger','Murshidabad', 'Muzaffarnagar', 'Muzaffarpur', 'Mysuru','Nabarangapur', 'Nadia', 'Nagapattinam', 'Nagaur', 'Nagpur','Nainital', 'Nalanda', 'Namakkal', 'Namsai', 'Nanded', 'Nandurbar','Narayanpur', 'Narmada', 'Narsinghpur', 'Nashik', 'Navsari','Nawada', 'Nayagarh', 'Neemuch', 'Nilgiris', 'Niwari','North 24 Parganas', 'North Garo Hills', 'North Tripura','Nuapada', 'Nuh', 'Osmanabad', 'Other Region', 'Other State','Others', 'Pakke Kessang', 'Pakur', 'Palakkad', 'Palamu','Palghar', 'Pali', 'Palwal', 'Panchkula', 'Panchmahal', 'Panipat','Panna', 'Papum Pare', 'Parbhani', 'Paschim Bardhaman','Paschim Medinipur', 'Patan', 'Pathanamthitta', 'Pathankot','Patiala', 'Patna', 'Pauri Garhwal', 'Perambalur', 'Peren', 'Phek','Pilibhit', 'Pithoragarh', 'Porbandar', 'Prakasam', 'Pratapgarh','Prayagraj', 'Puducherry', 'Pudukkottai', 'Pulwama', 'Punch','Pune', 'Purba Bardhaman', 'Purba Medinipur', 'Puri', 'Purnia','Purulia', 'Rae Bareli', 'Raichur', 'Raigad', 'Raigarh','Railway Quarantine', 'Raipur', 'Raisen', 'Rajgarh', 'Rajkot','Rajnandgaon', 'Rajouri', 'Rajsamand', 'Ramanagara','Ramanathapuram', 'Ramban', 'Ramgarh', 'Rampur', 'Ranchi','Ranipet', 'Ratlam', 'Ratnagiri', 'Rayagada', 'Reasi', 'Rewa','Rewari', 'Ribhoi', 'Rohtak', 'Rohtas', 'Rudraprayag', 'Rupnagar','S.A.S. Nagar', 'S.P.S. Nellore', 'Sabarkantha', 'Sagar','Saharanpur', 'Saharsa', 'Sahibganj', 'Saiha', 'Saitual', 'Salem','Samastipur', 'Samba', 'Sambalpur', 'Sambhal', 'Sangli', 'Sangrur','Sant Kabir Nagar', 'Saraikela-Kharsawan', 'Saran', 'Satara','Satna', 'Sawai Madhopur', 'Sehore', 'Seoni', 'Serchhip','Shahdol', 'Shahid Bhagat Singh Nagar', 'Shahjahanpur', 'Shajapur','Shamli', 'Sheikhpura', 'Sheohar', 'Sheopur', 'Shi Yomi', 'Shimla','Shivamogga', 'Shivpuri', 'Shopiyan', 'Shrawasti', 'Siang','Siddharthnagar', 'Sidhi', 'Sikar', 'Simdega', 'Sindhudurg','Singrauli', 'Sipahijala', 'Sirmaur', 'Sirohi', 'Sirsa','Sitamarhi', 'Sitapur', 'Sivaganga', 'Siwan', 'Solan', 'Solapur','Sonbhadra', 'Sonipat', 'South 24 Parganas', 'South Garo Hills','South Tripura', 'South West Garo Hills', 'South West Khasi Hills','Sri Muktsar Sahib', 'Srikakulam', 'Srinagar', 'State Pool','Subarnapur', 'Sukma', 'Sultanpur', 'Sundargarh', 'Supaul','Surajpur', 'Surat', 'Surendranagar', 'Surguja', 'Tapi','Tarn Taran', 'Tawang', 'Tehri Garhwal', 'Tenkasi', 'Thane','Thanjavur', 'Theni', 'Thiruvallur', 'Thiruvananthapuram','Thiruvarur', 'Thoothukkudi', 'Thrissur', 'Tikamgarh', 'Tirap','Tiruchirappalli', 'Tirunelveli', 'Tirupathur', 'Tiruppur','Tiruvannamalai', 'Tonk', 'Tuensang', 'Tumakuru', 'Udaipur','Udham Singh Nagar', 'Udhampur', 'Udupi', 'Ujjain', 'Umaria','Una', 'Unknown', 'Unnao', 'Unokoti', 'Upper Dibang Valley','Upper Siang', 'Upper Subansiri', 'Uttar Bastar Kanker','Uttar Dinajpur', 'Uttara Kannada', 'Uttarkashi', 'Vadodara','Vaishali', 'Valsad', 'Varanasi', 'Vellore', 'Vidisha','Vijayapura', 'Viluppuram', 'Virudhunagar', 'Visakhapatnam','Vizianagaram', 'Wardha', 'Washim', 'Wayanad', 'West Champaran','West Garo Hills', 'West Godavari', 'West Jaintia Hills','West Kameng', 'West Khasi Hills', 'West Siang', 'West Singhbhum','West Tripura', 'Wokha', 'Y.S.R. Kadapa', 'Yadgir', 'Yamunanagar','Yanam', 'Yavatmal', 'Zunheboto']\n",
        "Apply_Rolling = 4 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "Plot_Method = \"Mean\" #@param [\"None\", \"Median\", \"Mean\", \"Max\", \"Min\"]\n",
        "Fill_Below = True #@param {type:\"boolean\"}\n",
        "Plot_Column = Plot_Column.split(' ')\n",
        "\n",
        "data = District_[District_.District == Plot_District]\n",
        "n_cols = len(District_['Month'].unique())\n",
        "n_rows = len(Plot_Column)\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=n_rows*n_cols).as_hex())\n",
        "plt.figure(figsize = (Graphs_Width*4.5,int(Graphs_Height/2)*n_rows))\n",
        "i=0\n",
        "\n",
        "for plot_row in Plot_Column:\n",
        "  plot_row = plot_row.replace('-',' ')\n",
        "  for col in data['Month'].unique():\n",
        "    temp = data[data['Month'] == col].reset_index(drop = True)\n",
        "    plt.subplot( n_rows , n_cols , i+1)\n",
        "    if Plot_Method == 'Mean':\n",
        "      plt.plot(temp[plot_row].rolling(Apply_Rolling, min_periods = 1).mean() , color = plot_color[i] , label = '{} Rolling Mean'.format(col))\n",
        "    elif Plot_Method == 'Median':\n",
        "      plt.plot(temp[plot_row].rolling(Apply_Rolling, min_periods = 1).median() , color = plot_color[i] , label = '{} Rolling Median'.format(col))\n",
        "    elif Plot_Method == 'Max':\n",
        "      plt.plot(temp[plot_row].rolling(Apply_Rolling, min_periods = 1).max() , color = plot_color[i] , label = '{} Rolling Max'.format(col))\n",
        "    elif Plot_Method == 'Min':\n",
        "      plt.plot(temp[plot_row].rolling(Apply_Rolling, min_periods = 1).min() , color = plot_color[i] , label = '{} Rolling Min'.format(col))\n",
        "    else:\n",
        "      plt.plot(temp[plot_row] , color = plot_color[i] , label = '{}'.format(col))\n",
        "      \n",
        "    if Fill_Below:\n",
        "      plt.fill_between(list(temp.index) ,0, temp[plot_row] ,color = plot_color[i] , alpha =0.4, label = '{}'.format(col))\n",
        "  \n",
        "    plt.legend()\n",
        "    plt.title('{}  in Month {}'.format(plot_row.replace('_',' (Per Day) ') , col) , fontsize = 19)\n",
        "    i+=1\n",
        "plt.plot()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlBYxbCfYPy8"
      },
      "source": [
        "# Forecasting and Best Fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkZon6ChlqyB"
      },
      "source": [
        "##SEIR Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQYcbD9p9aht",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='https://file.scirp.org/Html/3-7401490/5c6169a0-4c91-4bdc-be3e-3c9ba7cf13ce.jpg' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2><br>Predict Corona Virus Cases in India With SEIR Model</h2></center><br>\n",
        "Days_From_Exposed_To_Infected = 10 #@param {type:\"slider\", min:0, max:21, step:1}\n",
        "Phase_Differnce = 81 #@param {type:\"slider\", min:0, max:300, step:1}\n",
        "\n",
        "\n",
        "def seir_model_ode(y, t, params): \n",
        "  infection_rate = params[0]\n",
        "  recovery_rate = params[1]\n",
        "  exposed_rate = params[2]\n",
        "  reinfection_rate = params[3]\n",
        "  \n",
        "  s = y[0]\n",
        "  e = y[1]\n",
        "  i = y[2]\n",
        "  r = y[3]\n",
        "\n",
        "  dsdt = -exposed_rate*s*(i+e) + reinfection_rate*r\n",
        "  dedt = (exposed_rate*s*(i+e)) - (infection_rate*e)\n",
        "  didt = (infection_rate*e) - (recovery_rate*i)\n",
        "  drdt = recovery_rate*i - reinfection_rate*r\n",
        "\n",
        "  return (dsdt, dedt, didt, drdt)\n",
        "\n",
        "def calculate_seir_model(params, t, initial_condition):\n",
        "  seir_ode = lambda y,t:seir_model_ode(y,t, params)\n",
        "  ode_result = integrate.odeint(func=seir_ode, y0=initial_condition, t=t)\n",
        "  return ode_result\n",
        "\n",
        "def fit_seir_model(params_to_fit, t, initial_condition, i_r_true):\n",
        "  fit_result = calculate_seir_model(params_to_fit, t, initial_condition)\n",
        "  residual_i = i_r_true[0] - fit_result[:,2]\n",
        "  residual_r = i_r_true[1] - fit_result[:,3]\n",
        "  residual = np.concatenate((residual_i, residual_r))\n",
        "  return residual \n",
        "\n",
        "def country2Divided(N, status,lockdownDay,countryName):\n",
        "  plot_color = list(sns.color_palette(Style_Color,n_colors=4).as_hex())\n",
        "  I_start = status.loc[0, 'Confirmed']/N\n",
        "  E_start = (status.loc[Days_From_Exposed_To_Infected, 'Confirmed'] - status.loc[0, 'Confirmed'])/N\n",
        "  S_start = 1 - E_start - I_start\n",
        "  R_start = status.loc[0, 'Recovered']/N\n",
        "\n",
        "  ic = (S_start, E_start, I_start, R_start)\n",
        "\n",
        "  beforelockdown=status.loc[0:lockdownDay]\n",
        "  afterlockdown=status.loc[lockdownDay+1:]\n",
        "  i_r_true_bf = (list(beforelockdown['Confirmed']/N), list(beforelockdown['Recovered']/N))\n",
        "  i_r_true_af = (list(afterlockdown['Confirmed']/N), list(afterlockdown['Recovered']/N))\n",
        "\n",
        "  time_opt_bf = range(0, lockdownDay+1)\n",
        "  time_opt_af = range(0, len(afterlockdown))\n",
        "  time_opt =range(0,len(status))\n",
        "\n",
        "  E_start_day = min(len(status['Days_Passed']),len(beforelockdown)+14)\n",
        "  \n",
        "  E_start_af = (status.loc[E_start_day, 'Confirmed'] - status.loc[len(beforelockdown), 'Confirmed'])/N\n",
        "  I_start_af = status.loc[len(beforelockdown), 'Confirmed']/N\n",
        "  S_start_af = 1 - E_start_af - I_start_af\n",
        "  R_start_af = status.loc[len(beforelockdown), 'Recovered']/N\n",
        "\n",
        "  ic_af = (S_start_af, E_start_af, I_start_af, R_start_af)\n",
        "  \n",
        "  params_start_guess = [0.01, 0.001, 0.01, 0.001]\n",
        "  optimal = optimize.least_squares(fit_seir_model,\n",
        "    x0=params_start_guess,\n",
        "    args=(time_opt_bf, ic, i_r_true_bf),\n",
        "    ftol=1.49012e-22)\n",
        "  optimal_af = optimize.least_squares(fit_seir_model,\n",
        "    x0=params_start_guess,\n",
        "    args=(time_opt_af, ic_af, i_r_true_af),\n",
        "    ftol=1.49012e-22)\n",
        "  \n",
        "  optimal_params = optimal.x\n",
        "  optimal_params_af = optimal_af.x\n",
        "\n",
        "  print('## '+countryName+' In Intial Phase')\n",
        "  print('Optimized infection rate: ', optimal_params[0])\n",
        "  print('Optimized recovered rate: ', optimal_params[1])\n",
        "  print('Optimized exposed rate: ', optimal_params[2])\n",
        "  print('Optimized reinfection rate: ', optimal_params[3])\n",
        "  print('\\n')\n",
        "  print('## '+countryName+' after Phase')\n",
        "  print('Optimize infection rate: ', optimal_params_af[0])\n",
        "  print('Optimize recovered rate: ', optimal_params_af[1])\n",
        "  print('Optimize exposed rate: ', optimal_params_af[2])\n",
        "  print('Optimized reinfection rate: ', optimal_params_af[3])\n",
        "  ir = optimal_params[0]\n",
        "  rr = optimal_params[1]\n",
        "  er = optimal_params[2]\n",
        "  rir = optimal_params[3]\n",
        "  ir_af = optimal_params_af[0]\n",
        "  rr_af = optimal_params_af[1]\n",
        "  er_af = optimal_params_af[2]\n",
        "  rir_af = optimal_params_af[3]\n",
        "\n",
        "  fit_result_bf = calculate_seir_model((ir, rr, er, rir), time_opt_bf, ic)\n",
        "  fit_result_af = calculate_seir_model((ir_af, rr_af, er_af, rir_af), time_opt_af, ic_af)\n",
        "  fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, sharey=True, sharex=True, figsize=[Graphs_Width,int(Graphs_Height/2)])\n",
        "  fig.text(0.5, 0.04, 'Number of days after March-01 2020', ha='center', fontsize=18)\n",
        "\n",
        "  ax1.set_title('Infected cases in '+ countryName,fontsize=20)\n",
        "  ax1.plot(time_opt, i_r_true_bf[0]+i_r_true_af[0], 'o-', color= plot_color[0] , markersize = 0.3)\n",
        "  ax1.plot(time_opt, np.hstack((fit_result_bf[:,2],fit_result_af[:,2])), 'o-', color= plot_color[2] , markersize=0.3)\n",
        "  ax1.legend(['Actual infection', 'Predicted infection'],loc=2, fontsize=12)\n",
        "  ax1.set_ylabel('Proportion of population', fontsize=12)\n",
        "  \n",
        "  ax2.set_title('Recovered cases in '+countryName,fontsize=20)    \n",
        "  ax2.plot(time_opt, i_r_true_bf[1]+i_r_true_af[1], 'o-', color= plot_color[1] ,  markersize = .3)\n",
        "  ax2.plot(time_opt, np.hstack((fit_result_bf[:,3],fit_result_af[:,3])), 'o-', color= plot_color[3],markersize=0.3)\n",
        "  ax2.legend(['Real recover', 'Predicted recover'],loc=2, fontsize=12)\n",
        "  datetime_pred = pd.date_range(start=\"2020-03-01\",end=\"2021-01-01\", freq='D')\n",
        "  pred_time = [x.strftime(\"%Y-%m-%d\") for x in datetime_pred]\n",
        "  pred_range = range(0, len(pred_time))\n",
        "  pred_result = calculate_seir_model((ir_af, rr_af, er_af, rir_af), pred_range, ic_af)\n",
        "  time_axis = [pred_time[i] for i in[0, 29, 60, 90, 121, 151, 182, 213, 243, 274, 304]]\n",
        "  time_labels = ['Mar.', 'Apr.', 'May', 'June', 'July', 'Aug.', 'Sept.', 'Oct.', 'Nov.', 'Dec.', 'Jan.']\n",
        "  ## Plot SEIDR\n",
        "  fig, ax = plt.subplots(figsize=[Graphs_Width,Graphs_Height])\n",
        "\n",
        "  ax.plot(pred_time, pred_result[:,0],color=plot_color[0] ) #susceptible\n",
        "  ax.plot(pred_time, pred_result[:,1],color=plot_color[1] ) #exposed\n",
        "  ax.plot(pred_time, pred_result[:,2],color=plot_color[2] ) #infected\n",
        "  ax.plot(pred_time, pred_result[:,3], color = plot_color[3] ) #recovered\n",
        "  ax.legend(loc=1, labels=['Susceptible', 'Exposed', 'Infected', 'Recovered'], fontsize=12)\n",
        "  ax.set_title('SEIR predictions', fontsize=20)\n",
        "  ax.set_xlabel('Month', fontsize=12)\n",
        "  ax.set_ylabel('Proportion of population', fontsize=12)\n",
        "  plt.xticks(time_axis, time_labels, rotation='vertical');\n",
        "\n",
        "country2Divided(138*1e6 ,India_.reset_index(drop = True), Phase_Differnce, 'India');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "RmOLFtA_lsdU"
      },
      "source": [
        "#@markdown <center><h2><br>How Normal Unoptimized SEIR Model Looks</h2></center><br>\n",
        "\n",
        "def base_seir_model(init_vals, params, t):\n",
        "    S_0, E_0, I_0, R_0 = init_vals\n",
        "    S, E, I, R = [S_0], [E_0], [I_0], [R_0]\n",
        "    alpha, beta, gamma = params\n",
        "    dt = t[1] - t[0]\n",
        "    for _ in t[1:]:\n",
        "        next_S = S[-1] - (beta*S[-1]*I[-1])*dt\n",
        "        next_E = E[-1] + (beta*S[-1]*I[-1] - alpha*E[-1])*dt\n",
        "        next_I = I[-1] + (alpha*E[-1] - gamma*I[-1])*dt\n",
        "        next_R = R[-1] + (gamma*I[-1])*dt\n",
        "        S.append(next_S)\n",
        "        E.append(next_E)\n",
        "        I.append(next_I)\n",
        "        R.append(next_R)\n",
        "    return [S,E, I,R]\n",
        "  \n",
        "t_max = 100\n",
        "dt = .1\n",
        "t = np.linspace(0, t_max, int(t_max/dt) + 1)\n",
        "N = 1000000\n",
        "init_vals = 1 - 1/N, 1/N, 0, 0\n",
        "alpha = 0.2\n",
        "beta = 1.75\n",
        "gamma = 0.5\n",
        "params = alpha, beta, gamma\n",
        "# Run simulation\n",
        "results = base_seir_model(init_vals, params, t)\n",
        "\n",
        "plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "plt.suptitle(Sup_Title, fontsize = 29)\n",
        "\n",
        "for i in results:\n",
        "  plt.plot(i )\n",
        "plt.legend(['Susceptible','Exposed','Infected','Recovered'])\n",
        "plt.ylabel('% of Population')\n",
        "plt.xlabel('Days Passed Since 01-Jan-2020')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXoaBXhkii8P"
      },
      "source": [
        "## SEIRD Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTKhz0bqLZLI",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='https://www.researchgate.net/profile/Sebastiano_Battiato/publication/340482894/figure/fig1/AS:877674142654465@1586265230482/The-employed-SEIRD-epidemic-model-for-SARS-CoV-2.jpg' height=\"200\" alt=\"SEIRD-logo\"/></center>\n",
        "#@markdown <center><h2><br>Predict Corona Virus Cases in Country With SEIRD Model</h2></center><br>\n",
        "Days_From_Exposed_To_Infected = 7 #@param {type:\"slider\", min:0, max:21, step:1}\n",
        "Phase_Differnce = 59 #@param {type:\"slider\", min:0, max:300, step:1}\n",
        "Consider_Exposed_as_Infectious = True #@param {type:\"boolean\"}\n",
        "\n",
        "def seird_v2_model_ode(y, t, params): \n",
        "  # Parameters to find\n",
        "  infection_rate = params[0]\n",
        "  recovery_rate = params[1]\n",
        "  exposed_rate = params[2]\n",
        "  reinfection_rate = params[3]\n",
        "  death_rate = params[4]\n",
        "  \n",
        "  # Y variables\n",
        "  s = y[0]\n",
        "  e = y[1]\n",
        "  i = y[2]\n",
        "  r = y[3]\n",
        "  d = y[4]\n",
        "  # SIR ODE System \n",
        "  dsdt = -exposed_rate*s*i + reinfection_rate*r\n",
        "  dedt = (exposed_rate*s*i) - (infection_rate*e)\n",
        "  didt = (infection_rate*e) - (recovery_rate*i + death_rate*i)\n",
        "  drdt = recovery_rate*i - reinfection_rate*r \n",
        "  dddt = death_rate*i\n",
        "    \n",
        "  # Return our system\n",
        "  return (dsdt, dedt, didt, drdt, dddt)\n",
        "\n",
        "\n",
        "def seird_model_ode(y, t, params): \n",
        "  # Parameters to find\n",
        "  infection_rate = params[0]\n",
        "  recovery_rate = params[1]\n",
        "  exposed_rate = params[2]\n",
        "  reinfection_rate = params[3]\n",
        "  death_rate = params[4]\n",
        "  \n",
        "  # Y variables\n",
        "  s = y[0]\n",
        "  e = y[1]\n",
        "  i = y[2]\n",
        "  r = y[3]\n",
        "  d = y[4]\n",
        "  # SIR ODE System \n",
        "  dsdt = -exposed_rate*s*(i+e) + reinfection_rate*r\n",
        "  dedt = (exposed_rate*s*(i+e)) - (infection_rate*e)\n",
        "  didt = (infection_rate*e) - (recovery_rate*i + death_rate*i)\n",
        "  drdt = recovery_rate*i - reinfection_rate*r\n",
        "  dddt = death_rate*i\n",
        "    \n",
        "  # Return our system\n",
        "  return (dsdt, dedt, didt, drdt, dddt)\n",
        "\n",
        "def calculate_seird_model(params, t, initial_condition):\n",
        "  if Consider_Exposed_as_Infectious:\n",
        "    seird_ode = lambda y,t:seird_model_ode(y,t, params)\n",
        "  else:\n",
        "    seird_ode = lambda y,t:seird_v2_model_ode(y,t, params)\n",
        "  ode_result = integrate.odeint(func=seird_ode, y0=initial_condition, t=t)\n",
        "  return ode_result\n",
        "\n",
        "def fit_seird_model(params_to_fit, t, initial_condition, i_r_true):\n",
        "  fit_result = calculate_seird_model(params_to_fit, t, initial_condition)\n",
        "  residual_i = i_r_true[0] - fit_result[:,2]\n",
        "  residual_r = i_r_true[1] - fit_result[:,3]\n",
        "  residual_d = i_r_true[2] - fit_result[:,4]\n",
        "  residual = np.concatenate((residual_i, residual_r , residual_d))\n",
        "  return residual\n",
        "\n",
        "def seird_predict(N, status,lockdownDay,countryName):\n",
        "  #Initial Values of SEIRD\n",
        "  I_start = status.iloc[0]['Confirmed']/N\n",
        "  E_start = (status.iloc[Days_From_Exposed_To_Infected]['Confirmed'] - status.iloc[0]['Confirmed'])/N\n",
        "  S_start = 1 - E_start - I_start\n",
        "  R_start = status.iloc[0]['Recovered']/N\n",
        "  D_start = status.iloc[0]['Deceased']/N\n",
        "  ic = (S_start, E_start, I_start, R_start , D_start)\n",
        "\n",
        "  #Dividing the Data to Two Phases\n",
        "  beforelockdown=status.iloc[0:lockdownDay]\n",
        "  afterlockdown=status.iloc[lockdownDay+1:]\n",
        "  i_r_true_bf = (list(beforelockdown['Confirmed']/N), list(beforelockdown['Recovered']/N) , list(beforelockdown['Deceased']/N))\n",
        "  i_r_true_af = (list(afterlockdown['Confirmed']/N), list(afterlockdown['Recovered']/N) , list(afterlockdown['Deceased']/N))\n",
        "\n",
        "  time_opt_bf = range(0, lockdownDay)\n",
        "  time_opt_af = range(0, len(afterlockdown))\n",
        "  time_opt =range(1,len(status))\n",
        "  \n",
        "  # Find Minimum for Start Day of Exposed Data\n",
        "\n",
        "  E_start_day = min(len(status['Days_Passed']),len(beforelockdown)+Days_From_Exposed_To_Infected)\n",
        "  E_start_af = (status.iloc[E_start_day]['Confirmed'] - status.iloc[len(beforelockdown)]['Confirmed'])/N\n",
        "  I_start_af = status.iloc[len(beforelockdown)]['Confirmed']/N\n",
        "  S_start_af = 1 - E_start_af - I_start_af\n",
        "  R_start_af = status.iloc[len(beforelockdown)]['Recovered']/N\n",
        "  D_start_af = status.iloc[len(beforelockdown)]['Deceased']/N\n",
        "\n",
        "  # Calculating Optimal Solution\n",
        "  ic_af = (S_start_af, E_start_af, I_start_af, R_start_af, D_start_af)  \n",
        "  params_start_guess = [0.01, 0.001, 0.005, 0.001 , 0.00005]\n",
        "  # assert (len())\n",
        "  optimal = optimize.least_squares(fit_seird_model,\n",
        "    x0=params_start_guess,\n",
        "    args=(time_opt_bf, ic, i_r_true_bf),\n",
        "    ftol=1.49012e-22,\n",
        "    jac= '3-point',\n",
        "    method = 'trf',loss= 'linear' , verbose = 1)\n",
        "  optimal_af = optimize.least_squares(fit_seird_model,\n",
        "    x0=params_start_guess,\n",
        "    args=(time_opt_af, ic_af, i_r_true_af),\n",
        "    ftol=1.49012e-22,\n",
        "    jac= '3-point',\n",
        "    method = 'trf' , loss = 'linear', verbose = 1)\n",
        "  optimal_params = optimal.x\n",
        "  optimal_params_af = optimal_af.x\n",
        "  # Printing Optimal Solution\n",
        "  print('## '+countryName+' In Intial Phase')\n",
        "  print('Optimized infection rate: ', optimal_params[0])\n",
        "  print('Optimized recovered rate: ', optimal_params[1])\n",
        "  print('Optimized exposed rate: ', optimal_params[2])\n",
        "  print('Optimized reinfection rate: ', optimal_params[3])\n",
        "  print('Optimized Death rate: ', optimal_params[4])\n",
        "  print('\\n')\n",
        "  print('## '+countryName+' after Phase')\n",
        "  print('Optimize infection rate: ', optimal_params_af[0])\n",
        "  print('Optimize recovered rate: ', optimal_params_af[1])\n",
        "  print('Optimize exposed rate: ', optimal_params_af[2])\n",
        "  print('Optimized reinfection rate: ', optimal_params_af[3])\n",
        "  print('Optimized Death rate: ', optimal_params_af[4])\n",
        "  ir = optimal_params[0]\n",
        "  rr = optimal_params[1]\n",
        "  er = optimal_params[2]\n",
        "  rir = optimal_params[3]\n",
        "  dr = optimal_params[4]\n",
        "  ir_af = optimal_params_af[0]\n",
        "  rr_af = optimal_params_af[1]\n",
        "  er_af = optimal_params_af[2]\n",
        "  rir_af = optimal_params_af[3]\n",
        "  dr_af = optimal_params_af[4]\n",
        "\n",
        "  fit_result_bf = calculate_seird_model((ir, rr, er, rir , dr), time_opt_bf, ic)\n",
        "  fit_result_af = calculate_seird_model((ir_af, rr_af, er_af, rir_af , dr_af), time_opt_af, ic_af)\n",
        "\n",
        "  plot_color = list(sns.color_palette(Style_Color,n_colors=6).as_hex())\n",
        "  fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, sharey=False, sharex=False, figsize=[Graphs_Width,int(Graphs_Height/3)])\n",
        "  # fig.text(0.5, 0.04, 'Number of days after March-01 2020', ha='center', fontsize=18)\n",
        "\n",
        "  ax1.set_title('Infected cases in '+ countryName,fontsize=20)\n",
        "  ax1.plot(time_opt, i_r_true_bf[0]+i_r_true_af[0], 'o-', color= plot_color[0] , markersize = 0.3)\n",
        "  ax1.plot(time_opt, np.hstack((fit_result_bf[:,2],fit_result_af[:,3])), 'o-', color= plot_color[3] , markersize=0.3)\n",
        "  ax1.legend(['Actual infection', 'Predicted infection'],loc=2, fontsize=12)\n",
        "  ax1.set_ylabel('Proportion of population')\n",
        "  ax1.set_xlabel('No. of Days Passed')\n",
        "  \n",
        "  ax2.set_title('Recovered cases in '+countryName,fontsize=20)    \n",
        "  ax2.plot(time_opt, i_r_true_bf[1]+i_r_true_af[1], 'o-', color= plot_color[1] ,  markersize = .3)\n",
        "  ax2.plot(time_opt, np.hstack((fit_result_bf[:,3],fit_result_af[:,3])), 'o-', color= plot_color[4],markersize=0.3)\n",
        "  ax2.legend(['Actual Recovery', 'Predicted Recovery'],loc=2, fontsize=12)\n",
        "  ax2.set_ylabel('Proportion of population')\n",
        "  ax2.set_xlabel('No. of Days Passed')\n",
        "\n",
        "  ax3.set_title('Deceased cases in '+countryName,fontsize=20)    \n",
        "  ax3.plot(time_opt, i_r_true_bf[2]+i_r_true_af[2], 'o-', color= plot_color[2] ,  markersize = .3)\n",
        "  ax3.plot(time_opt, np.hstack((fit_result_bf[:,4],fit_result_af[:,4])), 'o-', color= plot_color[5],markersize=0.3)\n",
        "  ax3.legend(['Actual Deceased Cases', 'Predicted Deceased Cases'],loc=2, fontsize=12)\n",
        "  ax3.set_ylabel('Proportion of population')\n",
        "  ax3.set_xlabel('No. of Days Passed')\n",
        "\n",
        "  datetime_pred = pd.date_range(start=\"2020-03-01\",end=\"2021-01-01\", freq='D')\n",
        "  pred_time = [x.strftime(\"%Y-%m-%d\") for x in datetime_pred]\n",
        "  pred_range = range(0, len(pred_time))\n",
        "  pred_result = calculate_seird_model((ir_af, rr_af, er_af, rir_af, dr_af), pred_range, ic_af)\n",
        "  # time_axis = [pred_time[i] for i in[0, 29, 60, 90, 121, 151, 182, 213, 243, 274, 304]]\n",
        "  # time_labels = ['Mar.', 'Apr.', 'May', 'June', 'July', 'Aug.', 'Sept.', 'Oct.', 'Nov.', 'Dec.', 'Jan.']\n",
        "  \n",
        "  ## Plot SEIDR\n",
        "  fig, ax = plt.subplots(figsize=[Graphs_Width,Graphs_Height])\n",
        "\n",
        "  ax.plot(pred_range, pred_result[:,0],color=plot_color[0] ) #susceptible\n",
        "  ax.plot(pred_range, pred_result[:,1],color=plot_color[1] ) #exposed\n",
        "  ax.plot(pred_range, pred_result[:,2],color=plot_color[2] ) #infected\n",
        "  ax.plot(pred_range, pred_result[:,3], color = plot_color[3] ) #recovered\n",
        "  ax.plot(pred_range, pred_result[:,4], color = plot_color[4] ) #deceased\n",
        "  # ax.plot(pred_time, pred_result[:,4], color = plot_color[4] ) #deceased\n",
        "  ax.legend(loc=1, labels=['Susceptible', 'Exposed', 'Infected', 'Recovered' , 'Deceased'])\n",
        "  ax.set_title('SEIRD predictions')\n",
        "  ax.set_xlabel('Months')\n",
        "  ax.set_ylabel('Proportion of population', fontsize=12)\n",
        "  # plt.xticks(time_axis, time_labels, rotation='vertical');\n",
        "  return optimal , optimal_af\n",
        "optimal , optimal_af = seird_predict(138*1e6 ,India_.reset_index(drop = True), Phase_Differnce, 'India');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmiv0f3z9PHu"
      },
      "source": [
        "## New Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC2m6nlazrpd",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='' height=\"200\" alt=\"SEIRD-logo\"/></center>\n",
        "#@markdown <center><h2><br>Predict Corona Virus Cases in Country With SEIRD Model</h2></center><br>\n",
        "Days_From_Exposed_To_Infected = 7 #@param {type:\"slider\", min:0, max:21, step:1}\n",
        "Phase_Differnce = 59 #@param {type:\"slider\", min:0, max:300, step:1}\n",
        "Consider_Exposed_as_Infectious = True #@param {type:\"boolean\"}\n",
        "\n",
        "def seird_v2_model_ode(y, t, params): \n",
        "  # Parameters to find\n",
        "  infection_rate = params[0]\n",
        "  recovery_rate = params[1]\n",
        "  exposed_rate = params[2]\n",
        "  reinfection_rate = params[3]\n",
        "  death_rate = params[4]\n",
        "  \n",
        "  # Y variables\n",
        "  s = y[0]\n",
        "  e = y[1]\n",
        "  i = y[2]\n",
        "  r = y[3]\n",
        "  d = y[4]\n",
        "  # SIR ODE System \n",
        "  dsdt = -exposed_rate*s*i + reinfection_rate*r\n",
        "  dedt = (exposed_rate*s*i) - (infection_rate*e)\n",
        "  didt = (infection_rate*e) - (recovery_rate*i + death_rate*i)\n",
        "  drdt = recovery_rate*i - reinfection_rate*r \n",
        "  dddt = death_rate*i\n",
        "    \n",
        "  # Return our system\n",
        "  return (dsdt, dedt, didt, drdt, dddt)\n",
        "\n",
        "\n",
        "def seird_model_ode(y, t, params): \n",
        "  # Parameters to find\n",
        "  infection_rate = params[0]\n",
        "  recovery_rate = params[1]\n",
        "  exposed_rate = params[2]\n",
        "  reinfection_rate = params[3]\n",
        "  death_rate = params[4]\n",
        "  \n",
        "  # Y variables\n",
        "  s = y[0]\n",
        "  e = y[1]\n",
        "  i = y[2]\n",
        "  r = y[3]\n",
        "  d = y[4]\n",
        "  # SIR ODE System \n",
        "  dsdt = -exposed_rate*s*(i+e) + reinfection_rate*r\n",
        "  dedt = (exposed_rate*s*(i+e)) - (infection_rate*e)\n",
        "  didt = (infection_rate*e) - (recovery_rate*i + death_rate*i)\n",
        "  drdt = recovery_rate*i - reinfection_rate*r\n",
        "  dddt = death_rate*i\n",
        "    \n",
        "  # Return our system\n",
        "  return (dsdt, dedt, didt, drdt, dddt)\n",
        "\n",
        "def calculate_seird_model(params, t, initial_condition):\n",
        "  if Consider_Exposed_as_Infectious:\n",
        "    seird_ode = lambda y,t:seird_model_ode(y,t, params)\n",
        "  else:\n",
        "    seird_ode = lambda y,t:seird_v2_model_ode(y,t, params)\n",
        "  ode_result = integrate.odeint(func=seird_ode, y0=initial_condition, t=t)\n",
        "  return ode_result\n",
        "\n",
        "def fit_seird_model(params_to_fit, t, initial_condition, i_r_true):\n",
        "  fit_result = calculate_seird_model(params_to_fit, t, initial_condition)\n",
        "  residual_i = i_r_true[0] - fit_result[:,2]\n",
        "  residual_r = i_r_true[1] - fit_result[:,3]\n",
        "  residual_d = i_r_true[2] - fit_result[:,4]\n",
        "  residual = np.concatenate((residual_i, residual_r , residual_d))\n",
        "  return residual\n",
        "\n",
        "def seird_predict(N, status,lockdownDay,countryName):\n",
        "  #Initial Values of SEIRD\n",
        "  I_start = status.iloc[0]['Confirmed']/N\n",
        "  E_start = (status.iloc[Days_From_Exposed_To_Infected]['Confirmed'] - status.iloc[0]['Confirmed'])/N\n",
        "  S_start = 1 - E_start - I_start\n",
        "  R_start = status.iloc[0]['Recovered']/N\n",
        "  D_start = status.iloc[0]['Deceased']/N\n",
        "  ic = (S_start, E_start, I_start, R_start , D_start)\n",
        "\n",
        "  #Dividing the Data to Two Phases\n",
        "  beforelockdown=status.iloc[0:lockdownDay]\n",
        "  afterlockdown=status.iloc[lockdownDay+1:]\n",
        "  i_r_true_bf = (list(beforelockdown['Confirmed']/N), list(beforelockdown['Recovered']/N) , list(beforelockdown['Deceased']/N))\n",
        "  i_r_true_af = (list(afterlockdown['Confirmed']/N), list(afterlockdown['Recovered']/N) , list(afterlockdown['Deceased']/N))\n",
        "\n",
        "  time_opt_bf = range(0, lockdownDay)\n",
        "  time_opt_af = range(0, len(afterlockdown))\n",
        "  time_opt =range(1,len(status))\n",
        "  \n",
        "  # Find Minimum for Start Day of Exposed Data\n",
        "\n",
        "  E_start_day = min(len(status['Days_Passed']),len(beforelockdown)+Days_From_Exposed_To_Infected)\n",
        "  E_start_af = (status.iloc[E_start_day]['Confirmed'] - status.iloc[len(beforelockdown)]['Confirmed'])/N\n",
        "  I_start_af = status.iloc[len(beforelockdown)]['Confirmed']/N\n",
        "  S_start_af = 1 - E_start_af - I_start_af\n",
        "  R_start_af = status.iloc[len(beforelockdown)]['Recovered']/N\n",
        "  D_start_af = status.iloc[len(beforelockdown)]['Deceased']/N\n",
        "\n",
        "  # Calculating Optimal Solution\n",
        "  ic_af = (S_start_af, E_start_af, I_start_af, R_start_af, D_start_af)  \n",
        "  params_start_guess = [0.01, 0.001, 0.005, 0.001 , 0.00005]\n",
        "  # assert (len())\n",
        "  optimal = optimize.least_squares(fit_seird_model,\n",
        "    x0=params_start_guess,\n",
        "    args=(time_opt_bf, ic, i_r_true_bf),\n",
        "    ftol=1.49012e-22,\n",
        "    jac= '3-point',\n",
        "    method = 'trf',loss= 'linear' , verbose = 1)\n",
        "  optimal_af = optimize.least_squares(fit_seird_model,\n",
        "    x0=params_start_guess,\n",
        "    args=(time_opt_af, ic_af, i_r_true_af),\n",
        "    ftol=1.49012e-22,\n",
        "    jac= '3-point',\n",
        "    method = 'trf' , loss = 'linear', verbose = 1)\n",
        "  optimal_params = optimal.x\n",
        "  optimal_params_af = optimal_af.x\n",
        "  # Printing Optimal Solution\n",
        "  print('## '+countryName+' In Intial Phase')\n",
        "  print('Optimized infection rate: ', optimal_params[0])\n",
        "  print('Optimized recovered rate: ', optimal_params[1])\n",
        "  print('Optimized exposed rate: ', optimal_params[2])\n",
        "  print('Optimized reinfection rate: ', optimal_params[3])\n",
        "  print('Optimized Death rate: ', optimal_params[4])\n",
        "  print('\\n')\n",
        "  print('## '+countryName+' after Phase')\n",
        "  print('Optimize infection rate: ', optimal_params_af[0])\n",
        "  print('Optimize recovered rate: ', optimal_params_af[1])\n",
        "  print('Optimize exposed rate: ', optimal_params_af[2])\n",
        "  print('Optimized reinfection rate: ', optimal_params_af[3])\n",
        "  print('Optimized Death rate: ', optimal_params_af[4])\n",
        "  ir = optimal_params[0]\n",
        "  rr = optimal_params[1]\n",
        "  er = optimal_params[2]\n",
        "  rir = optimal_params[3]\n",
        "  dr = optimal_params[4]\n",
        "  ir_af = optimal_params_af[0]\n",
        "  rr_af = optimal_params_af[1]\n",
        "  er_af = optimal_params_af[2]\n",
        "  rir_af = optimal_params_af[3]\n",
        "  dr_af = optimal_params_af[4]\n",
        "\n",
        "  fit_result_bf = calculate_seird_model((ir, rr, er, rir , dr), time_opt_bf, ic)\n",
        "  fit_result_af = calculate_seird_model((ir_af, rr_af, er_af, rir_af , dr_af), time_opt_af, ic_af)\n",
        "\n",
        "  plot_color = list(sns.color_palette(Style_Color,n_colors=6).as_hex())\n",
        "  fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, sharey=False, sharex=False, figsize=[Graphs_Width,int(Graphs_Height/3)])\n",
        "  # fig.text(0.5, 0.04, 'Number of days after March-01 2020', ha='center', fontsize=18)\n",
        "\n",
        "  ax1.set_title('Infected cases in '+ countryName,fontsize=20)\n",
        "  ax1.plot(time_opt, i_r_true_bf[0]+i_r_true_af[0], 'o-', color= plot_color[0] , markersize = 0.3)\n",
        "  ax1.plot(time_opt, np.hstack((fit_result_bf[:,2],fit_result_af[:,3])), 'o-', color= plot_color[3] , markersize=0.3)\n",
        "  ax1.legend(['Actual infection', 'Predicted infection'],loc=2, fontsize=12)\n",
        "  ax1.set_ylabel('Proportion of population')\n",
        "  ax1.set_xlabel('No. of Days Passed')\n",
        "  \n",
        "  ax2.set_title('Recovered cases in '+countryName,fontsize=20)    \n",
        "  ax2.plot(time_opt, i_r_true_bf[1]+i_r_true_af[1], 'o-', color= plot_color[1] ,  markersize = .3)\n",
        "  ax2.plot(time_opt, np.hstack((fit_result_bf[:,3],fit_result_af[:,3])), 'o-', color= plot_color[4],markersize=0.3)\n",
        "  ax2.legend(['Actual Recovery', 'Predicted Recovery'],loc=2, fontsize=12)\n",
        "  ax2.set_ylabel('Proportion of population')\n",
        "  ax2.set_xlabel('No. of Days Passed')\n",
        "\n",
        "  ax3.set_title('Deceased cases in '+countryName,fontsize=20)    \n",
        "  ax3.plot(time_opt, i_r_true_bf[2]+i_r_true_af[2], 'o-', color= plot_color[2] ,  markersize = .3)\n",
        "  ax3.plot(time_opt, np.hstack((fit_result_bf[:,4],fit_result_af[:,4])), 'o-', color= plot_color[5],markersize=0.3)\n",
        "  ax3.legend(['Actual Deceased Cases', 'Predicted Deceased Cases'],loc=2, fontsize=12)\n",
        "  ax3.set_ylabel('Proportion of population')\n",
        "  ax3.set_xlabel('No. of Days Passed')\n",
        "\n",
        "  datetime_pred = pd.date_range(start=\"2020-03-01\",end=\"2021-01-01\", freq='D')\n",
        "  pred_time = [x.strftime(\"%Y-%m-%d\") for x in datetime_pred]\n",
        "  pred_range = range(0, len(pred_time))\n",
        "  pred_result = calculate_seird_model((ir_af, rr_af, er_af, rir_af, dr_af), pred_range, ic_af)\n",
        "  # time_axis = [pred_time[i] for i in[0, 29, 60, 90, 121, 151, 182, 213, 243, 274, 304]]\n",
        "  # time_labels = ['Mar.', 'Apr.', 'May', 'June', 'July', 'Aug.', 'Sept.', 'Oct.', 'Nov.', 'Dec.', 'Jan.']\n",
        "  \n",
        "  ## Plot SEIDR\n",
        "  fig, ax = plt.subplots(figsize=[Graphs_Width,Graphs_Height])\n",
        "\n",
        "  ax.plot(pred_range, pred_result[:,0],color=plot_color[0] ) #susceptible\n",
        "  ax.plot(pred_range, pred_result[:,1],color=plot_color[1] ) #exposed\n",
        "  ax.plot(pred_range, pred_result[:,2],color=plot_color[2] ) #infected\n",
        "  ax.plot(pred_range, pred_result[:,3], color = plot_color[3] ) #recovered\n",
        "  ax.plot(pred_range, pred_result[:,4], color = plot_color[4] ) #deceased\n",
        "  # ax.plot(pred_time, pred_result[:,4], color = plot_color[4] ) #deceased\n",
        "  ax.legend(loc=1, labels=['Susceptible', 'Exposed', 'Infected', 'Recovered' , 'Deceased'])\n",
        "  ax.set_title('SEIRD predictions')\n",
        "  ax.set_xlabel('Months')\n",
        "  ax.set_ylabel('Proportion of population', fontsize=12)\n",
        "  # plt.xticks(time_axis, time_labels, rotation='vertical');\n",
        "  return optimal , optimal_af\n",
        "optimal , optimal_af = seird_predict(138*1e6 ,India_.reset_index(drop = True), Phase_Differnce, 'India');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGZmDQJMWZ2C"
      },
      "source": [
        "## Prophet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rmMMg2OXulW",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='https://external-content.duckduckgo.com/iu/?u=http%3A%2F%2Fwww.pngall.com%2Fwp-content%2Fuploads%2F2016%2F07%2FFacebook-Download-PNG.png&f=1&nofb=1' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2><br>Prophet Model for Forecasting</h2></center><br>\n",
        "\n",
        "Plot_Column = \"Confirmed\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_']\n",
        "Location = \"India\" #@param ['Kerala', 'Delhi', 'Telangana', 'India', 'Rajasthan', 'Haryana','UP', 'Ladakh', 'TN', 'J&K', 'Karnataka', 'Maharashtra', 'Punjab','Andra P', 'HP', 'Uttarakhand', 'Odisha', 'Puducherry','West Bengal', 'Chandigarh', 'Chhattisgarh', 'Gujarat', 'MP','Bihar', 'Manipur', 'Goa', 'Mizoram', 'A&N', 'Assam', 'Jharkhand','Arun P', 'Nagaland', 'Tripura', 'D&D', 'Meghalaya', 'Sikkim','Other']\n",
        "Predict_For = 55 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "\n",
        "\n",
        "prophet_data = Completed_[Completed_.State == Location][['Date' , Plot_Column]]\n",
        "prophet_data['Date'] = pd.to_datetime(prophet_data['Date'])\n",
        "prophet_data.columns = ['ds','y']\n",
        "\n",
        "m = Prophet()\n",
        "m.fit(prophet_data)\n",
        "future = m.make_future_dataframe(periods=Predict_For)\n",
        "forecast = m.predict(future)\n",
        "forecast.index = pd.to_datetime(forecast.ds)\n",
        "clear_output()\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=3).as_hex())\n",
        "plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "\n",
        "plt.bar(list(prophet_data.index) , prophet_data['y'].values, width = 0.3 , linewidth = 0 , color = list(sns.color_palette(Style_Color,n_colors=prophet_data.shape[0]).as_hex()) )\n",
        "plt.fill_between(list(forecast.index), forecast['yhat_lower'].values, forecast['yhat_upper'].values, color = plot_color[0] , alpha = 0.2 )\n",
        "plt.plot(forecast['yhat'], label = 'Predicted Corona Cases By Prophet Model ' , color = plot_color[1] )\n",
        "plt.plot(prophet_data['y'], label = 'Confirmed Corona Cases ' , color = plot_color[2] )\n",
        "\n",
        "plt.suptitle(Sup_Title, fontsize = 29)\n",
        "plt.title('{} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title() ) , fontsize = 19)\n",
        "plt.legend()\n",
        "plt.ylabel('Cases')\n",
        "plt.xlabel('Days Passed Since {}'.format(Completed_.Date.min()))\n",
        "plt.subplots_adjust(top=SubPlot_Top)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-C0bt5t1uPl"
      },
      "source": [
        "plot_plotly(m, forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6u6gpz31vfK"
      },
      "source": [
        "plot_components_plotly(m, forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NnfRmrcYDHJ"
      },
      "source": [
        "## Support Vector Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "7Sbz0QhNYJTL"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='https://svmwebsolutions.com/wp-content/uploads/2019/04/logo.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2><br>SVM Model for Forecasting</h2></center><br>\n",
        "\n",
        "Plot_Column = \"Confirmed\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_']\n",
        "Location = \"India\" #@param ['Kerala', 'Delhi', 'Telangana', 'India', 'Rajasthan', 'Haryana','UP', 'Ladakh', 'TN', 'J&K', 'Karnataka', 'Maharashtra', 'Punjab','Andra P', 'HP', 'Uttarakhand', 'Odisha', 'Puducherry','West Bengal', 'Chandigarh', 'Chhattisgarh', 'Gujarat', 'MP','Bihar', 'Manipur', 'Goa', 'Mizoram', 'A&N', 'Assam', 'Jharkhand','Arun P', 'Nagaland', 'Tripura', 'D&D', 'Meghalaya', 'Sikkim','Other']\n",
        "Kernel_SVM = \"poly\" #@param['poly','linear','rbf','sigmoid']\n",
        "Predict_For = 35 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "#@markdown <br><h4><i>* Note - SVR Show Poor Result Worst than expected</i></h4>\n",
        "\n",
        "svm=SVR(C=1,degree=6,kernel=Kernel_SVM , epsilon=0.01)\n",
        "# C -> Regularization Parameter\n",
        "# Degree -> Degree of Polynomial Kernel to use (Ignored for Others)\n",
        "# Kernel -> Kernel to use for Prediction\n",
        "\n",
        "data = Completed_[Completed_['State'] == Location]\n",
        "#Fitting model on the training data\n",
        "svm.fit(data['Days_Passed'].values.reshape(-1,1) , data[Plot_Column].values.reshape(-1,1))\n",
        "prediction_valid_svm=svm.predict(np.array(range(int(data['Days_Passed'].max()+Predict_For))).reshape(-1,1))\n",
        "\n",
        "clear_output()\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=3).as_hex())\n",
        "plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "\n",
        "plt.bar(list(data['Days_Passed'].values) ,data[Plot_Column].values, width = 0.2 , linewidth = 0 , color = list(sns.color_palette(Style_Color,n_colors=len(data)).as_hex()) )\n",
        "# plt.fill_between(list(forecast.index), forecast['yhat_lower'].values, forecast['yhat_upper'].values, color = plot_color[0] , alpha = 0.2 )\n",
        "plt.plot(prediction_valid_svm, label = 'Predicted Corona Cases By SVR Model ' , color = plot_color[1] )\n",
        "plt.plot(data[Plot_Column].values.reshape(-1,1), label = '{} Corona Cases '.format(Plot_Column) , color = plot_color[2] )\n",
        "\n",
        "plt.suptitle(Sup_Title, fontsize = 29)\n",
        "plt.title('{} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title() ) , fontsize = 19)\n",
        "plt.legend()\n",
        "plt.ylabel('Cases')\n",
        "plt.xlabel('Days Passed Since {}'.format(Completed_.Date.min()))\n",
        "plt.subplots_adjust(top=SubPlot_Top)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-vBDZzr6Blq"
      },
      "source": [
        "## Ploting Moving Average, Moving STD, ACF & PACF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqOmwZ_pB7Bj"
      },
      "source": [
        "\n",
        "\n",
        "*   Autocorrelation Function (ACF): It just measures the correlation between two consecutive (lagged version). example at lag 4, ACF will compare series at time instance t1…t2 with series at instance t1–4…t2–4\n",
        "\n",
        "*   Partial Autocorrelation Function (PACF): is used to measure the degree of association between y(t) and y(t-p).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gKJOjY96b1p",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='https://cdn1.iconfinder.com/data/icons/media-player-long-shadow/50/Repeat-512.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2><br>Correlations and Moving Average</h2></center><br>\n",
        "\n",
        "Plot_Column = \"Other\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_']\n",
        "Location = \"India\" #@param ['Kerala', 'Delhi', 'Telangana', 'India', 'Rajasthan', 'Haryana','UP', 'Ladakh', 'TN', 'J&K', 'Karnataka', 'Maharashtra', 'Punjab','Andra P', 'HP', 'Uttarakhand', 'Odisha', 'Puducherry','West Bengal', 'Chandigarh', 'Chhattisgarh', 'Gujarat', 'MP','Bihar', 'Manipur', 'Goa', 'Mizoram', 'A&N', 'Assam', 'Jharkhand','Arun P', 'Nagaland', 'Tripura', 'D&D', 'Meghalaya', 'Sikkim','Other']\n",
        "Season_Period = 7 #@param {type:\"slider\", min:1, max:40, step:1}\n",
        "Use_Log = False #@param {type:\"boolean\"}\n",
        "Date = 'Date'\n",
        "Predict_For = 0\n",
        "data = Completed_[Completed_['State'] == Location]\n",
        "times = pd.date_range(data[Date].min(), periods = data.shape[0]+Predict_For , freq='D')\n",
        "data.index = pd.to_datetime(data[Date])\n",
        "if Use_Log:\n",
        "  data[Plot_Column] = np.log1p(data[Plot_Column].values)\n",
        "train_split = data[Plot_Column]\n",
        "train_split_mean = train_split.rolling(Season_Period , min_periods = 1).mean()\n",
        "train_split_std = train_split.rolling(Season_Period , min_periods = 1).std()\n",
        "\n",
        "train_split_acf = pd.Series(acf(train_split, nlags = 40))\n",
        "train_split_pacf = pd.Series(pacf(train_split, nlags = 40 , method = 'ols') )\n",
        "\n",
        "Result = [[train_split_mean, 'Roling Mean'],\n",
        "          [train_split_std , 'Rolling STD'],\n",
        "          ]\n",
        "Result_2 =[[train_split_acf , 'Autocorrelation Function'],\n",
        "          [train_split_pacf, 'Partial Autocorrelation Function']]\n",
        "\n",
        "if True:\n",
        "  plot_color = list(sns.color_palette(Style_Color,n_colors=len(Result)+1).as_hex())\n",
        "  fig = plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  plt.suptitle(Sup_Title, fontsize = 29)\n",
        "  plt.subplots_adjust(top=SubPlot_Top)\n",
        "  plt.subplot(2,1,1)\n",
        "  plt.title('{} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title()  ) , fontsize = 19)\n",
        "\n",
        "  plt.fill_between(train_split.index , 0 , train_split , color = plot_color[0],alpha = .2 , label = 'Original Data')\n",
        "  for j,i in enumerate(Result):\n",
        "    plt.plot(i[0], label = i[1] , color = plot_color[j+1] )\n",
        "  plt.legend()\n",
        "  plt.ylabel('Cases')\n",
        "  plt.xlabel('Days Passed')\n",
        "  \n",
        "  # plt.plot()\n",
        "  plt.subplot(2,1,2)\n",
        "\n",
        "  # fig = plt.figure(figsize=(Graphs_Width,Graphs_Height/2))\n",
        "  for j,i in enumerate(Result_2):\n",
        "    plt.plot(i[0], label = i[1] , color = plot_color[j+1] )\n",
        "  plt.legend()\n",
        "  plt.plot()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CndOLEt0sjvl",
        "cellView": "form"
      },
      "source": [
        "Plot_Column = \"Deceased Deceased_\" #@param ['Confirmed Confirmed_', 'Recovered Recovered_', 'Deceased Deceased_', 'Other Other_', 'Tested Tested_', 'Active Active_']\n",
        "Location = \"India\" #@param ['Kerala', 'Delhi', 'Telangana', 'India', 'Rajasthan', 'Haryana','UP', 'Ladakh', 'TN', 'J&K', 'Karnataka', 'Maharashtra', 'Punjab','Andra P', 'HP', 'Uttarakhand', 'Odisha', 'Puducherry','West Bengal', 'Chandigarh', 'Chhattisgarh', 'Gujarat', 'MP','Bihar', 'Manipur', 'Goa', 'Mizoram', 'A&N', 'Assam', 'Jharkhand','Arun P', 'Nagaland', 'Tripura', 'D&D', 'Meghalaya', 'Sikkim','Other']\n",
        "Date = 'Date'\n",
        "\n",
        "data = Completed_[Completed_['State'] == Location]\n",
        "# times = pd.date_range(data[Date].min(), periods = data.shape[0] , freq='D')\n",
        "# data.index = pd.to_datetime(data[Date])\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=4).as_hex())\n",
        "\n",
        "Plot_Column = Plot_Column.split(' ')\n",
        "n_cols = 2\n",
        "n_rows = 2\n",
        "plt.figure(figsize = (Graphs_Width,Graphs_Height))\n",
        "plt.subplot(n_rows , n_cols , 1)\n",
        "plot_acf(data[Plot_Column[0]], lags = 75, ax = plt.gca() , c = plot_color[0] , title = Plot_Column[0]+' Autocorrelation' )\n",
        "plt.subplot(n_rows , n_cols , 2)\n",
        "plot_pacf(data[Plot_Column[0]], lags = 75, ax = plt.gca() , c = plot_color[1], title = Plot_Column[0]+' Partial Autocorrelation' )\n",
        "plt.subplot(n_rows , n_cols , 3)\n",
        "plot_acf(data[Plot_Column[1]] , lags = 75, ax = plt.gca() , c = plot_color[2], title = Plot_Column[1]+' Autocorrelation' )\n",
        "plt.subplot(n_rows , n_cols , 4)\n",
        "plot_pacf(data[Plot_Column[1]] , lags = 75, ax = plt.gca() , c = plot_color[3], title = Plot_Column[1]+' Partial Autocorrelation' )\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X50_IsIVgV_"
      },
      "source": [
        "## Seasonal decomposition using Moving Averages.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFJLZJ1zcS8K"
      },
      "source": [
        "Decomposing Time Series into several components-Trend, Seasonality, and Random noise. We know that Time series data is composed of Level, Trend, Seasonality, and Random noise. Let’s decompose the data and plot the trend, seasonality, and randomness in the data.\n",
        "<br>\n",
        "We use statsmodel for seasonal decompose as an Additive / Multiplicative Model and the Period of the time series, which is the periodicity of the data, which is ***14 days*** as Infection Time of Corona Virus.\n",
        "<br>\n",
        "><b>Additive model</b> = Trend + Seasonality + Random Noise<br>\n",
        "><b>Multiplicative model</b> = Trend * Seasonality * Random Noise<br>\n",
        "\n",
        "The seasonal component is first removed by applying a convolution filter to the data. The average of this smoothed series for each period is the returned seasonal component.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_tn0w9bE6Mc",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='https://cdn2.iconfinder.com/data/icons/wirecons-free-vector-icons/32/475331-calculate-512.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2><br>Seasonal Decompose of Data</h2></center><br>\n",
        "\n",
        "Plot_Column = \"Confirmed\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_']\n",
        "Location = \"India\" #@param ['Kerala', 'Delhi', 'Telangana', 'India', 'Rajasthan', 'Haryana','UP', 'Ladakh', 'TN', 'J&K', 'Karnataka', 'Maharashtra', 'Punjab','Andra P', 'HP', 'Uttarakhand', 'Odisha', 'Puducherry','West Bengal', 'Chandigarh', 'Chhattisgarh', 'Gujarat', 'MP','Bihar', 'Manipur', 'Goa', 'Mizoram', 'A&N', 'Assam', 'Jharkhand','Arun P', 'Nagaland', 'Tripura', 'D&D', 'Meghalaya', 'Sikkim','Other']\n",
        "Season_Period = 14 #@param {type:\"slider\", min:1, max:40, step:1}\n",
        "Model_Behaviour = \"add\" #@param [\"add\", \"mul\"]\n",
        "\n",
        "data = Completed_[Completed_['State'] == Location]\n",
        "train_split = data[Plot_Column].values\n",
        "train_split = pd.Series(train_split)\n",
        "if Model_Behaviour == 'mul':\n",
        "  train_split = train_split +0.000001 \n",
        "seas_d=sm.tsa.seasonal_decompose(train_split,model=Model_Behaviour,period=Season_Period , extrapolate_trend='freq')\n",
        "\n",
        "print('Accuracy Scores For Data is :\\n  -> Mean Squared Error : {} ({})\\n  -> Root Mean Squared Error : {} ({})\\n  -> Standard Deviation : {} ({})\\n  -> Mean Absolute Error : {} ({})\\n'\\\n",
        "      .format(\\\n",
        "              eval.mse(seas_d.trend.values, train_split),\\\n",
        "              eval.mse(seas_d.trend.values, train_split)/len(train_split), \\\n",
        "              eval.rmse(seas_d.trend.values, train_split) , \\\n",
        "              eval.rmse(seas_d.trend.values, train_split)/len(train_split) , \\\n",
        "              eval.stde(seas_d.trend.values, train_split), \\\n",
        "              eval.stde(seas_d.trend.values, train_split)/len(train_split), \\\n",
        "              eval.meanabs(seas_d.trend.values, train_split),\\\n",
        "              eval.meanabs(seas_d.trend.values, train_split)/len(train_split)\\\n",
        "              )\\\n",
        "      )\n",
        "\n",
        "plot_color = list(sns.color_palette(Style_Color,n_colors=4).as_hex())\n",
        "Plt_Col = 2\n",
        "Plt_Row = 1\n",
        "plt.figure(figsize=(Graphs_Width,Graphs_Height/Plt_Col))\n",
        "\n",
        "plt.subplot(Plt_Row,Plt_Col , 1)\n",
        "plt.plot(seas_d.seasonal.values , label = 'Estimated Seasonal Component', color = plot_color[0])\n",
        "plt.fill_between(list(range(seas_d.nobs[0])) ,0, seas_d.seasonal.values ,color = plot_color[0] , alpha =0.4)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(Plt_Row,Plt_Col , 2)\n",
        "plt.plot(seas_d.resid.values , label = 'Estimated Residual Component', color = plot_color[1])\n",
        "plt.fill_between(list(range(seas_d.nobs[0])) ,0, seas_d.seasonal.values ,color = plot_color[1] , alpha =0.4 , label = 'Estimated Seasonal Components')\n",
        "plt.legend()\n",
        "\n",
        "plt.suptitle(Sup_Title, fontsize = 29)\n",
        "plt.subplots_adjust(top=SubPlot_Top)\n",
        "plt.plot()\n",
        "\n",
        "plt.figure(figsize=(Graphs_Width,Graphs_Height/Plt_Col))\n",
        "plt.plot(seas_d.observed.values , label = 'Observed Component', color = plot_color[2])\n",
        "plt.plot(seas_d.trend.values , label = 'Estimated Trend Component', color = plot_color[3])\n",
        "plt.legend()\n",
        "plt.plot()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgwmc4Wt5vq5"
      },
      "source": [
        "## AutoRegressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4v0QFTP5uoE",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='https://cdn0.iconfinder.com/data/icons/data-analytics-line/64/Autoregression-chart-graph-result-analytics-512.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2><br>Auto Regression for Forecasting</h2></center><br>\n",
        "AR_Model = \"AutoReg\" #@param [\"AutoReg\", \"ar_select_order\"]\n",
        "\n",
        "Plot_Column = \"Confirmed\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_']\n",
        "Location = \"India\" #@param ['Kerala', 'Delhi', 'Telangana', 'India', 'Rajasthan', 'Haryana','UP', 'Ladakh', 'TN', 'J&K', 'Karnataka', 'Maharashtra', 'Punjab','Andra P', 'HP', 'Uttarakhand', 'Odisha', 'Puducherry','West Bengal', 'Chandigarh', 'Chhattisgarh', 'Gujarat', 'MP','Bihar', 'Manipur', 'Goa', 'Mizoram', 'A&N', 'Assam', 'Jharkhand','Arun P', 'Nagaland', 'Tripura', 'D&D', 'Meghalaya', 'Sikkim','Other']\n",
        "Train_Split = 0.8 #@param {type:\"slider\", min:0.05, max:0.95, step:0.05}\n",
        "Predict_For = 20 #@param {type:\"slider\", min:0, max:100, step:5}\n",
        "Season_Period = 14 #@param {type:\"slider\", min:1, max:40, step:1}\n",
        "Plot_Forecast = \"Complete Plot ( Train + Test + Forecast )\" #@param [\"Complete Plot ( Train + Test + Forecast )\", \"Test + Forecast Plot\"]\n",
        "Plot_Log = \"MatplotLib\" #@param [\"Plotly\", \"MatplotLib\"]\n",
        "Plot_Summary = True #@param {type:\"boolean\"}\n",
        "Apply_Log = False #@param {type:\"boolean\"}\n",
        "Date = 'Date'\n",
        "data = Completed_[Completed_['State'] == Location]\n",
        "train_for = int(data.shape[0]*Train_Split)\n",
        "train_split = data.iloc[:train_for][Plot_Column].values + 0.00001\n",
        "valid_split = data.iloc[train_for:][Plot_Column].values + 0.00001\n",
        "if Apply_Log:\n",
        "  train_split = np.log1p(train_split)\n",
        "  valid_split = np.log1p(valid_split)\n",
        "\n",
        "train_split = pd.Series(train_split)\n",
        "valid_split = pd.Series(valid_split)\n",
        "if AR_Model == 'AutoReg':\n",
        "  es = AutoReg(train_split, 2 , trend = 'ct', seasonal = True , period = Season_Period)\n",
        "  es = es.fit()\n",
        "else:\n",
        "  es = ar_select_order(train_split, 2 , trend = 'ct', seasonal = True , period = Season_Period)\n",
        "  es.ar_lags\n",
        "  es = es.model.fit()\n",
        "if Plot_Summary:\n",
        "  print(es.summary())\n",
        "\n",
        "if Plot_Forecast == 'Test + Forecast Plot':\n",
        "  pred = es.predict(start = train_for, end = train_for + len(valid_split) + Predict_For)\n",
        "  Plot_Data = [\n",
        "               [list(range(train_for , train_for + len(pred),1)),\n",
        "               pred,'Predicted Forecast',':'\n",
        "               ],\n",
        "               [list(range(train_for , train_for+ len(valid_split))),\n",
        "               valid_split,'{} Covid Cases'.format(Plot_Column),'--'\n",
        "               ]\n",
        "  ]\n",
        "  \n",
        "else:\n",
        "  pred = es.predict(start = 0 , end = data.shape[0]+Predict_For )\n",
        "  Plot_Data = [\n",
        "               [list(range(0 , len(pred))),\n",
        "               pred,'Predicted Curve' ,':'\n",
        "               ],\n",
        "               [list(range(0, len(train_split))),\n",
        "                train_split , 'Actual Train Curve','--'\n",
        "               ],\n",
        "               [list(range(train_for , train_for+len(valid_split))),\n",
        "                valid_split , 'Observed Test Curve','--'\n",
        "               ]\n",
        "  ]\n",
        "# simulations = es.simulate(len(valid_split) + Predict_For , repetitions = No_Of_Simulations , error = 'add').values\n",
        "# Simulation_Data = [\n",
        "#                    list(range(train_for , train_for + len(valid_split) + Predict_For , 1)),\n",
        "#                    simulations[:,0],\n",
        "#                    simulations[:,-1]\n",
        "#                   ]\n",
        "pred = es.predict(start = 0 , end = data.shape[0]+Predict_For )\n",
        "pred = np.nan_to_num(pred, copy=True, nan=0.0, posinf=None, neginf=None)\n",
        "\n",
        "print('Accuracy Scores For Training Data :\\n  -> Mean Squared Error : {} ({})\\n  -> Root Mean Squared Error : {} ({})\\n  -> Standard Deviation : {} ({})\\n  -> Mean Absolute Error : {} ({})\\n'\\\n",
        "      .format(\\\n",
        "              eval.mse(pred[0:train_split.shape[0]], train_split),\\\n",
        "              eval.mse(pred[0:train_split.shape[0]], train_split)/len(train_split), \\\n",
        "              eval.rmse(pred[0:train_split.shape[0]], train_split) , \\\n",
        "              eval.rmse(pred[0:train_split.shape[0]], train_split)/len(train_split) , \\\n",
        "              eval.stde(pred[0:train_split.shape[0]], train_split), \\\n",
        "              eval.stde(pred[0:train_split.shape[0]], train_split)/len(train_split), \\\n",
        "              eval.meanabs(pred[0:train_split.shape[0]], train_split),\\\n",
        "              eval.meanabs(pred[0:train_split.shape[0]], train_split)/len(train_split)\\\n",
        "              )\\\n",
        "      )\n",
        "print('Accuracy Scores For Testing Data :\\n  -> Mean Squared Error : {} ({})\\n  -> Root Mean Squared Error : {} ({})\\n  -> Standard Deviation : {} ({})\\n  -> Mean Absolute Error : {} ({})\\n'\\\n",
        "      .format(\\\n",
        "              eval.mse(pred[-valid_split.shape[0]:], valid_split) ,\\\n",
        "              eval.mse(pred[-valid_split.shape[0]:], valid_split)/len(valid_split) ,\\\n",
        "              eval.rmse(pred[-valid_split.shape[0]:], valid_split) , \\\n",
        "              eval.rmse(pred[-valid_split.shape[0]:], valid_split)/len(valid_split) , \\\n",
        "              eval.stde(pred[-valid_split.shape[0]:], valid_split) , \\\n",
        "              eval.stde(pred[-valid_split.shape[0]:], valid_split)/len(valid_split) , \\\n",
        "              eval.meanabs(pred[-valid_split.shape[0]:], valid_split),\\\n",
        "              eval.meanabs(pred[-valid_split.shape[0]:], valid_split)/len(valid_split)\\\n",
        "              )\\\n",
        "      )\n",
        "if Plot_Lib == 'MatplotLib':\n",
        "  plot_color = list(sns.color_palette(Style_Color,n_colors=len(Plot_Data)+1).as_hex())\n",
        "  fig = plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  for j,i in enumerate(Plot_Data):\n",
        "    plt.plot(i[0], i[1],i[3],label = i[2] , color = plot_color[j+1]  )\n",
        "  \n",
        "  fig = es.plot_predict(fig = fig , start = train_for, end = train_for + len(valid_split) + Predict_For)\n",
        "  plt.suptitle(Sup_Title, fontsize = 29)\n",
        "  plt.title('{} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title()  ) , fontsize = 19)\n",
        "  plt.legend()\n",
        "  plt.ylabel('Cases')\n",
        "  plt.xlabel('Days Passed Since {}'.format(Completed_.Date.min()))\n",
        "  plt.subplots_adjust(top=SubPlot_Top)\n",
        "  plt.plot()\n",
        "  fig = plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  fig = es.plot_diagnostics(fig=fig, lags=2)\n",
        "  plt.plot()\n",
        "else:\n",
        "  fig=go.Figure()\n",
        "  for i in Plot_Data:\n",
        "    fig.add_trace(go.Scatter(x = i[0], y = i[1], mode = 'lines+markers', name = i[2]))\n",
        "\n",
        "  fig.update_layout(title='{} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title()),\n",
        "                  xaxis_title='Days Passed Since {}'.format(Completed_.Date.min()),yaxis_title=\"Cases\",legend=dict(x=0,y=1,traceorder=\"normal\"))\n",
        "  fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApiKB67cp-RN"
      },
      "source": [
        "## Simple Exponential Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoAYnUk_qYKh",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='https://cdn4.iconfinder.com/data/icons/coronavirus-1/512/wuhan-coronavirus-virus-outbreak-02-256.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2><br>Simple Exponential Smoothing for Forecasting</h2></center><br>\n",
        "\n",
        "Plot_Column = \"Confirmed\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_']\n",
        "Location = \"India\" #@param ['Kerala', 'Delhi', 'Telangana', 'India', 'Rajasthan', 'Haryana','UP', 'Ladakh', 'TN', 'J&K', 'Karnataka', 'Maharashtra', 'Punjab','Andra P', 'HP', 'Uttarakhand', 'Odisha', 'Puducherry','West Bengal', 'Chandigarh', 'Chhattisgarh', 'Gujarat', 'MP','Bihar', 'Manipur', 'Goa', 'Mizoram', 'A&N', 'Assam', 'Jharkhand','Arun P', 'Nagaland', 'Tripura', 'D&D', 'Meghalaya', 'Sikkim','Other']\n",
        "Train_Split = 0.8 #@param {type:\"slider\", min:0.05, max:0.95, step:0.05}\n",
        "Predict_For = 25 #@param {type:\"slider\", min:0, max:100, step:5}\n",
        "No_Of_Simulations = 100 #@param {type:\"slider\", min:10, max:500, step:5}\n",
        "Initialization_Method = \"legacy-heuristic\" #@param [\"None\", \"estimated\", \"heuristic\", \"legacy-heuristic\"]\n",
        "Plot_Forecast = \"Complete Plot ( Train + Test + Forecast )\" #@param [\"Complete Plot ( Train + Test + Forecast )\", \"Test + Forecast Plot\"]\n",
        "Plot_Lib = \"MatplotLib\" #@param [\"Plotly\", \"MatplotLib\"]\n",
        "Plot_Summary = True #@param {type:\"boolean\"}\n",
        "Apply_Log = True #@param {type:\"boolean\"}\n",
        "\n",
        "Date = 'Date'\n",
        "Model_Name = \"Exponential Smoothing\"\n",
        "data = Completed_[Completed_['State'] == Location]\n",
        "train_for = int(data.shape[0]*Train_Split)\n",
        "train_split = data.iloc[:train_for][Plot_Column].values + 0.00001\n",
        "valid_split = data.iloc[train_for:][Plot_Column].values + 0.00001\n",
        "\n",
        "if Apply_Log:\n",
        "  train_split = np.log1p(train_split)\n",
        "  valid_split = np.log1p(valid_split)\n",
        "\n",
        "train_split = pd.Series(train_split)\n",
        "valid_split = pd.Series(valid_split)\n",
        "\n",
        "if Initialization_Method == 'None':\n",
        "  Initialization_Method = None\n",
        "\n",
        "es = SimpleExpSmoothing(train_split, initialization_method=Initialization_Method).fit()\n",
        "if Plot_Summary:\n",
        "  print(es.summary())\n",
        "\n",
        "if Plot_Forecast == 'Test + Forecast Plot':\n",
        "  pred = es.predict(start = train_for, end = train_for + len(valid_split) + Predict_For)\n",
        "  Plot_Data = [\n",
        "               [list(range(train_for , train_for + len(pred),1)),\n",
        "               pred,'Predicted Forecast',':'\n",
        "               ],\n",
        "               [list(range(train_for , train_for+ len(valid_split))),\n",
        "               valid_split,'{} Covid Cases'.format(Plot_Column),'--'\n",
        "               ]\n",
        "  ]\n",
        "  \n",
        "else:\n",
        "  pred = es.predict(start = 0 , end = data.shape[0]+Predict_For )\n",
        "  Plot_Data = [\n",
        "               [list(range(0 , len(pred))),\n",
        "               pred,'Predicted Curve' ,':'\n",
        "               ],\n",
        "               [list(range(0, len(train_split))),\n",
        "                train_split , 'Actual Train Curve','--'\n",
        "               ],\n",
        "               [list(range(train_for , train_for+len(valid_split))),\n",
        "                valid_split , 'Observed Test Curve','--'\n",
        "               ]\n",
        "  ]\n",
        "simulations = es.simulate(len(valid_split) + Predict_For , repetitions = No_Of_Simulations , error = 'add').values\n",
        "Simulation_Data = [\n",
        "                   list(range(train_for , train_for + len(valid_split) + Predict_For , 1)),\n",
        "                   simulations[:,0],\n",
        "                   simulations[:,-1]\n",
        "                  ]\n",
        "pred = es.predict(start = 0 , end = data.shape[0]+Predict_For )\n",
        "pred = np.nan_to_num(pred, copy=True, nan=0.0, posinf=None, neginf=None)\n",
        "\n",
        "print('Accuracy Scores For Training Data :\\n  -> Mean Squared Error : {} ({})\\n  -> Root Mean Squared Error : {} ({})\\n  -> Standard Deviation : {} ({})\\n  -> Mean Absolute Error : {} ({})\\n'\\\n",
        "      .format(\\\n",
        "              eval.mse(pred[0:train_split.shape[0]], train_split),\\\n",
        "              eval.mse(pred[0:train_split.shape[0]], train_split)/len(train_split), \\\n",
        "              eval.rmse(pred[0:train_split.shape[0]], train_split) , \\\n",
        "              eval.rmse(pred[0:train_split.shape[0]], train_split)/len(train_split) , \\\n",
        "              eval.stde(pred[0:train_split.shape[0]], train_split), \\\n",
        "              eval.stde(pred[0:train_split.shape[0]], train_split)/len(train_split), \\\n",
        "              eval.meanabs(pred[0:train_split.shape[0]], train_split),\\\n",
        "              eval.meanabs(pred[0:train_split.shape[0]], train_split)/len(train_split)\\\n",
        "              )\\\n",
        "      )\n",
        "print('Accuracy Scores For Testing Data :\\n  -> Mean Squared Error : {} ({})\\n  -> Root Mean Squared Error : {} ({})\\n  -> Standard Deviation : {} ({})\\n  -> Mean Absolute Error : {} ({})\\n'\\\n",
        "      .format(\\\n",
        "              eval.mse(pred[-valid_split.shape[0]:], valid_split) ,\\\n",
        "              eval.mse(pred[-valid_split.shape[0]:], valid_split)/len(valid_split) ,\\\n",
        "              eval.rmse(pred[-valid_split.shape[0]:], valid_split) , \\\n",
        "              eval.rmse(pred[-valid_split.shape[0]:], valid_split)/len(valid_split) , \\\n",
        "              eval.stde(pred[-valid_split.shape[0]:], valid_split) , \\\n",
        "              eval.stde(pred[-valid_split.shape[0]:], valid_split)/len(valid_split) , \\\n",
        "              eval.meanabs(pred[-valid_split.shape[0]:], valid_split),\\\n",
        "              eval.meanabs(pred[-valid_split.shape[0]:], valid_split)/len(valid_split)\\\n",
        "              )\\\n",
        "      )\n",
        "if Plot_Lib == 'MatplotLib':\n",
        "  plot_color = list(sns.color_palette(Style_Color,n_colors=len(Plot_Data)+1).as_hex())\n",
        "  plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  plt.fill_between(Simulation_Data[0],Simulation_Data[1], Simulation_Data[2], color = plot_color[0] , alpha = 0.1 , label = 'Simulations' )\n",
        "\n",
        "  for j,i in enumerate(Plot_Data):\n",
        "    plt.plot(i[0], i[1],i[3],label = i[2] , color = plot_color[j+1]  )\n",
        "  plt.suptitle(Sup_Title, fontsize = 29)\n",
        "  plt.title('{} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title()  ) , fontsize = 19)\n",
        "  plt.legend()\n",
        "  plt.ylabel('Cases')\n",
        "  plt.xlabel('Days Passed Since {}'.format(Completed_.Date.min()))\n",
        "  plt.subplots_adjust(top=SubPlot_Top)\n",
        "  plt.plot()\n",
        "\n",
        "else:\n",
        "  fig=go.Figure()\n",
        "  for i in Plot_Data:\n",
        "    fig.add_trace(go.Scatter(x = i[0], y = i[1], mode = 'lines+markers', name = i[2]))\n",
        "\n",
        "  fig.update_layout(title='{} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title()),\n",
        "                  xaxis_title='Days Passed Since {}'.format(Completed_.Date.min()),yaxis_title=\"Cases\",legend=dict(x=0,y=1,traceorder=\"normal\"))\n",
        "  fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noEfl3qMP1EQ"
      },
      "source": [
        "## Holt's Exponential Smoothing Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiRWYj3juOen"
      },
      "source": [
        "Holt linear attempts to capture the high-level trends in the time series data and fits the data with a straight line. The method can be summarized as follows:\n",
        "Forecast, level, and trend equations respectively.<br>\n",
        "<center>\n",
        "<img src = 'https://i.imgur.com/MHgcgGo.png' height = 38px></img><br>\n",
        "<img src = 'https://i.imgur.com/3ImRHEO.png' height = 38px></img><br>\n",
        "<img src = 'https://i.imgur.com/XExnvMX.png' height = 38px></img>\n",
        "<br>\n",
        "</center>\n",
        "In the above equations, α and β are constants which can be configured. The values lt and bt represent the level and trend values repsectively. The trend value is the slope of the linear forecast function and the level value is the y-intercept of the linear forecast function. The slope and y-intercept values are continuously updated using the second and third update equations. Finally, the slope and y-intercept are used to calculate the forecast y<sub>t+h</sub> (in equation 1), which is h time steps ahead of the current time step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "KJQiwrwYP4Co"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='https://cdn3.iconfinder.com/data/icons/pictograms-vol-2-3/400/linear_diagram-256.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2><br>Holt's Exponential Smoothing for Forecasting</h2></center><br>\n",
        "\n",
        "Plot_Column = \"Confirmed\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_']\n",
        "Location = \"India\" #@param ['Kerala', 'Delhi', 'Telangana', 'India', 'Rajasthan', 'Haryana','UP', 'Ladakh', 'TN', 'J&K', 'Karnataka', 'Maharashtra', 'Punjab','Andra P', 'HP', 'Uttarakhand', 'Odisha', 'Puducherry','West Bengal', 'Chandigarh', 'Chhattisgarh', 'Gujarat', 'MP','Bihar', 'Manipur', 'Goa', 'Mizoram', 'A&N', 'Assam', 'Jharkhand','Arun P', 'Nagaland', 'Tripura', 'D&D', 'Meghalaya', 'Sikkim','Other']\n",
        "Train_Split = 0.8 #@param {type:\"slider\", min:0.05, max:0.95, step:0.05}\n",
        "Predict_For = 25 #@param {type:\"slider\", min:0, max:100, step:5}\n",
        "No_Of_Simulations = 100 #@param {type:\"slider\", min:10, max:500, step:5}\n",
        "Plot_Forecast = \"Complete Plot ( Train + Test + Forecast )\" #@param [\"Complete Plot ( Train + Test + Forecast )\", \"Test + Forecast Plot\"]\n",
        "Plot_Lib = \"MatplotLib\" #@param [\"Plotly\", \"MatplotLib\"]\n",
        "Plot_Summary = True #@param {type:\"boolean\"}\n",
        "Enable_Exponential_Trend = False #@param {type:\"boolean\"}\n",
        "Enable_Damped_Trend = True #@param {type:\"boolean\"}\n",
        "Enable_Damped_Trend = True #@param {type:\"boolean\"}\n",
        "Apply_Log = True #@param {type:\"boolean\"}\n",
        "Date = 'Date'\n",
        "Model_Name = \"Exponential Smoothing\"\n",
        "data = Completed_[Completed_['State'] == Location]\n",
        "train_for = int(data.shape[0]*Train_Split)\n",
        "train_split = data.iloc[:train_for][Plot_Column].values + 0.00001\n",
        "valid_split = data.iloc[train_for:][Plot_Column].values + 0.00001\n",
        "\n",
        "if Apply_Log:\n",
        "  train_split = np.log1p(train_split)\n",
        "  valid_split = np.log1p(valid_split)\n",
        "\n",
        "\n",
        "train_split = pd.Series(train_split)\n",
        "valid_split = pd.Series(valid_split)\n",
        "\n",
        "es = Holt(train_split,exponential = Enable_Exponential_Trend, damped_trend = Enable_Damped_Trend, initialization_method=\"estimated\").fit()\n",
        "if Plot_Summary:\n",
        "  print(es.summary())\n",
        "\n",
        "\n",
        "if Plot_Forecast == 'Test + Forecast Plot':\n",
        "  pred = es.predict(start = train_for, end = train_for + len(valid_split) + Predict_For)\n",
        "  Plot_Data = [\n",
        "               [list(range(train_for , train_for + len(pred),1)),\n",
        "               pred,'Predicted Forecast',':'\n",
        "               ],\n",
        "               [list(range(train_for , train_for+ len(valid_split))),\n",
        "               valid_split,'{} Covid Cases'.format(Plot_Column),'--'\n",
        "               ]\n",
        "  ]\n",
        "  \n",
        "else:\n",
        "  pred = es.predict(start = 0 , end = data.shape[0]+Predict_For )\n",
        "  Plot_Data = [\n",
        "               [list(range(0 , len(pred))),\n",
        "               pred,'Predicted Curve' ,':'\n",
        "               ],\n",
        "               [list(range(0, len(train_split))),\n",
        "                train_split , 'Actual Train Curve','--'\n",
        "               ],\n",
        "               [list(range(train_for , train_for+len(valid_split))),\n",
        "                valid_split , 'Observed Test Curve','--'\n",
        "               ]\n",
        "  ]\n",
        "simulations = es.simulate(len(valid_split) + Predict_For , repetitions = No_Of_Simulations , error = 'add').values\n",
        "Simulation_Data = [\n",
        "                   list(range(train_for , train_for + len(valid_split) + Predict_For , 1)),\n",
        "                   simulations[:,0],\n",
        "                   simulations[:,-1]\n",
        "                  ]\n",
        "pred = es.predict(start = 0 , end = data.shape[0]+Predict_For )\n",
        "pred = np.nan_to_num(pred, copy=True, nan=0.0, posinf=None, neginf=None)\n",
        "\n",
        "print('Accuracy Scores For Training Data :\\n  -> Mean Squared Error : {} ({})\\n  -> Root Mean Squared Error : {} ({})\\n  -> Standard Deviation : {} ({})\\n  -> Mean Absolute Error : {} ({})\\n'\\\n",
        "      .format(\\\n",
        "              eval.mse(pred[0:train_split.shape[0]], train_split),\\\n",
        "              eval.mse(pred[0:train_split.shape[0]], train_split)/len(train_split), \\\n",
        "              eval.rmse(pred[0:train_split.shape[0]], train_split) , \\\n",
        "              eval.rmse(pred[0:train_split.shape[0]], train_split)/len(train_split) , \\\n",
        "              eval.stde(pred[0:train_split.shape[0]], train_split), \\\n",
        "              eval.stde(pred[0:train_split.shape[0]], train_split)/len(train_split), \\\n",
        "              eval.meanabs(pred[0:train_split.shape[0]], train_split),\\\n",
        "              eval.meanabs(pred[0:train_split.shape[0]], train_split)/len(train_split)\\\n",
        "              )\\\n",
        "      )\n",
        "print('Accuracy Scores For Testing Data :\\n  -> Mean Squared Error : {} ({})\\n  -> Root Mean Squared Error : {} ({})\\n  -> Standard Deviation : {} ({})\\n  -> Mean Absolute Error : {} ({})\\n'\\\n",
        "      .format(\\\n",
        "              eval.mse(pred[-valid_split.shape[0]:], valid_split) ,\\\n",
        "              eval.mse(pred[-valid_split.shape[0]:], valid_split)/len(valid_split) ,\\\n",
        "              eval.rmse(pred[-valid_split.shape[0]:], valid_split) , \\\n",
        "              eval.rmse(pred[-valid_split.shape[0]:], valid_split)/len(valid_split) , \\\n",
        "              eval.stde(pred[-valid_split.shape[0]:], valid_split) , \\\n",
        "              eval.stde(pred[-valid_split.shape[0]:], valid_split)/len(valid_split) , \\\n",
        "              eval.meanabs(pred[-valid_split.shape[0]:], valid_split),\\\n",
        "              eval.meanabs(pred[-valid_split.shape[0]:], valid_split)/len(valid_split)\\\n",
        "              )\\\n",
        "      )\n",
        "if Plot_Lib == 'MatplotLib':\n",
        "  plot_color = list(sns.color_palette(Style_Color,n_colors=len(Plot_Data)+1).as_hex())\n",
        "  plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  plt.fill_between(Simulation_Data[0],Simulation_Data[1], Simulation_Data[2], color = plot_color[0] , alpha = 0.1 , label = 'Simulations' )\n",
        "\n",
        "  for j,i in enumerate(Plot_Data):\n",
        "    plt.plot(i[0], i[1],i[3],label = i[2] , color = plot_color[j+1]  )\n",
        "  plt.suptitle(Sup_Title, fontsize = 29)\n",
        "  plt.title('{} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title()  ) , fontsize = 19)\n",
        "  plt.legend()\n",
        "  plt.ylabel('Cases')\n",
        "  plt.xlabel('Days Passed Since {}'.format(Completed_.Date.min()))\n",
        "  plt.subplots_adjust(top=SubPlot_Top)\n",
        "  plt.plot()\n",
        "  # fig = plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  # fig = es.plot_diagnostics(fig=fig, lags=2)\n",
        "  # plt.plot()\n",
        "else:\n",
        "  fig=go.Figure()\n",
        "  for i in Plot_Data:\n",
        "    fig.add_trace(go.Scatter(x = i[0], y = i[1], mode = 'lines+markers', name = i[2]))\n",
        "\n",
        "  fig.update_layout(title='{} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title()),\n",
        "                  xaxis_title='Days Passed Since {}'.format(Completed_.Date.min()),yaxis_title=\"Cases\",legend=dict(x=0,y=1,traceorder=\"normal\"))\n",
        "  fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sj0mgUGDA2v"
      },
      "source": [
        "## Exponential Smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJfkATZGv4jJ"
      },
      "source": [
        "\n",
        "The exponential smoothing method uses a different type of \"smoothing\" which differs from average smoothing. The previous time steps are exponentially weighted and added up to generate the forecast. The weights decay as we move further backwards in time. The model can be summarized as follows:\n",
        "<br>\n",
        "<center>\n",
        "<img src = 'https://i.imgur.com/IqqjOFc.png' height = 38px></img><br>\n",
        "<img src = 'https://i.imgur.com/GiyHyZf.png' height = 38px></img><br>\n",
        "</center>\n",
        "In the above equations, α is the smoothing parameter. The forecast y<sub>t+1</sub> is a weighted average of all the observations in the series y1, … ,yt. The rate at which the weights decay is controlled by the parameter α. This method gives different weightage to different time steps, instead of giving the same weightage to all time steps (like the moving average method). This ensures that recent sales data is given more importance than old sales data while making the forecast. Now let us see how this new smoothing method performs on our miniature dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "G3rf0NVND9Xw"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='https://cdn0.iconfinder.com/data/icons/charts-graphs-1/24/chart-trend-exponential-up-512.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2><br>Exponential Smoothing for Forecasting</h2></center><br>\n",
        "\n",
        "Plot_Column = \"Confirmed\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_']\n",
        "Location = \"India\" #@param ['Kerala', 'Delhi', 'Telangana', 'India', 'Rajasthan', 'Haryana','UP', 'Ladakh', 'TN', 'J&K', 'Karnataka', 'Maharashtra', 'Punjab','Andra P', 'HP', 'Uttarakhand', 'Odisha', 'Puducherry','West Bengal', 'Chandigarh', 'Chhattisgarh', 'Gujarat', 'MP','Bihar', 'Manipur', 'Goa', 'Mizoram', 'A&N', 'Assam', 'Jharkhand','Arun P', 'Nagaland', 'Tripura', 'D&D', 'Meghalaya', 'Sikkim','Other']\n",
        "Train_Split = 0.8 #@param {type:\"slider\", min:0.05, max:0.95, step:0.05}\n",
        "Predict_For = 70 #@param {type:\"slider\", min:0, max:100, step:5}\n",
        "Season_Period = 7 #@param {type:\"slider\", min:1, max:40, step:1}\n",
        "No_Of_Simulations = 100 #@param {type:\"slider\", min:10, max:500, step:5}\n",
        "Plot_Forecast = \"Complete Plot ( Train + Test + Forecast )\" #@param [\"Complete Plot ( Train + Test + Forecast )\", \"Test + Forecast Plot\"]\n",
        "Plot_Lib = \"MatplotLib\" #@param [\"Plotly\", \"MatplotLib\"]\n",
        "Plot_Summary = True #@param {type:\"boolean\"}\n",
        "Apply_Log = False #@param {type:\"boolean\"}\n",
        "Date = 'Date'\n",
        "Model_Name = \"Exponential Smoothing\"\n",
        "data = Completed_[Completed_['State'] == Location]\n",
        "train_for = int(data.shape[0]*Train_Split)\n",
        "train_split = data.iloc[:train_for][Plot_Column].values + 0.00001\n",
        "valid_split = data.iloc[train_for:][Plot_Column].values + 0.00001\n",
        "if Apply_Log:\n",
        "  train_split = np.log1p(train_split)\n",
        "  valid_split = np.log1p(valid_split)\n",
        "\n",
        "train_split = pd.Series(train_split)\n",
        "valid_split = pd.Series(valid_split)\n",
        "\n",
        "es = ExponentialSmoothing(train_split,seasonal_periods=Season_Period,trend='add',seasonal= 'mul', damped_trend=True, use_boxcox=False, initialization_method=\"estimated\").fit()\n",
        "if Plot_Summary:\n",
        "  print(es.summary())\n",
        "\n",
        "\n",
        "if Plot_Forecast == 'Test + Forecast Plot':\n",
        "  pred = es.predict(start = train_for, end = train_for + len(valid_split) + Predict_For)\n",
        "  Plot_Data = [\n",
        "               [list(range(train_for , train_for + len(pred),1)),\n",
        "               pred,'Predicted Forecast',':'\n",
        "               ],\n",
        "               [list(range(train_for , train_for+ len(valid_split))),\n",
        "               valid_split,'{} Covid Cases'.format(Plot_Column),'--'\n",
        "               ]\n",
        "  ]\n",
        "  \n",
        "else:\n",
        "  pred = es.predict(start = 0 , end = data.shape[0]+Predict_For )\n",
        "  Plot_Data = [\n",
        "               [list(range(0 , len(pred))),\n",
        "               pred,'Predicted Curve' ,':'\n",
        "               ],\n",
        "               [list(range(0, len(train_split))),\n",
        "                train_split , 'Actual Train Curve','--'\n",
        "               ],\n",
        "               [list(range(train_for , train_for+len(valid_split))),\n",
        "                valid_split , 'Observed Test Curve','--'\n",
        "               ]\n",
        "  ]\n",
        "simulations = es.simulate(len(valid_split) + Predict_For , repetitions = No_Of_Simulations , error = 'add').values\n",
        "Simulation_Data = [\n",
        "                   list(range(train_for , train_for + len(valid_split) + Predict_For , 1)),\n",
        "                   simulations[:,0],\n",
        "                   simulations[:,-1]\n",
        "                  ]\n",
        "pred = es.predict(start = 0 , end = data.shape[0]+Predict_For )\n",
        "pred = np.nan_to_num(pred, copy=True, nan=0.0, posinf=None, neginf=None)\n",
        "\n",
        "print('Accuracy Scores For Training Data :\\n  -> Mean Squared Error : {} ({})\\n  -> Root Mean Squared Error : {} ({})\\n  -> Standard Deviation : {} ({})\\n  -> Mean Absolute Error : {} ({})\\n'\\\n",
        "      .format(\\\n",
        "              eval.mse(pred[0:train_split.shape[0]], train_split),\\\n",
        "              eval.mse(pred[0:train_split.shape[0]], train_split)/len(train_split), \\\n",
        "              eval.rmse(pred[0:train_split.shape[0]], train_split) , \\\n",
        "              eval.rmse(pred[0:train_split.shape[0]], train_split)/len(train_split) , \\\n",
        "              eval.stde(pred[0:train_split.shape[0]], train_split), \\\n",
        "              eval.stde(pred[0:train_split.shape[0]], train_split)/len(train_split), \\\n",
        "              eval.meanabs(pred[0:train_split.shape[0]], train_split),\\\n",
        "              eval.meanabs(pred[0:train_split.shape[0]], train_split)/len(train_split)\\\n",
        "              )\\\n",
        "      )\n",
        "print('Accuracy Scores For Testing Data :\\n  -> Mean Squared Error : {} ({})\\n  -> Root Mean Squared Error : {} ({})\\n  -> Standard Deviation : {} ({})\\n  -> Mean Absolute Error : {} ({})\\n'\\\n",
        "      .format(\\\n",
        "              eval.mse(pred[-valid_split.shape[0]:], valid_split) ,\\\n",
        "              eval.mse(pred[-valid_split.shape[0]:], valid_split)/len(valid_split) ,\\\n",
        "              eval.rmse(pred[-valid_split.shape[0]:], valid_split) , \\\n",
        "              eval.rmse(pred[-valid_split.shape[0]:], valid_split)/len(valid_split) , \\\n",
        "              eval.stde(pred[-valid_split.shape[0]:], valid_split) , \\\n",
        "              eval.stde(pred[-valid_split.shape[0]:], valid_split)/len(valid_split) , \\\n",
        "              eval.meanabs(pred[-valid_split.shape[0]:], valid_split),\\\n",
        "              eval.meanabs(pred[-valid_split.shape[0]:], valid_split)/len(valid_split)\\\n",
        "              )\\\n",
        "      )\n",
        "if Plot_Lib == 'MatplotLib':\n",
        "  plot_color = list(sns.color_palette(Style_Color,n_colors=len(Plot_Data)+1).as_hex())\n",
        "  plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  plt.fill_between(Simulation_Data[0],Simulation_Data[1], Simulation_Data[2], color = plot_color[0] , alpha = 0.1 , label = 'Simulations' )\n",
        "\n",
        "  for j,i in enumerate(Plot_Data):\n",
        "    plt.plot(i[0], i[1],i[3],label = i[2] , color = plot_color[j+1]  )\n",
        "  plt.suptitle(Sup_Title, fontsize = 29)\n",
        "  plt.title('{} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title()  ) , fontsize = 19)\n",
        "  plt.legend()\n",
        "  plt.ylabel('Cases')\n",
        "  plt.xlabel('Days Passed Since {}'.format(Completed_.Date.min()))\n",
        "  plt.subplots_adjust(top=SubPlot_Top)\n",
        "  plt.plot()\n",
        "  # fig = plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  # fig = es.plot_diagnostics(fig=fig, lags=2)\n",
        "  # plt.plot()\n",
        "else:\n",
        "  fig=go.Figure()\n",
        "  for i in Plot_Data:\n",
        "    fig.add_trace(go.Scatter(x = i[0], y = i[1], mode = 'lines+markers', name = i[2]))\n",
        "\n",
        "  fig.update_layout(title='{} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title()),\n",
        "                  xaxis_title='Days Passed Since {}'.format(Completed_.Date.min()),yaxis_title=\"Cases\",legend=dict(x=0,y=1,traceorder=\"normal\"))\n",
        "  fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYnU_8NguQ_T"
      },
      "source": [
        "## Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors model (SARIMAX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTdLLxINilKr"
      },
      "source": [
        "### Searching for Optimal ARIMA Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Q_KwqxfXlngH"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='https://cdn3.iconfinder.com/data/icons/education-and-school-8/48/Search-512.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2><br>Searching For Optimal SARIMAX Perimeters</h2></center><br>\n",
        "\n",
        "Plot_Column = \"Confirmed\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_']\n",
        "Location = \"India\" #@param ['Kerala', 'Delhi', 'Telangana', 'India', 'Rajasthan', 'Haryana','UP', 'Ladakh', 'TN', 'J&K', 'Karnataka', 'Maharashtra', 'Punjab','Andra P', 'HP', 'Uttarakhand', 'Odisha', 'Puducherry','West Bengal', 'Chandigarh', 'Chhattisgarh', 'Gujarat', 'MP','Bihar', 'Manipur', 'Goa', 'Mizoram', 'A&N', 'Assam', 'Jharkhand','Arun P', 'Nagaland', 'Tripura', 'D&D', 'Meghalaya', 'Sikkim','Other']\n",
        "\n",
        "data = Completed_[Completed_['State'] == Location]\n",
        "train_split = data[Plot_Column].values\n",
        "train_split = pd.Series(train_split)\n",
        "\n",
        "auto_Arima = AutoARIMA(start_p=1 , d=None, start_q=1 ,max_p=9, max_d=9, max_q=9, max_P=9, max_D=9, max_Q=9,trend = 'ct', stepwise=True, n_jobs=-1 , n_fits=50 ,trace = True)\n",
        "auto_Arima.fit(train_split)\n",
        "print(auto_Arima.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYdqA8kV21W-"
      },
      "source": [
        "### Implementing SARIMAX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcWJ7E10uUv_",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='https://static.tildacdn.com/tild3234-6238-4138-b261-393230376565/analytics_4.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2><br>SARIMAX Fitting for Forecasting</h2></center><br>\n",
        "\n",
        "Plot_Column = \"Confirmed\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_']\n",
        "Location = \"India\" #@param ['Kerala', 'Delhi', 'Telangana', 'India', 'Rajasthan', 'Haryana','UP', 'Ladakh', 'TN', 'J&K', 'Karnataka', 'Maharashtra', 'Punjab','Andra P', 'HP', 'Uttarakhand', 'Odisha', 'Puducherry','West Bengal', 'Chandigarh', 'Chhattisgarh', 'Gujarat', 'MP','Bihar', 'Manipur', 'Goa', 'Mizoram', 'A&N', 'Assam', 'Jharkhand','Arun P', 'Nagaland', 'Tripura', 'D&D', 'Meghalaya', 'Sikkim','Other']\n",
        "Train_Split = 0.9 #@param {type:\"slider\", min:0.05, max:0.95, step:0.05}\n",
        "Predict_For = 70 #@param {type:\"slider\", min:0, max:100, step:5}\n",
        "Plot_Forecast = \"Complete Plot ( Train + Test + Forecast )\" #@param [\"Complete Plot ( Train + Test + Forecast )\", \"Test + Forecast Plot\"]\n",
        "Plot_Lib = \"Plotly\" #@param [\"Plotly\", \"MatplotLib\"]\n",
        "Plot_Summary = True #@param {type:\"boolean\"}\n",
        "Date = 'Date'\n",
        "Model_Name = \"Exponential Smoothing\"\n",
        "data = Completed_[Completed_['State'] == Location]\n",
        "train_for = int(data.shape[0]*Train_Split)\n",
        "train_split = data.iloc[:train_for][Plot_Column].values + 0.00001\n",
        "valid_split = data.iloc[train_for:][Plot_Column].values + 0.00001\n",
        "\n",
        "train_split = pd.Series(train_split)\n",
        "valid_split = pd.Series(valid_split)\n",
        "\n",
        "# es = SARIMAX(train_split , order = (7,3,0),enforce_invertibility = True ,time_varying_regression =False).fit()\n",
        "es = SARIMAX(train_split , order = (8,3,1),enforce_invertibility = True ,time_varying_regression =False).fit()\n",
        "if Plot_Summary:\n",
        "  print(es.summary())\n",
        "\n",
        "\n",
        "if Plot_Forecast == 'Test + Forecast Plot':\n",
        "  pred = es.predict(start = train_for, end = train_for + len(valid_split) + Predict_For)\n",
        "  Plot_Data = [\n",
        "               [list(range(train_for , train_for + len(pred),1)),\n",
        "               pred,'Predicted Forecast',':'\n",
        "               ],\n",
        "               [list(range(train_for , train_for+ len(valid_split))),\n",
        "               valid_split,'{} Covid Cases'.format(Plot_Column),'--'\n",
        "               ]\n",
        "  ]\n",
        "  \n",
        "else:\n",
        "  pred = es.predict(start = 0 , end = data.shape[0]+Predict_For )\n",
        "  Plot_Data = [\n",
        "               [list(range(0 , len(pred))),\n",
        "               pred,'Predicted Curve' ,':'\n",
        "               ],\n",
        "               [list(range(0, len(train_split))),\n",
        "                train_split , 'Actual Train Curve','--'\n",
        "               ],\n",
        "               [list(range(train_for , train_for+len(valid_split))),\n",
        "                valid_split , 'Observed Test Curve','--'\n",
        "               ]\n",
        "  ]\n",
        "\n",
        "pred = es.predict(start = 0 , end = data.shape[0]+Predict_For )\n",
        "pred = np.nan_to_num(pred, copy=True, nan=0.0, posinf=None, neginf=None)\n",
        "\n",
        "print('Accuracy Scores For Training Data :\\n  -> Mean Squared Error : {} ({})\\n  -> Root Mean Squared Error : {} ({})\\n  -> Standard Deviation : {} ({})\\n  -> Mean Absolute Error : {} ({})\\n'\\\n",
        "      .format(\\\n",
        "              eval.mse(pred[0:train_split.shape[0]], train_split),\\\n",
        "              eval.mse(pred[0:train_split.shape[0]], train_split)/len(train_split), \\\n",
        "              eval.rmse(pred[0:train_split.shape[0]], train_split) , \\\n",
        "              eval.rmse(pred[0:train_split.shape[0]], train_split)/len(train_split) , \\\n",
        "              eval.stde(pred[0:train_split.shape[0]], train_split), \\\n",
        "              eval.stde(pred[0:train_split.shape[0]], train_split)/len(train_split), \\\n",
        "              eval.meanabs(pred[0:train_split.shape[0]], train_split),\\\n",
        "              eval.meanabs(pred[0:train_split.shape[0]], train_split)/len(train_split)\\\n",
        "              )\\\n",
        "      )\n",
        "print('Accuracy Scores For Testing Data :\\n  -> Mean Squared Error : {} ({})\\n  -> Root Mean Squared Error : {} ({})\\n  -> Standard Deviation : {} ({})\\n  -> Mean Absolute Error : {} ({})\\n'\\\n",
        "      .format(\\\n",
        "              eval.mse(pred[-valid_split.shape[0]:], valid_split) ,\\\n",
        "              eval.mse(pred[-valid_split.shape[0]:], valid_split)/len(valid_split) ,\\\n",
        "              eval.rmse(pred[-valid_split.shape[0]:], valid_split) , \\\n",
        "              eval.rmse(pred[-valid_split.shape[0]:], valid_split)/len(valid_split) , \\\n",
        "              eval.stde(pred[-valid_split.shape[0]:], valid_split) , \\\n",
        "              eval.stde(pred[-valid_split.shape[0]:], valid_split)/len(valid_split) , \\\n",
        "              eval.meanabs(pred[-valid_split.shape[0]:], valid_split),\\\n",
        "              eval.meanabs(pred[-valid_split.shape[0]:], valid_split)/len(valid_split)\\\n",
        "              )\\\n",
        "      )\n",
        "if Plot_Lib == 'MatplotLib':\n",
        "  plot_color = list(sns.color_palette(Style_Color,n_colors=len(Plot_Data)+1).as_hex())\n",
        "  plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  # plt.fill_between(Simulation_Data[0],Simulation_Data[1], Simulation_Data[2], color = plot_color[0] , alpha = 0.1 , label = 'Simulations' )\n",
        "\n",
        "  for j,i in enumerate(Plot_Data):\n",
        "    plt.plot(i[0], i[1],i[3],label = i[2] , color = plot_color[j+1]  )\n",
        "  plt.suptitle(Sup_Title, fontsize = 29)\n",
        "  plt.title('{} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title()  ) , fontsize = 19)\n",
        "  plt.legend()\n",
        "  plt.ylabel('Cases')\n",
        "  plt.xlabel('Days Passed Since {}'.format(Completed_.Date.min()))\n",
        "  plt.subplots_adjust(top=SubPlot_Top)\n",
        "  plt.plot()\n",
        "  # fig = plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  # fig = es.plot_diagnostics(fig=fig, lags=2)\n",
        "  # plt.plot()\n",
        "else:\n",
        "  fig=go.Figure()\n",
        "  for i in Plot_Data:\n",
        "    fig.add_trace(go.Scatter(x = i[0], y = i[1], mode = 'lines+markers', name = i[2]))\n",
        "\n",
        "  fig.update_layout(title='{} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title()),\n",
        "                  xaxis_title='Days Passed Since {}'.format(Completed_.Date.min()),yaxis_title=\"Cases\",legend=dict(x=0,y=1,traceorder=\"normal\"))\n",
        "  fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKdw7gLjccAr"
      },
      "source": [
        "## Theta Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdtoRm-Jchwe"
      },
      "source": [
        "The  [Theta model of Assimakopoulos & Nikolopoulos (2000)](https://www.statsmodels.org/dev/examples/notebooks/generated/theta-model.html) is a simple method for forecasting the involves fitting two θ-lines, forecasting the lines using a Simple Exponential Smoother, and then combining the forecasts from the two lines to produce the final forecast. The model is implemented in steps:\n",
        "\n",
        "\n",
        "1.   Test for seasonality\n",
        "2.   Deseasonalize if seasonality detected\n",
        "3.   Estimate α by fitting a SES model to the data and b0 by OLS.\n",
        "4.   Forecast the series\n",
        "5.   Reseasonalize if the data was deseasonalized.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "VlmyYdVIfass"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START Fitting</h3>\n",
        "#@markdown <br><center><img src='https://cdn1.iconfinder.com/data/icons/gestureworks_gesture_glyphs/256/stroke_greek_theta_gestureworks.png' height=\"200\" alt=\"Gdrive-logo\"/></center>\n",
        "#@markdown <center><h2><br>Theta Model Fitting for Forecasting</h2></center><br>\n",
        "\n",
        "Plot_Column = \"Confirmed\" #@param ['Confirmed', 'Recovered', 'Deceased', 'Other', 'Tested', 'Active', 'Confirmed_', 'Recovered_', 'Deceased_', 'Other_','Tested_', 'Active_']\n",
        "Location = \"India\" #@param ['Kerala', 'Delhi', 'Telangana', 'India', 'Rajasthan', 'Haryana','UP', 'Ladakh', 'TN', 'J&K', 'Karnataka', 'Maharashtra', 'Punjab','Andra P', 'HP', 'Uttarakhand', 'Odisha', 'Puducherry','West Bengal', 'Chandigarh', 'Chhattisgarh', 'Gujarat', 'MP','Bihar', 'Manipur', 'Goa', 'Mizoram', 'A&N', 'Assam', 'Jharkhand','Arun P', 'Nagaland', 'Tripura', 'D&D', 'Meghalaya', 'Sikkim','Other']\n",
        "\n",
        "Predict_For = 59 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "Intervals = 54 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "Model_Behaviour = \"add\" #@param [\"add\", \"mul\"]\n",
        "Plot_Lib = \"MatplotLib\" #@param [ \"MatplotLib\"]\n",
        "Date = 'Date'\n",
        "\n",
        "Model_Name = \"Exponential Smoothing\"\n",
        "data = Completed_[Completed_['State'] == Location]\n",
        "\n",
        "times = pd.date_range(data[Date].min(), periods = data.shape[0]+Predict_For , freq='D')\n",
        "\n",
        "data.index = pd.to_datetime(data[Date])\n",
        "train_split = data[Plot_Column]\n",
        "\n",
        "i = Intervals\n",
        "result = []\n",
        "\n",
        "while i < train_split.shape[0]:\n",
        "  data = train_split[:i]\n",
        "  tm = ThetaModel(data , method = Model_Behaviour).fit()\n",
        "  result.append(pd.Series(tm.forecast(Predict_For).values , index = times[i:i+Predict_For]))\n",
        "  i+=Intervals\n",
        "\n",
        "print(tm.summary())\n",
        "if Plot_Lib == 'MatplotLib':\n",
        "  plot_color = list(sns.color_palette(Style_Color,n_colors=len(result)+1).as_hex())\n",
        "  plt.figure(figsize=(Graphs_Width,Graphs_Height))\n",
        "  plt.plot(train_split , ':' , label = 'Original Data' , color = plot_color[0])\n",
        "\n",
        "  for j,i in enumerate(result):\n",
        "    plt.plot(i,color = plot_color[j+1]  )\n",
        "  plt.suptitle(Sup_Title, fontsize = 29)\n",
        "  plt.title('{} Cases of  SARS-CoV-2 \\n'.format(Plot_Column.replace('_',' (Daily)').title()  ) , fontsize = 19)\n",
        "  plt.legend()\n",
        "  plt.ylabel('Cases')\n",
        "  plt.xlabel('Days Passed Since {}'.format(Completed_.Date.min()))\n",
        "  plt.subplots_adjust(top=SubPlot_Top)\n",
        "  plt.plot()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL-re7LB4gSl"
      },
      "source": [
        "# RNN (LSTM)\n",
        "\n",
        "I tried alot to make LSTM Work....\n",
        "But LSTM Doesn't Work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RjoqwHK4oRN"
      },
      "source": [
        "series_len = 14\n",
        "def Preprocess_RNN(data = World_ , Col_ = 'iso_code' , use_col = 'total_cases' , series_len = 14 , first_min = 100 ,  Apply_Scaler = False , Use_Log = True ):\n",
        "  flag = []\n",
        "  for iso in data[Col_].unique():\n",
        "    temp = data[data[Col_]== iso]\n",
        "    date_temp = temp.index\n",
        "    temp[use_col] = temp[use_col].clip(0)\n",
        "    temp = temp[use_col].values\n",
        "    if Use_Log:\n",
        "      temp = np.log1p(temp)\n",
        "    if Apply_Scaler:\n",
        "      scaler = MinMaxScaler()\n",
        "      temp = scaler.fit_transform(temp)\n",
        "    for i in range(len(temp) - series_len):\n",
        "      if temp[i]>0:\n",
        "        flag.append([ date_temp[i], temp[i:i+series_len] , temp[i+series_len] , iso])\n",
        "  t_data =  pd.DataFrame([i[1] for i in flag] , columns = ['X_{}'.format(i) for i in range(1,series_len+1)])\n",
        "  t_data['Y'] = [i[2] for i in flag]\n",
        "  t_data.index = [i[0] for i in flag]\n",
        "  t_data['iso_code'] = [i[3] for i in flag]\n",
        "  return t_data\n",
        "\n",
        "train_Data = Preprocess_RNN()\n",
        "Additional_Data = World_[['iso_code','population', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand','life_expectancy', 'human_development_index', 'Latitude (average)', 'Longitude (average)']].drop_duplicates(['iso_code'])\n",
        "Additional_Data.fillna(0 , inplace = True)\n",
        "train_Data = train_Data.merge(Additional_Data , on = ['iso_code'])\n",
        "\n",
        "train_Data = train_Data.sample(frac = 1)\n",
        "Additional_columns = ['population', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand','life_expectancy', 'human_development_index', 'Latitude (average)', 'Longitude (average)']\n",
        "train_Add = train_Data[Additional_columns]\n",
        "Use_Log = True\n",
        "if Use_Log:\n",
        "  for i in ['population', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand','life_expectancy', 'human_development_index']:\n",
        "    train_Add[i] = np.log1p(train_Add[i])\n",
        "train_Add = train_Add.values\n",
        "train_X = train_Data[['X_{}'.format(i) for i in range(1,series_len+1)]].values\n",
        "train_Y = train_Data['Y'].values\n",
        "\n",
        "train_X = np.reshape(train_X , (train_X.shape[0] , train_X.shape[1], 1))\n",
        "train_Y = train_Y.reshape(train_Y.shape[0],1)\n",
        "\n",
        "features_len =len(Additional_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmNd3_BPili7"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(1000, activation = 'relu', input_shape = (series_len , 1) , return_sequences=True))\n",
        "model.add(Dropout(.2))\n",
        "model.add(LSTM(750, activation = 'relu' , return_sequences=True))\n",
        "model.add(Dropout(.2))\n",
        "model.add(LSTM(750, activation = 'relu' , return_sequences=True))\n",
        "model.add(Dropout(.2))\n",
        "model.add(LSTM(750, activation = 'relu' , return_sequences=True))\n",
        "model.add(Dropout(.2))\n",
        "model.add(Dense(75 , activation = 'relu'))\n",
        "model.add(Dropout(.2))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer = 'adam' , loss = 'mse')\n",
        "early_stopping = EarlyStopping(monitor = 'loss' , patience = 20 , restore_best_weights = True)\n",
        "clear_output()\n",
        "print(model.summary())\n",
        "model.fit(train_X , train_Y , batch_size = 128 , epochs = 100 , verbose = 1 , callbacks = [early_stopping] , steps_per_epoch=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rjFM7THYMut"
      },
      "source": [
        "# cases_IN = Input(input_shape = (series_len , 1) , name = 'LSTM_Input')\n",
        "cases_IN = Input(shape = (series_len , 1) , name = 'LSTM_Input')\n",
        "cases = Bidirectional(LSTM(300 , activation='relu' , return_sequences = True , name = 'Bidirectional_LSTM_1'))(cases_IN)\n",
        "cases = Dropout(0.2)(cases)\n",
        "cases = Bidirectional(LSTM(300 , activation='relu' , return_sequences = True , name = 'Bidirectional_LSTM_2'))(cases)\n",
        "cases = Dropout(0.2)(cases)\n",
        "cases = Bidirectional(LSTM(300 , activation='relu' , return_sequences = True , name = 'Bidirectional_LSTM_3'))(cases)\n",
        "cases = Dropout(0.2)(cases)\n",
        "cases = Bidirectional(LSTM(300 , activation='relu' , name = 'Bidirectional_LSTM_4'))(cases)\n",
        "cases = Dropout(0.2)(cases)\n",
        "cases = Dense(300 , activation = 'relu' , name = 'Dense_Layer_1')(cases)\n",
        "cases = Dense(75 , activation = 'relu' , name = 'Dense_Layer_2')(cases)\n",
        "cases_OUT = Dense(1 , name = 'Dense_Layer_Output')(cases)\n",
        "\n",
        "model = Model(inputs = cases_IN, outputs = cases_OUT)\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.summary()\n",
        "callbacks = [ ReduceLROnPlateau(monitor='loss', patience=10 , verbose= 1),EarlyStopping(monitor='loss', min_delta=1e-4, patience=20, verbose= 1)]\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pumg4AosUYMK"
      },
      "source": [
        "cases_IN = Input(shape = (series_len , 1) , name = 'LSTM_Input')\n",
        "cases = Bidirectional(LSTM(300 , activation='relu' , return_sequences = True , name = 'Bidirectional_LSTM_1'))(cases_IN)\n",
        "cases = Dropout(0.2)(cases)\n",
        "cases = Bidirectional(LSTM(300 , activation='relu' , return_sequences = True , name = 'Bidirectional_LSTM_2'))(cases)\n",
        "cases = Dropout(0.2)(cases)\n",
        "cases = Bidirectional(LSTM(300 , activation='relu' , return_sequences = True , name = 'Bidirectional_LSTM_3'))(cases)\n",
        "cases = Dropout(0.2)(cases)\n",
        "cases = Bidirectional(LSTM(300 , activation='relu' , name = 'Bidirectional_LSTM_4'))(cases)\n",
        "cases = Dropout(0.2)(cases)\n",
        "cases = Dense(300 , activation = 'relu' , name = 'Dense_Layer_1')(cases)\n",
        "\n",
        "features_IN = Input(shape = (features_len, ) , name = 'Feature_Space_Input')\n",
        "features = Dense(300 , activation = 'relu' , name = 'Features_Dense_Layer')(features_IN)\n",
        "\n",
        "cases = Concatenate()([cases , add([cases , features]) , features])\n",
        "cases = Dense(256 , activation = 'relu' , name = 'Dense_Layer_2')(cases)\n",
        "cases = Dense(75 , activation = 'relu' , name = 'Dense_Layer_3')(cases)\n",
        "cases_OUT = Dense(1 , name = 'Dense_Layer_Output')(cases)\n",
        "\n",
        "model = Model(inputs = [cases_IN , features_IN], outputs = cases_OUT)\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.summary()\n",
        "callbacks = [ ReduceLROnPlateau(monitor='loss', patience=10 , verbose= 1),EarlyStopping(monitor='loss', min_delta=1e-4, patience=20, verbose= 1)]\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9t2HKECNxe6"
      },
      "source": [
        "model.fit([train_X , train_Add] , train_Y , batch_size = 128 , epochs = 100 , verbose = 1 , callbacks = callbacks, steps_per_epoch=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRK0Zu9oZLsP"
      },
      "source": [
        "scores = model.evaluate([train_X , train_Add] , train_Y , verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hdm38GCcCNJ"
      },
      "source": [
        "train_iso = train_Data[train_Data['iso_code'] == 'IND']\n",
        "train_iso_Add = train_iso[Additional_columns]\n",
        "Use_Log = True\n",
        "if Use_Log:\n",
        "  for i in ['population', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand','life_expectancy', 'human_development_index']:\n",
        "    train_iso_Add[i] = np.log1p(train_iso_Add[i])\n",
        "train_iso_Add = train_iso_Add.values\n",
        "\n",
        "train_iso_X = train_iso[['X_{}'.format(i) for i in range(1,series_len+1)]].values\n",
        "train_iso_Y = train_iso['Y'].values\n",
        "\n",
        "train_iso_X = np.reshape(train_iso_X , (train_iso_X.shape[0] , train_iso_X.shape[1], 1))\n",
        "train_iso_Y = train_iso_Y.reshape(train_iso_Y.shape[0],1)\n",
        "\n",
        "features_len =len(Additional_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZKJIbeWembO"
      },
      "source": [
        "model.fit([train_iso_X , train_iso_Add] , train_iso_Y , batch_size = 128 , epochs = 500 , verbose = 1 , steps_per_epoch=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9pOSTnBiNOe"
      },
      "source": [
        "def create_test_data(data = World_  , Add_D = Additional_Data, iso_code  = 'IND' , series_len = series_len , use_col = 'total_cases', Use_Log = True):\n",
        "  data = World_[World_['iso_code'] == iso_code].tail(series_len)\n",
        "  data = data[use_col].values\n",
        "  A_D = Add_D[Add_D['iso_code'] == iso_code]\n",
        "  Additional_columns = ['population', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand','life_expectancy', 'human_development_index', 'Latitude (average)', 'Longitude (average)']\n",
        "  A_D = A_D[Additional_columns]\n",
        "\n",
        "  if Use_Log:\n",
        "    data = np.log1p(data)\n",
        "    for i in ['population', 'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand','life_expectancy', 'human_development_index']:\n",
        "      A_D[i] = np.log1p(A_D[i])\n",
        "\n",
        "  return data , A_D.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0MNvDY4yJ1Y"
      },
      "source": [
        "train_iso_Add"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E91En6G458BL"
      },
      "source": [
        "def ceate_prediction(predict_for = 100):\n",
        "  test_X , test_Add = create_test_data()\n",
        "  for i in range(predict_for):\n",
        "    pred = model.predict([test_X.reshape(1,-1,1) , test_Add])[0]\n",
        "    test_X = np.append(test_X , pred)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmlUjvqO8lVo"
      },
      "source": [
        "test_Add"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkvbqhyQ-R85"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmqpyHhwlrDV"
      },
      "source": [
        "model.predict([test_X.reshape(1,-1,1) , test_Add])[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_bTttCkbNO0"
      },
      "source": [
        "model.predict([train_iso_X , train_iso_Add])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS-ElAzCLo4S"
      },
      "source": [
        "  series_Len = 21\n",
        "First_Min = 100\n",
        "flag = []\n",
        "for i in range(start_index , len(temp) - series_Len , ):\n",
        "  if temp[i]>100:\n",
        "    flag.append([date_index[i],temp[i:i+series_Len] , temp[i+series_Len]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwYeYpzHORPP"
      },
      "source": [
        "train_data = pd.DataFrame([i[1] for i in flag] , columns = ['X_{}'.format(i) for i in range(1,series_Len+1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJjsu5OGb0VD"
      },
      "source": [
        "train_data['Y'] =[i[2] for i in flag]\n",
        "# train_data['date'] =[i[0] for i in flag]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcX-zSaKZRq8"
      },
      "source": [
        "model.save(\"model.h5\")\n",
        "model = load_model('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ_Wg2lVkb1b"
      },
      "source": [
        "# Unused Codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD6N_ElbitzI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqtHcOfBh0NV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e80IF3NdOJ1"
      },
      "source": [
        "!pip install pgeocode\n",
        "nomi = pgeocode.Nominatim('in')\n",
        "wget.download('https://raw.githubusercontent.com/symerio/postal-codes-data/master/data/geonames/IN.txt')\n",
        "centroids = pd.read_csv('https://raw.githubusercontent.com/reachsumit/population-density-India/master/csv%20outputs/centroids.csv')\n",
        "Lat_Lon = pd.read_csv('/content/IN.txt', sep='\\t',names = ['country_code','postal_code','place_name','state_name','state_code','county_name','county_code','community_name','community_code','latitude','longitude','accuracy'])\n",
        "def clear_common_name(text):\n",
        "  text = re.sub(r\"Panchmahala\",r\"Panchmahal\",text)\n",
        "  text = re.sub(r\"Raigadh\",r\"Raigad\",text)\n",
        "  text = re.sub(r\"Bhel Ranipet\",r\"Ranipet\",text)\n",
        "  return text\n",
        "\n",
        "def clear_districts(text):\n",
        "  text = re.sub(r\"Allahabad\", \"Prayagraj\", text)\n",
        "  text = re.sub(r\"Gurgaon\", \"Gurugram\", text)\n",
        "  text = re.sub(r\"Kachchh\", \"Kutch\", text)\n",
        "  text = re.sub(r\"Bangalore\", \"Bengaluru\", text)\n",
        "  text = re.sub(r\"West Siang\",r\"Siang\",text)\n",
        "  # text = re.sub(r\"East Siang\",r\"Siang\",text)\n",
        "  # text = re.sub(r\"Upper Siang\",r\"Siang\",text)\n",
        "  text = re.sub(r\"Nawan Shehar\", \"Shahid Bhagat Singh Nagar\", text)\n",
        "  return text\n",
        "\n",
        "\n",
        "def clear_ll_state(text):\n",
        "  text = re.sub(r\"Andaman & Nicobar Islands\", \"Andaman and Nicobar\", text)\n",
        "  text = re.sub(r\"Chandigarh\", \"Chhattisgarh\", text)\n",
        "  text = re.sub(r\"Jammu & Kashmir\", \"Jammu and Kashmir\", text)\n",
        "  text = re.sub(r\"Pondicherry\", \"Puducherry\", text)\n",
        "  return text\n",
        "\n",
        "def clear_state(text):\n",
        "  text = re.sub(r\"Uttaranchal\", \"Uttarakhand\", text)\n",
        "  text = re.sub(r\"Orissa\", \"Odisha\", text)\n",
        "  # text = re.sub(r\"Jammu and Kashmir\", \"Ladakh\", text)\n",
        "  text = re.sub(r\"Daman and Diu|Dadra and Nagar Haveli\", \"Dadra and Nagar Haveli and Daman and Diu\", text)\n",
        "  # text = re.sub(r\"Dadra and Nagar Haveli\", \"Dadra and Nagar Haveli and Daman and Diu\", text)\n",
        "  return text\n",
        "\n",
        "def clear_county_name(text):\n",
        "  text = re.sub(r\"Kaimur (Bhabua)\",r\"Kaimur\",text)\n",
        "  text = re.sub(r\"West Siang\",r\"Siang\",text)\n",
        "  text = re.sub(r\"East Siang\",r\"Siang\",text)\n",
        "  text = re.sub(r\"Upper Siang\",r\"Siang\",text)\n",
        "  return text\n",
        "\n",
        "centroids['District'] = centroids['District'].apply(lambda x : clear_districts(x))\n",
        "centroids['State'] = centroids['State'].apply(lambda x : clear_state(x))\n",
        "Lat_Lon['place_name'] = Lat_Lon['place_name'].apply(lambda x : clear_common_name(x))\n",
        "Lat_Lon['county_name'] = Lat_Lon['county_name'].apply(lambda x : clear_county_name(x))\n",
        "Lat_Lon['state_name'] = Lat_Lon['state_name'].apply(lambda x : clear_ll_state(x))\n",
        "sample = District_.merge(centroids , on =['District','State'] , how = 'left')\n",
        "\n",
        "c_ct = []\n",
        "for i in sample[sample.isnull().any(axis=1)][['State' , 'District']].drop_duplicates(keep='first').values:\n",
        "  st = i[0]\n",
        "  sd = i[1]\n",
        "  temp = Lat_Lon[Lat_Lon['state_name']== st]\n",
        "  if temp[temp['county_name'] == sd].shape[0]!=0:\n",
        "    c_c = temp[temp['county_name'] == sd][['latitude','longitude']].median().values\n",
        "    c_ct.append([sd,c_c[0],c_c[1] , st])\n",
        "  elif temp[temp['community_name'] == sd].shape[0]!=0:\n",
        "    c_c = temp[temp['community_name'] == sd][['latitude','longitude']].median().values\n",
        "    c_ct.append([sd,c_c[0],c_c[1] , st])\n",
        "  elif temp[temp['place_name'] == sd].shape[0]!=0:\n",
        "    c_c = temp[temp['place_name'] == sd][['latitude','longitude']].median().values\n",
        "    c_ct.append([sd,c_c[0],c_c[1] , st])\n",
        "  else:\n",
        "    pass\n",
        "centroids = pd.concat([centroids[['District','State','Latitude','Longitude']] , pd.DataFrame(c_ct,columns=['District','Latitude','Longitude','State'])], axis = 0)\n",
        "sample = District_.merge(centroids , on =['District','State'] , how = 'left')\n",
        "# Unable to find centroids of these Districts\n",
        "print(sample[sample['Latitude'].isnull()]['District'].unique())\n",
        "centroids.to_csv('centroids.csv' , index= False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFMxGfl_i0hC"
      },
      "source": [
        "# Accidently Closed Colab Without saving it.\n",
        "import inspect\n",
        "print(inspect.getsource(clear_common_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKvEbyg13Iwb"
      },
      "source": [
        "# Global cases\n",
        "global_confirm_csv = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
        "global_death_csv = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
        "global_recover_csv = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
        "# US cases\n",
        "us_confirm_csv = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'\n",
        "us_death_csv = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv'\n",
        "us_state_loc_csv = 'https://gist.githubusercontent.com/mbostock/9535021/raw/eaed7e5632735a6609f02d0ba0e55c031e14200d/us-state-capitals.csv'\n",
        "\n",
        "Confirmed = pd.read_csv(global_confirm_csv)\n",
        "Death = pd.read_csv(global_death_csv) \n",
        "Recovered = pd.read_csv(global_recover_csv)\n",
        "Confirmed_us = pd.read_csv(us_confirm_csv)\n",
        "Death_us = pd.read_csv(us_death_csv)\n",
        "us_state_location = pd.read_csv(us_state_loc_csv)\n",
        "\n",
        "Confirmed.drop(axis=1, inplace=True, columns=['Province/State', 'Lat', 'Long'])\n",
        "Death.drop(axis=1, inplace=True, columns=['Province/State', 'Lat', 'Long'])\n",
        "Recovered.drop(axis=1, inplace=True, columns=['Province/State', 'Lat', 'Long'])\n",
        "\n",
        "def join_national_data(confirmed, death, recovered):\n",
        "    total_case = confirmed.join(death.set_index('date'), on='date').join(recovered.set_index('date'), on='date')\n",
        "    total_case.reset_index(inplace=True, drop=True)\n",
        "    return total_case\n",
        "\n",
        "\n",
        "\n",
        "# function to extract the data of different cases in different country\n",
        "def extract_national_data(df, country, case):\n",
        "    df_extract = df[df['Country/Region'] == country].sum(axis=0)\n",
        "    df_extract = df_extract.T.reset_index()\n",
        "    df_extract = df_extract.iloc[1:]\n",
        "    df_extract.columns = ['date', case]\n",
        "    df_extract.date = pd.to_datetime(df_extract.date)\n",
        "    return df_extract\n",
        "\n",
        "us_confirmed = extract_national_data(Confirmed, 'US', 'positive')\n",
        "us_death = extract_national_data(Death, 'US', 'death')\n",
        "us_recovered = extract_national_data(Recovered, 'US', 'recovered')\n",
        "\n",
        "us_status = join_national_data(us_confirmed, us_death, us_recovered)\n",
        "\n",
        "\n",
        "in_confirmed = extract_national_data(Confirmed, 'India', 'positive')\n",
        "in_death = extract_national_data(Death, 'India', 'death')\n",
        "in_recovered = extract_national_data(Recovered, 'India', 'recovered')\n",
        "\n",
        "in_status = join_national_data(us_confirmed, us_death, us_recovered)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q472qBypyivS"
      },
      "source": [
        "wget.download('https://github.com/datameet/covid19/blob/master/data/all_totals.json','/content/drive/MyDrive/COVID/All_totals_datameet.json')\n",
        "wget.download('https://github.com/datameet/covid19/blob/master/data/mohfw.json', '/content/drive/MyDrive/COVID/mohfw_datameet.json')\n",
        "wget.download('https://hub.mph.in.gov/dataset/89cfa2e3-3319-4d31-a60d-710f76856588/resource/8b8e6cd7-ede2-4c41-a9bd-4266df783145/download/covid_report_county.xlsx','/content/drive/MyDrive/COVID/covid_report_county.xlsx')\n",
        "wget.download('https://hub.mph.in.gov/dataset/ab9d97ab-84e3-4c19-97f8-af045ee51882/resource/182b6742-edac-442d-8eeb-62f96b17773e/download/covid_report_date.xlsx' , '/content/drive/MyDrive/COVID/covid_report_date.xlsx')\n",
        "wget.download('https://hub.mph.in.gov/dataset/6bcfb11c-6b9e-44b2-be7f-a2910d28949a/resource/7661f008-81b5-4ff2-8e46-f59ad5aad456/download/covid_report_death_date_agegrp.xlsx' , '/content/drive/MyDrive/COVID/covid_report_death_date_agegrp.xlsx')\n",
        "wget.download('https://hub.mph.in.gov/dataset/62ddcb15-bbe8-477b-bb2e-175ee5af8629/resource/2538d7f1-391b-4733-90b3-9e95cd5f3ea6/download/covid_report_demographics.xlsx' , '/content/drive/MyDrive/COVID/covid_report_demographics.xlsx')\n",
        "wget.download('https://covid.ourworldindata.org/data/owid-covid-data.csv','/content/drive/MyDrive/COVID/Covid_data.csv')\n",
        "wget.download('https://covid.ourworldindata.org/data/ecdc/full_data.csv','/content/drive/MyDrive/COVID/Covid_full_data.csv')\n",
        "wget.download('https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv' , '/content/drive/MyDrive/COVID/JHU_Confirmed.csv')\n",
        "wget.download('https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv' , '/content/drive/MyDrive/COVID/JHU_Recovered.csv')\n",
        "wget.download('https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv' , '/content/drive/MyDrive/COVID/JHU_Deaths.csv')\n",
        "wget.download('https://api.covid19india.org/csv/latest/states.csv','/content/drive/MyDrive/COVID/India/states_.csv')\n",
        "wget.download('https://api.covid19india.org/csv/latest/districts.csv','/content/drive/MyDrive/COVID/India/districts_.csv')\n",
        "wget.download('https://gist.githubusercontent.com/jbrobst/56c13bbbf9d97d187fea01ca62ea5112/raw/e388c4cae20aa53cb5090210a42ebb9b765c0a36/india_states.geojson')\n",
        "State_list = [\"Assam\", \"Chandigarh\",\"Karnataka\" , \"Manipur\", \"Meghalaya\" \"Meghalaya\",\"Nagaland\" ,\"Punjab\",\n",
        "              \"Rajasthan\", \"Sikkim\" ,\"Tripura\" , \"Uttarakhand\" , \"Telangana\" , \"Bihar\" , \"Kerala\" , \n",
        "              \"Madhya Pradesh\" , \"Andaman & Nicobar\" , \"Gujarat\" , \"Lakshadweep\" , \"Odisha\" , \n",
        "              \"Dadra and Nagar Haveli and Daman and Diu\" , \"Ladakh\" , \"Jammu & Kashmir\" , \"Chhattisgarh\" , \"Delhi\" ,\n",
        "              \"Goa\" , \"Haryana\" , \"Himachal Pradesh\" , \"Jharkhand\" , \"Tamil Nadu\" , \"Uttar Pradesh\" , \"West Bengal\" , \n",
        "              \"Andhra Pradesh\" , \"Puducherry\"  , \"Maharashtra\" , \"Arunachal Pradesh\" ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY-3L0Yi3cMi"
      },
      "source": [
        "districts = pd.read_csv('/content/drive/MyDrive/COVID/India/districts_.csv')\n",
        "states = pd.read_csv('/content/drive/MyDrive/COVID/India/states_.csv')\n",
        "states = pd.concat([pd.DataFrame([['2020-03-01','Kerala',0,0,0,0,0]],columns = states.columns) , states] ,axis = 0)\n",
        "states.sort_values(by = ['Date'])\n",
        "states.fillna(0 , inplace = True)\n",
        "districts.fillna(0 , inplace = True)\n",
        "states['Active'] = states['Confirmed'] - (states['Recovered'] + states['Deceased'])\n",
        "states['Month'] = states['Date'].apply(lambda x: x.split('-')[1])\n",
        "states['Month'] = states['Month'].astype(int)\n",
        "states = states[states['Month']>2]\n",
        "date_unique = states.Date.unique()\n",
        "\n",
        "# states['Day'] = states['Date'].apply(lambda x: x.split('-')[2])\n",
        "# states['Day'] = states['Day'].astype(int)\n",
        "# states= states.assign(Pre_1 = lambda x: x.Month *31+ x.Day)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJMdzWGFcfpK"
      },
      "source": [
        "for datest in date_unique:\n",
        "  state_cases = Completed_[Completed_.Date == datest]\n",
        "  state_cases=state_cases.sort_values('Confirmed', ascending= False)\n",
        "  total_cases = state_cases['Confirmed'].sum()\n",
        "  # state_cases=state_cases.head(20)\n",
        "  plt.figure(figsize=(25,22))\n",
        "  ax = plt.subplot(1,1,1)\n",
        "  plt.suptitle('Data Analysis Assignment', fontsize = 29)\n",
        "  plt.title('\\nTop States with SARS-CoV-2 Cases ( March to November )\\n' , fontsize = 23)\n",
        "  graph = sns.barplot(data=state_cases,y='State',x='Confirmed',color=sns.color_palette('Set3')[4],label='Confirmed' , orient = 'h')\n",
        "  sns.barplot(data=state_cases,y='State',x='Recovered',color=sns.color_palette('Set3')[5],label='Cured' , orient = 'h')\n",
        "  # sns.barplot(data=state_cases,y='State',x='Active',color=sns.color_palette('viridis')[3],label='Active', ci = 'sd')\n",
        "  sns.barplot(data=state_cases,y='State',x='Deceased',color=sns.color_palette('Set3')[3],label='Deaths', orient = 'h')\n",
        "  # plt.xticks(rotation=90)\n",
        "  plt.ylabel('States')\n",
        "  plt.xlabel('Number of Cases')\n",
        "  # plt.xlim(0,Completed_['Confirmed'].max()+Completed_['Confirmed'].max()/10 )\n",
        "  plt.xlim(0,state_cases['Confirmed'].max()+state_cases['Confirmed'].max()/10 )\n",
        "  plt.legend(loc = 8)\n",
        "  anchored_text = AnchoredText(\"Month : {}\\nDays Passed : {}\\nTotal Confirmed Cases : {}\".format(state_cases.Month.unique()[0] ,  state_cases.Days_Passed.unique()[0],int(total_cases)), borderpad=1.0, pad = 1.0, loc=7 , frameon= True )\n",
        "  ax.add_artist(anchored_text)\n",
        "  # plt.text(0.95, 0.01, 'colored text in axes coords',\n",
        "  #         verticalalignment='bottom', horizontalalignment='right',\n",
        "  #         color='green', fontsize=15)\n",
        "  for p in graph.patches[:20]:\n",
        "    _x = p.get_x() + p.get_width() \n",
        "    _y = p.get_y() + p.get_height()/2 + float(0.2)\n",
        "    value = ((int(p.get_width())/total_cases)*100)\n",
        "    if np.isnan(value):\n",
        "      value = 0.0\n",
        "    graph.text(_x , _y , ' {:.2f}%'.format(value) , ha = 'left', color = sns.color_palette('rocket')[1])\n",
        "  plt.savefig('Figures/box_plot_states_large_{}.jpg'.format(datest) , bbox_inches = 'tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1ryUIhGdPBV"
      },
      "source": [
        "def make_video():\n",
        "  fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
        "  # dim = (int(1721/3),int(1421/3))\n",
        "  dim = (1721,1421)\n",
        "  out = cv2.VideoWriter('/content/drive/MyDrive/COVID/States_war_slow_.avi' , fourcc , 10 , dim)\n",
        "  for i in date_unique:\n",
        "    img_path = 'Figures/box_plot_states_large_{}.jpg'.format(i)\n",
        "    frame = cv2.imread(img_path)\n",
        "    frame = cv2.resize(frame , dsize = dim)\n",
        "    out.write(frame)\n",
        "  out.release()\n",
        "make_video()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KSOmGno178a"
      },
      "source": [
        "colors = sns.color_palette(\"rocket\")\n",
        "plt.figure(figsize=(25,18))\n",
        "\n",
        "# for iso in ['CHL', 'BEL', 'UKR', 'ZAF', 'IRN', 'POL', 'DEU', 'PER', 'MEX', 'COL', 'ARG', 'ITA', 'GBR', 'ESP', 'RUS', 'FRA', 'BRA', 'IND', 'USA']:\n",
        "# for iso in ['ITA', 'GBR', 'ESP', 'RUS', 'FRA', 'BRA', 'IND', 'USA']:\n",
        "for iso in ['FRA', 'BRA', 'IND', 'USA']:\n",
        "  plt.plot(World_[World_['iso_code'] == iso]['Days_Passed'].values , World_[World_['iso_code'] == iso]['new_cases_smoothed'].values , label = iso )\n",
        "plt.suptitle('Data Analysis Assignment', fontsize = 29)\n",
        "plt.title('\\nNew Cases in World of  SARS-CoV-2  ( Jan to November )\\n' , fontsize = 23)\n",
        "plt.legend()\n",
        "plt.ylabel('New Cases')\n",
        "plt.xlabel('Days Passed Since 31-December-2019')\n",
        "plt.savefig('/content/drive/MyDrive/COVID/India/World New Cases 3.jpg' , bbox_inches = 'tight')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6nMA3wm8v8f"
      },
      "source": [
        "colors = sns.color_palette(\"rocket\")\n",
        "plt.figure(figsize=(25,18))\n",
        "\n",
        "for iso in ['CHL', 'BEL', 'UKR', 'ZAF', 'IRN', 'POL', 'DEU', 'PER', 'MEX', 'COL', 'ARG', 'ITA', 'GBR', 'ESP', 'RUS', 'FRA', 'BRA', 'IND', 'USA']:\n",
        "# for iso in ['ITA', 'GBR', 'ESP', 'RUS', 'FRA', 'BRA', 'IND', 'USA']:\n",
        "# for iso in ['FRA', 'BRA', 'IND', 'USA']:\n",
        "  plt.plot(World_[World_['iso_code'] == iso]['Days_Passed'].values , World_[World_['iso_code'] == iso]['total_cases'].values , label = iso )\n",
        "plt.suptitle('Data Analysis Assignment', fontsize = 29)\n",
        "plt.title('\\nTotal Cases in World of  SARS-CoV-2  ( Jan to November )\\n' , fontsize = 23)\n",
        "plt.legend()\n",
        "plt.ylabel('Total Cases')\n",
        "plt.xlabel('Days Passed Since 31-December-2019')\n",
        "plt.savefig('/content/drive/MyDrive/COVID/India/World Total Cases 1.jpg' , bbox_inches = 'tight')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2OfeTQ-M_jp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}